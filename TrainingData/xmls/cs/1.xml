<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE pdf2xml SYSTEM "pdf2xml.dtd">

<pdf2xml>
<page number="1" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="0" size="23" family="Times" color="#000000"/>
	<fontspec id="1" size="15" family="Times" color="#000000"/>
	<fontspec id="2" size="12" family="Times" color="#000000"/>
	<fontspec id="3" size="19" family="Times" color="#000000"/>
	<fontspec id="4" size="14" family="Times" color="#000000"/>
<text top="172" left="123" width="672" height="23" font="0">Tuﬀy: Scaling up Statistical Inference in Markov Logic Networks</text>
<text top="205" left="368" width="182" height="23" font="0">using an RDBMS</text>
<text top="256" left="195" width="70" height="16" font="1">Feng Niu</text>
<text top="256" left="314" width="118" height="16" font="1">Christopher R´</text>
<text top="256" left="423" width="8" height="16" font="1">e</text>
<text top="256" left="480" width="96" height="16" font="1">AnHai Doan</text>
<text top="256" left="625" width="98" height="16" font="1">Jude Shavlik</text>
<text top="283" left="341" width="253" height="16" font="1">University of Wisconsin-Madison</text>
<text top="303" left="310" width="317" height="17" font="1">{leonn,chrisre,anhai,shavlik}@cs.wisc.edu</text>
<text top="339" left="391" width="136" height="16" font="1">December 7, 2010</text>
<text top="402" left="426" width="66" height="13" font="2">Abstract</text>
<text top="429" left="171" width="598" height="16" font="2">Markov Logic Networks (MLNs) have emerged as a powerful framework that combines sta-</text>
<text top="447" left="149" width="620" height="13" font="2">tistical and logical reasoning; they have been applied to many data intensive problems including</text>
<text top="465" left="149" width="620" height="16" font="2">information extraction, entity resolution, and text mining. Current implementations of MLNs</text>
<text top="483" left="149" width="620" height="13" font="2">do not scale to real-world data sets, which is preventing their wide-spread adoption. We present</text>
<text top="503" left="149" width="620" height="13" font="2">Tuffy that achieves scalability via three novel contributions: (1) a bottom-up approach to</text>
<text top="519" left="149" width="620" height="13" font="2">grounding that allows us to leverage the full power of the relational optimizer, (2) a novel hy-</text>
<text top="537" left="149" width="620" height="13" font="2">brid architecture that allows us to perform AI-style local search eﬃciently using an RDBMS,</text>
<text top="554" left="149" width="620" height="13" font="2">and (3) a theoretical insight that shows when one can (exponentially) improve the eﬃciency</text>
<text top="572" left="149" width="620" height="13" font="2">of stochastic local search. We leverage (3) to build novel partitioning, loading, and parallel</text>
<text top="590" left="149" width="620" height="13" font="2">algorithms. We show that our approach outperforms state-of-the-art implementations in both</text>
<text top="608" left="149" width="366" height="13" font="2">quality and speed on several publicly available datasets.</text>
<text top="655" left="108" width="12" height="19" font="3">1</text>
<text top="655" left="144" width="133" height="19" font="3">Introduction</text>
<text top="695" left="108" width="702" height="17" font="4">Over the past few years, Markov Logic Networks (MLNs) have emerged as a powerful and popular</text>
<text top="716" left="108" width="702" height="17" font="4">framework that combines logical and probabilistic reasoning. MLNs have been successfully applied</text>
<text top="736" left="108" width="702" height="15" font="4">to a wide variety of data management problems, including information extraction, entity resolution,</text>
<text top="756" left="108" width="702" height="15" font="4">and text mining. In contrast to probability models like factor graphs [24] that require complex</text>
<text top="777" left="108" width="702" height="17" font="4">distributions to be speciﬁed in tedious detail, MLNs allow us to declare a rigorous statistical model</text>
<text top="797" left="108" width="702" height="15" font="4">at a much higher level using essentially ﬁrst-order logic. For example, in a problem where we try</text>
<text top="817" left="108" width="702" height="15" font="4">to classify papers by research area, one could write a rule such as “it is likely that if one paper cites</text>
<text top="838" left="108" width="318" height="15" font="4">another they are in the same research area.”</text>
<text top="858" left="133" width="677" height="17" font="4">Our interest in MLNs stems from our involvement in a DARPA project called “Machine Read-</text>
<text top="878" left="108" width="702" height="15" font="4">ing.” The grand challenge is to build software that can read the Web, i.e., extract and integrate</text>
<text top="899" left="108" width="702" height="15" font="4">structured data (e.g., entities, relationships) from Web data, then use this structured data to answer</text>
<text top="919" left="108" width="702" height="17" font="4">user queries. The current approach is to use MLNs as a lingua franca to combine many diﬀerent</text>
<text top="939" left="108" width="702" height="17" font="4">kinds of extractions into one coherent picture. To accomplish this goal, it is critical that MLNs</text>
<text top="960" left="108" width="615" height="15" font="4">scale to large data sets, and we have been put in charge of investigating this problem.</text>
<text top="980" left="133" width="677" height="17" font="4">Unfortunately, none of the current MLN implementations scale beyond relatively small data</text>
<text top="1000" left="108" width="702" height="15" font="4">sets (and even on many of these data sets, existing implementations routinely take hours to run).</text>
<text top="1021" left="108" width="702" height="15" font="4">The ﬁrst obvious reason is that these are in-memory implementations: when manipulating large</text>
<text top="1069" left="455" width="8" height="15" font="4">1</text>
</page>
<page number="2" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="5" size="9" family="Times" color="#000000"/>
	<fontspec id="6" size="6" family="Times" color="#000000"/>
	<fontspec id="7" size="11" family="Times" color="#000000"/>
<text top="113" left="108" width="702" height="15" font="4">intermediate data structures that overﬂow main memory, they either crash or thrash badly. Con-</text>
<text top="133" left="108" width="702" height="17" font="4">sequently, there is an emerging eﬀort across several research groups to scale up MLNs. In this</text>
<text top="154" left="108" width="702" height="17" font="4">paper, we describe our system, Tuffy, that leverages an RDBMS to address the above scalability</text>
<text top="174" left="108" width="63" height="15" font="4">problem.</text>
<text top="194" left="133" width="677" height="17" font="4">Reasoning with MLNs can be classiﬁed as either learning or inference [21]. We focus on infer-</text>
<text top="215" left="108" width="702" height="15" font="4">ence, since typically a model is learned once, and then an application may perform inference many</text>
<text top="235" left="108" width="702" height="15" font="4">times using the same model; hence inference is an on-line process, which must be fast. Conceptu-</text>
<text top="255" left="108" width="702" height="17" font="4">ally, inference in MLNs has two phases: a grounding phase, which constructs a large, weighted SAT</text>
<text top="276" left="108" width="702" height="15" font="4">formula, and a search phase, which searches for a low cost (weight) assignment (called a solution)</text>
<text top="296" left="108" width="611" height="17" font="4">to the SAT formula from grounding (using WalkSAT [14], a local search procedure).</text>
<text top="293" left="719" width="6" height="11" font="5">1</text>
<text top="296" left="733" width="77" height="15" font="4">Grounding</text>
<text top="316" left="108" width="702" height="15" font="4">is a non-trivial portion of the overall inference eﬀort: on a classiﬁcation benchmark (called RC)</text>
<text top="337" left="108" width="702" height="17" font="4">the state-of-the-art MLN inference engine, Alchemy [7], spends over 96% of its execution time in</text>
<text top="357" left="108" width="702" height="17" font="4">grounding. The state-of-the-art strategy for the grounding phase (and the one used by Alchemy)</text>
<text top="377" left="108" width="702" height="15" font="4">is a top-down procedure (similar to the proof strategy in Prolog). In contrast, we propose a bottom-</text>
<text top="398" left="108" width="702" height="17" font="4">up grounding strategy. Intuitively, bottom-up grounding allows Tuffy to fully exploit the RDBMS</text>
<text top="418" left="108" width="702" height="17" font="4">optimizer, and thereby signiﬁcantly speed up the grounding phase of MLN inference. On an entity</text>
<text top="438" left="108" width="702" height="17" font="4">resolution task, Alchemy takes over 7 hours to complete grounding, while Tuffy’s grounding</text>
<text top="459" left="108" width="219" height="15" font="4">ﬁnishes in less than 2 minutes.</text>
<text top="479" left="133" width="677" height="15" font="4">But not all phases are well-optimized by the RDBMS: during the search phase, we found that</text>
<text top="499" left="108" width="702" height="15" font="4">the RDBMS implementation performed poorly. The underlying reason is a fundamental problem</text>
<text top="520" left="108" width="702" height="15" font="4">for pushing local search procedures into an RDBMS: search procedures often perform inherently</text>
<text top="540" left="108" width="702" height="15" font="4">sequential, random data accesses. Consequently, any RDBMS-based solution must execute a large</text>
<text top="560" left="108" width="702" height="15" font="4">number of disk accesses, each of which has a substantial overhead (due to the RDBMS) versus direct</text>
<text top="581" left="108" width="702" height="15" font="4">main-memory access. Not surprisingly, given the same amount of time, an in-memory solution can</text>
<text top="601" left="108" width="702" height="15" font="4">execute between three and ﬁve orders of magnitude more search steps than an approach that uses</text>
<text top="621" left="108" width="702" height="15" font="4">an RDBMS. Thus, to achieve competitive performance, we are forced to develop a novel hybrid</text>
<text top="642" left="108" width="702" height="15" font="4">architecture that supports local search procedures in main memory whenever possible. This is our</text>
<text top="662" left="108" width="214" height="15" font="4">second technical contribution.</text>
<text top="682" left="133" width="677" height="17" font="4">Our third contribution is a simple partitioning technique that allows Tuffy to introduce paral-</text>
<text top="702" left="108" width="702" height="15" font="4">lelism and use less memory than state-of-the-art approaches. Surprisingly, this same technique often</text>
<text top="723" left="108" width="702" height="17" font="4">allows Tuffy to speed up the search phase exponentially. The underlying idea is simple: in many</text>
<text top="743" left="108" width="702" height="15" font="4">cases, a local search problem can be divided into multiple independent subproblems. For example,</text>
<text top="763" left="108" width="702" height="15" font="4">the formula that is output by the grounding phase may consist of multiple connected components.</text>
<text top="784" left="108" width="702" height="15" font="4">On such datasets, we derive a suﬃcient condition under which solving the subproblems indepen-</text>
<text top="804" left="108" width="702" height="15" font="4">dently results in exponentially faster search than running the larger global problem (Thm. 3.1). An</text>
<text top="824" left="108" width="702" height="15" font="4">application of our theorem shows that on an information extraction testbed, a system that is not</text>
<text top="845" left="108" width="563" height="17" font="4">aware of the partitioning phenomenon (such as Alchemy) must take at least 2</text>
<text top="842" left="671" width="19" height="11" font="5">200</text>
<text top="845" left="696" width="114" height="15" font="4">more steps than</text>
<text top="868" left="108" width="702" height="14" font="4">Tuffy’s approach. Empirically we found that, on some real-world datasets, solutions found by</text>
<text top="888" left="108" width="702" height="14" font="4">Tuffy within one minute has higher quality than those found by non-partitioning systems (such</text>
<text top="906" left="108" width="303" height="17" font="4">as Alchemy) even after running for days.</text>
<text top="926" left="133" width="677" height="15" font="4">The exponential diﬀerence in running time for independent subproblems versus the larger global</text>
<text top="946" left="108" width="702" height="15" font="4">problem suggests that in some cases, further decomposing the search space may improve the overall</text>
<text top="975" left="127" width="5" height="8" font="6">1</text>
<text top="978" left="133" width="677" height="12" font="7">We discuss maximum a posteriori inference (highest probability world) which is critical for many integration</text>
<text top="994" left="108" width="702" height="14" font="7">tasks. Our system, Tuffy, supports marginal probabilistic inference as well: the algorithms are similar, and in §A.5,</text>
<text top="1011" left="108" width="259" height="12" font="7">we apply our results to marginal inference.</text>
<text top="1069" left="455" width="8" height="15" font="4">2</text>
</page>
<page number="3" position="absolute" top="0" left="0" height="1188" width="918">
<text top="113" left="108" width="702" height="17" font="4">runtime. To implement this idea for MLNs, we must address two diﬃcult problems: (1) partitioning</text>
<text top="133" left="108" width="702" height="15" font="4">the formula from grounding (and so the search space) to minimize the number of formula that are</text>
<text top="154" left="108" width="702" height="15" font="4">split between partitions, and (2) augmenting the search algorithm to be aware of partitioning.</text>
<text top="174" left="108" width="702" height="15" font="4">We show that the ﬁrst problem is NP-hard (even to approximate), and design a scalable heuristic</text>
<text top="194" left="108" width="702" height="15" font="4">partitioning algorithm. For the second problem, we apply a technique from non-linear optimization</text>
<text top="215" left="108" width="702" height="15" font="4">to leverage the insights gained from our characterization of the phenomenon described above. The</text>
<text top="235" left="108" width="702" height="15" font="4">eﬀect of such partitioning is dramatic. As an example, on a classiﬁcation benchmark (called RC),</text>
<text top="258" left="108" width="702" height="14" font="4">Tuffy (using 15MB of RAM) produces much better result quality in minutes than Alchemy</text>
<text top="276" left="108" width="702" height="17" font="4">(using 2.8GB of RAM) even after days of running. In fact, Tuffy is able to answer queries on a</text>
<text top="296" left="108" width="702" height="17" font="4">version of the RC dataset that is over 2 orders of magnitude larger. (We estimate that Alchemy</text>
<text top="316" left="108" width="315" height="15" font="4">would need 280GB+ of RAM to process it.)</text>
<text top="360" left="108" width="114" height="15" font="4">Related Work</text>
<text top="362" left="239" width="571" height="14" font="4">MLNs are an integral part of state-of-the-art approaches in a variety of applica-</text>
<text top="380" left="108" width="702" height="15" font="4">tions: natural language processing [22], ontology matching [30], information extraction [18], entity</text>
<text top="400" left="108" width="702" height="17" font="4">resolution [26], data mining [27], etc. And so, there is an application push to support MLNs. In</text>
<text top="421" left="108" width="702" height="15" font="4">contrast to machine learning research that has focused on quality and algorithmic eﬃciency, we</text>
<text top="441" left="108" width="631" height="15" font="4">apply fundamental data management principles to improve scalability and performance.</text>
<text top="461" left="133" width="680" height="15" font="4">Pushing statistical reasoning models inside a database system has been a goal of many projects [5,</text>
<text top="481" left="108" width="702" height="17" font="4">11, 12, 20, 29]. Most closely related is the BayesStore project, in which the database essentially</text>
<text top="502" left="108" width="702" height="15" font="4">stores Bayes Nets [17] and allows these networks to be retrieved for inference by an external pro-</text>
<text top="522" left="108" width="702" height="17" font="4">gram. In contrast, Tuffy uses an RDBMS to optimize the inference procedure. The Monte-Carlo</text>
<text top="542" left="108" width="702" height="17" font="4">database [11] made sampling a ﬁrst-class citizen inside an RDBMS. In contrast, in Tuffy our</text>
<text top="563" left="108" width="702" height="15" font="4">approach can be viewed as pushing classical search inside the database engine. One way to view</text>
<text top="583" left="108" width="702" height="17" font="4">an MLN is a compact speciﬁcation of factor graphs [23, 24]. Sen et al. proposed new algorithms;</text>
<text top="603" left="108" width="702" height="15" font="4">in contrast, we take an existing, widely used class of algorithms (local search), and our focus is to</text>
<text top="624" left="108" width="332" height="15" font="4">leverage the RDBMS to improve performance.</text>
<text top="644" left="133" width="677" height="15" font="4">There has also been an extensive amount of work on probabilistic databases [1, 2, 4, 19] that</text>
<text top="664" left="108" width="702" height="15" font="4">deal with simpler probabilistic models. Finding the most likely world is trivial in these models;</text>
<text top="685" left="108" width="702" height="17" font="4">in contrast, it is highly non-trivial in MLNs (in fact, it is NP-hard [6]). MLNs also provide an</text>
<text top="705" left="108" width="702" height="15" font="4">appealing answer for one of the most pressing questions in the area of probabilistic databases:</text>
<text top="725" left="108" width="702" height="15" font="4">“Where do those probabilities come from?” Finally, none of these prior approaches deal with the</text>
<text top="746" left="108" width="702" height="17" font="4">core technical challenge Tuffy addresses, which is handling AI-style search inside a database.</text>
<text top="766" left="108" width="318" height="15" font="4">Additional related work can be found in §D.</text>
<text top="809" left="108" width="317" height="15" font="4">Contributions, Validation, and Outline</text>
<text top="809" left="441" width="369" height="15" font="4">To summarize, we make the following contributions:</text>
<text top="842" left="133" width="677" height="18" font="4">• In §3.1, we design a solution that pushes MLNs into RDBMSes. The key idea is to use</text>
<text top="863" left="149" width="661" height="15" font="4">bottom-up grounding that allows us to leverage the RDBMS optimizer; this idea improves</text>
<text top="884" left="149" width="516" height="15" font="4">the performance of the grounding phase by several orders of magnitude.</text>
<text top="907" left="133" width="677" height="15" font="4">• In §3.2, we devise a novel hybrid architecture to support eﬃcient grounding and in-memory</text>
<text top="928" left="149" width="661" height="15" font="4">inference. By itself, this architecture is orders of magnitude more scalable and, given the</text>
<text top="948" left="149" width="614" height="15" font="4">same amount of time, performs orders of magnitude more search steps than prior art.</text>
<text top="972" left="133" width="677" height="15" font="4">• In §3.3, we describe novel data partitioning techniques to decrease the memory usage and</text>
<text top="993" left="149" width="661" height="17" font="4">to increase parallelism (and so improve the scalability) of Tuffy’s in-memory inference al-</text>
<text top="1013" left="149" width="661" height="15" font="4">gorithms. Additionally, we show that for any MLN with an MRF that contains multiple</text>
<text top="1069" left="455" width="8" height="15" font="4">3</text>
</page>
<page number="4" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="8" size="8" family="Times" color="#000000"/>
<text top="129" left="126" width="147" height="12" font="2">paper(PaperID, URL)</text>
<text top="147" left="127" width="145" height="12" font="2">wrote(Author, Paper)</text>
<text top="165" left="127" width="145" height="12" font="2">refers(Paper, Paper)</text>
<text top="183" left="128" width="142" height="12" font="2">cat(Paper, Category)</text>
<text top="110" left="295" width="42" height="13" font="2">weight</text>
<text top="110" left="355" width="25" height="13" font="2">rule</text>
<text top="128" left="312" width="7" height="13" font="2">5</text>
<text top="129" left="355" width="213" height="12" font="2">cat(p, c1), cat(p, c2) =&gt; c1 = c2</text>
<text top="128" left="706" width="15" height="13" font="2">(F</text>
<text top="133" left="722" width="6" height="9" font="8">1</text>
<text top="128" left="729" width="6" height="13" font="2">)</text>
<text top="146" left="312" width="7" height="13" font="2">1</text>
<text top="147" left="355" width="333" height="12" font="2">wrote(x, p1), wrote(x, p2), cat(p1, c) =&gt; cat(p2, c)</text>
<text top="146" left="707" width="15" height="13" font="2">(F</text>
<text top="151" left="722" width="6" height="9" font="8">2</text>
<text top="146" left="729" width="6" height="13" font="2">)</text>
<text top="164" left="312" width="7" height="13" font="2">2</text>
<text top="165" left="355" width="260" height="12" font="2">cat(p1, c), refers(p1, p2) =&gt; cat(p2, c)</text>
<text top="164" left="707" width="15" height="13" font="2">(F</text>
<text top="169" left="722" width="6" height="9" font="8">3</text>
<text top="164" left="729" width="6" height="13" font="2">)</text>
<text top="182" left="303" width="27" height="13" font="2">+∞</text>
<text top="183" left="355" width="204" height="12" font="2">paper(p, u) =&gt; ∃x. wrote(x, p)</text>
<text top="182" left="707" width="15" height="13" font="2">(F</text>
<text top="187" left="722" width="6" height="9" font="8">4</text>
<text top="182" left="729" width="6" height="13" font="2">)</text>
<text top="200" left="310" width="12" height="13" font="2">-1</text>
<text top="201" left="355" width="132" height="12" font="2">cat(p, ‘Networking’)</text>
<text top="200" left="707" width="15" height="13" font="2">(F</text>
<text top="205" left="722" width="6" height="9" font="8">5</text>
<text top="200" left="729" width="6" height="13" font="2">)</text>
<text top="111" left="757" width="116" height="12" font="2">wrote(‘Joe’, ‘P1’)</text>
<text top="129" left="757" width="116" height="12" font="2">wrote(‘Joe’, ‘P2’)</text>
<text top="147" left="757" width="123" height="12" font="2">wrote(‘Jake’, ‘P3’)</text>
<text top="165" left="757" width="120" height="12" font="2">refers(‘P1’, ‘P3’)</text>
<text top="183" left="757" width="101" height="12" font="2">cat(‘P2’, ‘DB’)</text>
<text top="199" left="757" width="17" height="14" font="2">· · ·</text>
<text top="218" left="175" width="49" height="13" font="2">Schema</text>
<text top="218" left="431" width="167" height="13" font="2">A Markov Logic Program</text>
<text top="218" left="789" width="59" height="13" font="2">Evidence</text>
<text top="253" left="108" width="702" height="15" font="4">Figure 1: A Sample Markov Logic Program: The goal is to classify papers by category. As evidence</text>
<text top="274" left="108" width="702" height="15" font="4">we are given author and citation information of all papers, as well as the labels of a subset of the</text>
<text top="294" left="108" width="702" height="15" font="4">papers; and we want to classify the remaining papers. Any variable not explicitly quantiﬁed is</text>
<text top="314" left="108" width="158" height="15" font="4">universally quantiﬁed.</text>
<text top="364" left="149" width="661" height="15" font="4">components, partitioning exponentially improves search speed, and we quantify this theoret-</text>
<text top="384" left="149" width="41" height="15" font="4">ically.</text>
<text top="407" left="133" width="677" height="18" font="4">• In §3.4, we generalize our partitioning results to arbitrary MLNs using our characterization</text>
<text top="428" left="149" width="661" height="15" font="4">of the partitioning phenomenon. These techniques result in our highest quality, most space-</text>
<text top="448" left="149" width="128" height="15" font="4">eﬃcient solutions.</text>
<text top="479" left="108" width="702" height="17" font="4">We present an extensive experimental study on a diverse set of MLN testbeds to demonstrate that</text>
<text top="499" left="108" width="702" height="17" font="4">our system Tuffy is able to get better result quality more quickly and work over larger datasets</text>
<text top="519" left="108" width="263" height="15" font="4">than the state-of-the-art approaches.</text>
<text top="567" left="108" width="12" height="19" font="3">2</text>
<text top="567" left="144" width="140" height="19" font="3">Preliminaries</text>
<text top="607" left="108" width="702" height="15" font="4">We illustrate a Markov Logic Network program using the example of classifying papers by topic</text>
<text top="627" left="108" width="558" height="17" font="4">area. We then deﬁne the semantics of MLNs, and the mechanics of inference.</text>
<text top="669" left="108" width="26" height="16" font="1">2.1</text>
<text top="669" left="154" width="187" height="16" font="1">The Syntax of MLNs</text>
<text top="701" left="108" width="702" height="17" font="4">Figure 1 shows an example input MLN program for Tuffy that is used to classify paper references</text>
<text top="722" left="108" width="702" height="17" font="4">by topic area, such as databases, systems, AI, etc. In this example, a user gives Tuffy a set of</text>
<text top="742" left="108" width="702" height="15" font="4">relations that capture information about the papers in her dataset: she has extracted authors and</text>
<text top="762" left="108" width="702" height="15" font="4">citations and stored in them in the relations wrote(Author,Paper) and refers(Paper,Paper). She</text>
<text top="783" left="108" width="702" height="15" font="4">may also provide evidence, which is data that she knows to be true (or false). Here, the evidence</text>
<text top="803" left="108" width="702" height="15" font="4">shows that Joe wrote papers P1 and P2 and P1 cited another paper P3. In the relation cat, she</text>
<text top="823" left="108" width="702" height="17" font="4">provides Tuffy with a subset of papers and the categories into which they fall. The cat relation is</text>
<text top="844" left="108" width="702" height="15" font="4">incomplete: some papers are not labeled. We can think of each possible labeling of these papers as</text>
<text top="864" left="108" width="702" height="15" font="4">an instantiation of the cat relation, which can be viewed as a possible world [8]. The classiﬁcation</text>
<text top="884" left="108" width="702" height="15" font="4">task is to ﬁnd the most likely labeling of papers by topic area, and hence the most likely possible</text>
<text top="905" left="108" width="44" height="15" font="4">world.</text>
<text top="922" left="133" width="677" height="15" font="4">To tell the system which possible world it should produce, the user provides (in addition to the</text>
<text top="940" left="108" width="702" height="15" font="4">above data) a set of rules that incorporate their knowledge of the problem. A simple example rule</text>
<text top="958" left="108" width="27" height="15" font="4">is F</text>
<text top="964" left="135" width="6" height="11" font="5">1</text>
<text top="958" left="142" width="5" height="15" font="4">:</text>
<text top="978" left="331" width="213" height="12" font="2">cat(p, c1), cat(p, c2) =&gt; c1 = c2</text>
<text top="977" left="559" width="15" height="13" font="2">(F</text>
<text top="983" left="574" width="6" height="9" font="8">1</text>
<text top="977" left="581" width="6" height="13" font="2">)</text>
<text top="1003" left="115" width="95" height="15" font="4">Intuitively, F</text>
<text top="1009" left="210" width="6" height="11" font="5">1</text>
<text top="1003" left="224" width="586" height="17" font="4">says that a paper should be in one category. In MLNs, this rule may be hard,</text>
<text top="1024" left="108" width="702" height="15" font="4">meaning that it behaves like a standard key constraint: in any possible world, each paper must</text>
<text top="1069" left="455" width="8" height="15" font="4">4</text>
</page>
<page number="5" position="absolute" top="0" left="0" height="1188" width="918">
<text top="113" left="108" width="702" height="15" font="4">be in at most one category. This rule may also be soft, meaning that it may be violated in some</text>
<text top="133" left="108" width="702" height="15" font="4">possible worlds. For example, in some worlds a paper may be in two categories. Soft rules also have</text>
<text top="154" left="108" width="695" height="15" font="4">weights that intuitively tell us how likely the rule is to hold in a possible world. In this example, F</text>
<text top="159" left="803" width="6" height="11" font="5">1</text>
<text top="174" left="108" width="528" height="15" font="4">is a soft rule and has weight 5. Roughly, this means that a ﬁxed paper is e</text>
<text top="171" left="636" width="6" height="11" font="5">5</text>
<text top="174" left="648" width="162" height="15" font="4">times more likely to be</text>
<text top="194" left="108" width="388" height="15" font="4">in a single category compared to being in 2 categories.</text>
<text top="191" left="496" width="6" height="11" font="5">2</text>
<text top="197" left="510" width="300" height="14" font="4">MLNs can also involve data in non-trivial</text>
<text top="215" left="108" width="468" height="15" font="4">ways, we refer the reader to §A.1 for a more complete exposition.</text>
<text top="258" left="108" width="109" height="15" font="4">Query Model</text>
<text top="258" left="234" width="576" height="15" font="4">Given the data and the rules, a user may write arbitrary queries in terms of the</text>
<text top="278" left="108" width="702" height="17" font="4">relations. In Tuffy, the system is responsible for ﬁlling in whatever missing data is needed: in this</text>
<text top="299" left="108" width="702" height="15" font="4">example, the category of each unlabeled paper is unknown, and so to answer a query the system</text>
<text top="319" left="108" width="441" height="15" font="4">infers the most likely labels for each paper from the evidence.</text>
<text top="362" left="108" width="26" height="16" font="1">2.2</text>
<text top="362" left="154" width="173" height="16" font="1">Semantics of MLNs</text>
<text top="391" left="108" width="702" height="17" font="4">We describe the semantics of MLNs. Formally, we ﬁrst ﬁx a schema σ (as in Figure 1) and a domain</text>
<text top="409" left="108" width="368" height="15" font="4">of constants D. Given as input a set of formula ¯</text>
<text top="409" left="464" width="48" height="15" font="4">F = F</text>
<text top="415" left="512" width="6" height="11" font="5">1</text>
<text top="409" left="519" width="47" height="15" font="4">, . . . , F</text>
<text top="415" left="566" width="10" height="11" font="5">N</text>
<text top="409" left="585" width="115" height="15" font="4">(in clausal form</text>
<text top="406" left="699" width="6" height="11" font="5">3</text>
<text top="409" left="706" width="104" height="15" font="4">) with weights</text>
<text top="427" left="108" width="12" height="15" font="4">w</text>
<text top="432" left="120" width="6" height="11" font="5">1</text>
<text top="427" left="127" width="48" height="15" font="4">, . . . , w</text>
<text top="433" left="175" width="10" height="11" font="5">N</text>
<text top="427" left="187" width="623" height="15" font="4">, they deﬁne a probability distribution over possible worlds (deterministic databases).</text>
<text top="445" left="108" width="702" height="15" font="4">To construct this probability distribution, the ﬁrst step is grounding: given a formula F with free</text>
<text top="463" left="108" width="76" height="15" font="4">variables ¯</text>
<text top="463" left="175" width="47" height="15" font="4">x = (x</text>
<text top="468" left="222" width="6" height="11" font="5">1</text>
<text top="463" left="229" width="46" height="15" font="4">, . . . , x</text>
<text top="468" left="275" width="11" height="11" font="5">m</text>
<text top="463" left="287" width="123" height="15" font="4">), then for each ¯</text>
<text top="463" left="398" width="42" height="15" font="4">d ∈ D</text>
<text top="460" left="441" width="11" height="11" font="5">m</text>
<text top="463" left="453" width="191" height="15" font="4">, we create a new formula g</text>
<text top="467" left="646" width="6" height="11" font="5">¯</text>
<text top="470" left="644" width="7" height="11" font="5">d</text>
<text top="463" left="656" width="154" height="15" font="4">called a ground clause</text>
<text top="481" left="108" width="55" height="15" font="4">where g</text>
<text top="485" left="166" width="6" height="11" font="5">¯</text>
<text top="488" left="163" width="7" height="11" font="5">d</text>
<text top="481" left="176" width="352" height="15" font="4">denotes the result of substituting each variable x</text>
<text top="486" left="528" width="4" height="11" font="5">i</text>
<text top="481" left="539" width="83" height="15" font="4">of F with d</text>
<text top="486" left="622" width="4" height="11" font="5">i</text>
<text top="481" left="628" width="147" height="15" font="4">. For example, for F</text>
<text top="486" left="774" width="6" height="11" font="5">3</text>
<text top="481" left="787" width="23" height="15" font="4">the</text>
<text top="500" left="108" width="369" height="15" font="4">variables are {p1, p2, c}: one tuple of constants is ¯</text>
<text top="500" left="466" width="337" height="15" font="4">d = (‘P1’, ‘P2’, ‘DB’) and the ground formula f</text>
<text top="505" left="805" width="6" height="11" font="5">¯</text>
<text top="508" left="803" width="7" height="11" font="5">d</text>
<text top="518" left="108" width="16" height="15" font="4">is:</text>
<text top="538" left="283" width="352" height="12" font="2">cat(‘P1’, ‘DB’), refers(‘P1’, ‘P2’) =&gt; cat(‘P2’, ‘DB’)</text>
<text top="565" left="113" width="697" height="15" font="4">Each constituent in the ground formula, such as cat(‘P1’, ‘DB’) and refers(‘P1’, ‘P2’), is called a</text>
<text top="586" left="108" width="465" height="15" font="4">ground predicate or atom for short. In the worst case there are D</text>
<text top="583" left="574" width="6" height="11" font="5">3</text>
<text top="586" left="586" width="145" height="15" font="4">ground clauses for F</text>
<text top="591" left="731" width="6" height="11" font="5">3</text>
<text top="586" left="738" width="72" height="15" font="4">. For each</text>
<text top="606" left="108" width="71" height="15" font="4">formula F</text>
<text top="611" left="179" width="4" height="11" font="5">i</text>
<text top="606" left="190" width="615" height="15" font="4">(for i = 1 . . . N ), we perform the above process. Each ground clause g of a formula F</text>
<text top="611" left="805" width="4" height="11" font="5">i</text>
<text top="626" left="108" width="221" height="15" font="4">is assigned the same weight, w</text>
<text top="632" left="329" width="4" height="11" font="5">i</text>
<text top="626" left="334" width="189" height="15" font="4">. So, a ground clause of F</text>
<text top="632" left="523" width="6" height="11" font="5">1</text>
<text top="626" left="536" width="274" height="15" font="4">has weight 5, while any ground clause</text>
<text top="647" left="108" width="30" height="15" font="4">of F</text>
<text top="652" left="138" width="6" height="11" font="5">2</text>
<text top="647" left="151" width="259" height="15" font="4">has weight 1. We denote by G = (¯</text>
<text top="647" left="401" width="279" height="15" font="4">g, w) the set of all ground clauses of ¯</text>
<text top="647" left="668" width="141" height="15" font="4">F and a function w</text>
<text top="667" left="108" width="496" height="17" font="4">that maps each ground clause to its assigned weight. Fix an MLN ¯</text>
<text top="667" left="592" width="218" height="15" font="4">F , then for any possible world</text>
<text top="687" left="108" width="702" height="15" font="4">(instance) I we say a ground clause g is violated if w(g) &gt; 0 and g is false in I or if w(g) &lt; 0 and</text>
<text top="708" left="108" width="702" height="15" font="4">g is true in I. We denote the set of ground clauses violated in a world I as V (I). The cost of the</text>
<text top="728" left="108" width="70" height="15" font="4">world I is</text>
<text top="748" left="380" width="67" height="15" font="4">cost(I) =</text>
<text top="772" left="451" width="41" height="11" font="5">g∈V (I)</text>
<text top="747" left="496" width="42" height="15" font="4">|w(g)|</text>
<text top="748" left="789" width="21" height="15" font="4">(1)</text>
<text top="797" left="108" width="670" height="17" font="4">Through cost, an MLN deﬁnes a probability distribution over all instances (denoted Inst) as:</text>
<text top="836" left="242" width="68" height="15" font="4">Pr[I] = Z</text>
<text top="831" left="311" width="16" height="11" font="5">−1</text>
<text top="836" left="331" width="191" height="15" font="4">exp {−cost(I)} where Z =</text>
<text top="859" left="527" width="38" height="11" font="5">J ∈Inst</text>
<text top="836" left="568" width="108" height="15" font="4">exp {−cost(J )}</text>
<text top="888" left="108" width="702" height="15" font="4">A lowest cost world I is called a most likely world. Since cost(I) ≥ 0, if cost(I) = 0 then I is a</text>
<text top="908" left="108" width="702" height="15" font="4">most likely world. On the other hand the most likely world may have positive cost. There are two</text>
<text top="929" left="108" width="702" height="17" font="4">main types of inference with MLNs: MAP inference, where we want to ﬁnd a most likely world,</text>
<text top="957" left="127" width="5" height="8" font="6">2</text>
<text top="960" left="133" width="677" height="14" font="7">In MLNs, it is not possible to give a direct probabilistic interpretation of weights [21]. In practice, the weights</text>
<text top="977" left="108" width="702" height="12" font="7">associated to formula are learned,which compensates for their non-intuitive nature. In this work, we do not discuss</text>
<text top="993" left="108" width="158" height="12" font="7">the mechanics of learning.</text>
<text top="1007" left="127" width="5" height="8" font="6">3</text>
<text top="1009" left="133" width="677" height="12" font="7">Clausal form is a disjunction of positive or negative literals. For example, the rule is R(a) =&gt; R(b) is not in</text>
<text top="1026" left="108" width="439" height="12" font="7">clausal form, but is equivalent to ¬R(a) ∨ R(b), which is in clausal form.</text>
<text top="1069" left="455" width="8" height="15" font="4">5</text>
</page>
<page number="6" position="absolute" top="0" left="0" height="1188" width="918">
<text top="113" left="108" width="702" height="17" font="4">and marginal inference, where we want to compute marginal probabilities. Tuffy is capable of</text>
<text top="133" left="108" width="702" height="15" font="4">both types of inference, but we present only MAP inference in the body of this paper. We refer</text>
<text top="154" left="108" width="368" height="15" font="4">the reader to §A.5 for details of marginal inference.</text>
<text top="196" left="108" width="26" height="16" font="1">2.3</text>
<text top="196" left="154" width="81" height="16" font="1">Inference</text>
<text top="228" left="108" width="702" height="17" font="4">We now describe the state of the art of inference for MLNs (as in Alchemy, the reference MLN</text>
<text top="249" left="108" width="122" height="15" font="4">implementation).</text>
<text top="292" left="108" width="88" height="15" font="4">Grounding</text>
<text top="292" left="213" width="597" height="17" font="4">Conceptually, to obtain the ground clauses of an MLN formula F , the most straight-</text>
<text top="312" left="108" width="702" height="15" font="4">forward way is to enumerate all possible assignments to the free variables in F . There have been</text>
<text top="333" left="108" width="702" height="15" font="4">several heuristics in the literature that improve the grounding process by pruning groundings that</text>
<text top="353" left="108" width="702" height="17" font="4">have no eﬀect on inference results; we describe the heuristics that Tuffy (and Alchemy) im-</text>
<text top="373" left="108" width="702" height="15" font="4">plements in §A.3. The set of ground clauses corresponds to a hypergraph where each atom is a</text>
<text top="394" left="108" width="702" height="15" font="4">node and each clause is a hyperedge. This graph structure is often called a Markov Random Field</text>
<text top="414" left="108" width="375" height="15" font="4">(MRF). We describe this structure formally in §A.2.</text>
<text top="457" left="108" width="54" height="15" font="4">Search</text>
<text top="457" left="179" width="631" height="17" font="4">Finding a most likely world of an MLN is a generalization of the (NP-hard) MaxSAT</text>
<text top="477" left="108" width="702" height="15" font="4">problem. In this paper we concentrate on one of the most popular heuristic search algorithms,</text>
<text top="498" left="108" width="702" height="17" font="4">WalkSAT [14], which is used by Alchemy. WalkSAT works by repeatedly selecting a random</text>
<text top="518" left="108" width="702" height="15" font="4">violated clause and “ﬁxing” it by ﬂipping (i.e., changing the truth value of) an atom in it (see</text>
<text top="538" left="108" width="702" height="15" font="4">§A.4). As with any heuristic search, we cannot be sure that we have achieved the optimal, and so</text>
<text top="559" left="108" width="702" height="15" font="4">the goal of any system that executes such a search procedure is: execute more search steps in the</text>
<text top="579" left="108" width="702" height="17" font="4">same amount of time. To keep the comparison with Alchemy fair, we only discuss WalkSAT in</text>
<text top="599" left="108" width="518" height="15" font="4">the body and defer our experience with other search algorithms to §C.1.</text>
<text top="643" left="108" width="174" height="15" font="4">Problem Description</text>
<text top="643" left="298" width="512" height="15" font="4">The primary challenge that we address in this paper is scaling both</text>
<text top="663" left="108" width="702" height="15" font="4">phases of MAP inference algorithms, grounding and search, using an RDBMS. Second, our goal</text>
<text top="683" left="108" width="702" height="15" font="4">is to improve the number of (eﬀective) steps of the local search procedure using parallelism and</text>
<text top="704" left="108" width="702" height="15" font="4">partitioning – but only when it provably improves the search quality. To achieve these goals,</text>
<text top="724" left="108" width="702" height="17" font="4">we attack three main technical challenges: (1) eﬃciently grounding large MLNs, (2) eﬃciently</text>
<text top="744" left="108" width="702" height="17" font="4">performing inference (search) on large MLNs, and (3) designing partitioning and partition-aware</text>
<text top="765" left="108" width="506" height="15" font="4">search algorithms that preserve (or enhance) search quality and speed.</text>
<text top="813" left="108" width="12" height="19" font="3">3</text>
<text top="813" left="144" width="149" height="19" font="3">Tuﬀy Systems</text>
<text top="853" left="108" width="702" height="15" font="4">In this section, we describe our technical contributions: a bottom-up grounding approach to fully</text>
<text top="873" left="108" width="702" height="15" font="4">leverage the RDBMS (§3.1); a hybrid main-memory RDBMS architecture to support eﬃcient end-</text>
<text top="893" left="108" width="702" height="15" font="4">to-end inference (§3.2). In §3.3 and §3.4 we discuss data partitioning which dramatically improves</text>
<text top="917" left="108" width="248" height="14" font="4">Tuffy’s space and time eﬃciency.</text>
<text top="956" left="108" width="26" height="16" font="1">3.1</text>
<text top="956" left="154" width="352" height="16" font="1">Grounding with a Bottom-up Approach</text>
<text top="988" left="108" width="702" height="17" font="4">We describe how Tuffy performs grounding. In contrast to top-down approaches (similar to</text>
<text top="1009" left="108" width="702" height="17" font="4">Prolog) that employ nested loops, Tuffy takes a bottom-up approach (similar to Datalog) and</text>
<text top="1069" left="455" width="8" height="15" font="4">6</text>
</page>
<page number="7" position="absolute" top="0" left="0" height="1188" width="918">
<text top="113" left="108" width="702" height="15" font="4">expresses grounding as a sequence of SQL queries. Each SQL query is optimized by the RDBMS,</text>
<text top="133" left="108" width="702" height="17" font="4">which allows Tuffy to complete the grounding process orders of magnitude more quickly than</text>
<text top="154" left="108" width="123" height="15" font="4">prior approaches.</text>
<text top="174" left="133" width="168" height="15" font="4">For each predicate P ( ¯</text>
<text top="174" left="289" width="360" height="17" font="4">A) in the input MLN, Tuffy creates a relation R</text>
<text top="180" left="649" width="8" height="11" font="5">P</text>
<text top="174" left="659" width="50" height="15" font="4">(aid, ¯</text>
<text top="174" left="697" width="113" height="15" font="4">A, truth) where</text>
<text top="194" left="108" width="77" height="15" font="4">each row a</text>
<text top="200" left="185" width="6" height="11" font="5">p</text>
<text top="194" left="198" width="407" height="15" font="4">represents an atom, aid is a globally unique identiﬁer, ¯</text>
<text top="194" left="593" width="217" height="15" font="4">A is the tuple of arguments of</text>
<text top="215" left="108" width="413" height="15" font="4">P , and truth is a three-valued attribute that indicates if a</text>
<text top="220" left="521" width="6" height="11" font="5">p</text>
<text top="215" left="533" width="277" height="15" font="4">is true or false (in the evidence), or not</text>
<text top="235" left="108" width="702" height="17" font="4">speciﬁed in the evidence. These tables form the input to grounding, and Tuffy constructs them</text>
<text top="255" left="108" width="284" height="15" font="4">using standard bulk-loading techniques.</text>
<text top="276" left="133" width="677" height="17" font="4">In Tuffy, we produce an output table C(cid, lits, weight) where each row corresponds to a</text>
<text top="296" left="108" width="702" height="15" font="4">single ground clause. Here, cid is the id of a ground clause, lits is an array that stores the atom</text>
<text top="316" left="108" width="702" height="15" font="4">id of each literal in this clause (and whether or not it is negated), and weight is the weight of</text>
<text top="337" left="108" width="702" height="15" font="4">this clause. We ﬁrst consider a formula without existential quantiﬁers. In this case, the formula</text>
<text top="357" left="108" width="179" height="15" font="4">F can be written as F (¯</text>
<text top="357" left="278" width="44" height="15" font="4">x) = l</text>
<text top="362" left="322" width="6" height="11" font="5">1</text>
<text top="356" left="333" width="58" height="15" font="4">∨ · · · ∨ l</text>
<text top="363" left="391" width="10" height="11" font="5">N</text>
<text top="357" left="409" width="57" height="15" font="4">where ¯</text>
<text top="357" left="457" width="353" height="17" font="4">x are all variables in F . Tuffy produces a SQL</text>
<text top="377" left="108" width="702" height="15" font="4">query Q for F that joins together the relations corresponding to the predicates in F to produce</text>
<text top="398" left="108" width="702" height="15" font="4">the atom ids of the ground clauses (and whether or not they are negated). The join conditions in</text>
<text top="418" left="108" width="702" height="15" font="4">Q enforce variable equality inside F , and incorporate the pruning strategies described in §A.3. For</text>
<text top="438" left="108" width="371" height="15" font="4">more details on the compilation procedure see §B.2.</text>
<text top="481" left="108" width="26" height="16" font="1">3.2</text>
<text top="481" left="154" width="321" height="16" font="1">A Hybrid Architecture for Inference</text>
<text top="513" left="108" width="702" height="17" font="4">Our initial prototype of Tuffy ran both grounding and search in the RDBMS. While the grounding</text>
<text top="533" left="108" width="702" height="15" font="4">phase described in the previous section had good performance and scalability, we found that search</text>
<text top="554" left="108" width="702" height="15" font="4">in an RDBMS is often a bottleneck. Thus, we design a hybrid architecture that allows eﬃcient</text>
<text top="574" left="108" width="702" height="15" font="4">in-memory search while retaining the performance beneﬁts of RDBMS-based grounding. To see</text>
<text top="594" left="108" width="702" height="15" font="4">why in-memory search is critical, recall that WalkSAT works by selecting an unsatisﬁed clause C,</text>
<text top="615" left="108" width="702" height="15" font="4">selecting an atom in C and “ﬂipping” that atom to satisfy C. Thus, WalkSAT performs a large</text>
<text top="635" left="108" width="702" height="15" font="4">number of random accesses to the data representing ground clauses and atoms. Moreover, the data</text>
<text top="655" left="108" width="702" height="15" font="4">that is accessed in one iteration depends on the data that is accessed in the previous iteration. And</text>
<text top="676" left="108" width="702" height="15" font="4">so, this access pattern prevents both eﬀective caching and parallelism, which causes a high overhead</text>
<text top="696" left="108" width="702" height="15" font="4">per data access. Thus, we implement a hybrid architecture where the RDBMS performs grounding</text>
<text top="716" left="108" width="702" height="17" font="4">and Tuffy is able to read the result of grounding from the RDBMS into memory and perform</text>
<text top="737" left="108" width="702" height="17" font="4">inference. If the grounding result is too large to ﬁt in memory, Tuffy invokes an implementation</text>
<text top="757" left="108" width="702" height="15" font="4">of search directly inside the RDBMS (§B.3). This approach is much less eﬃcient than in-memory</text>
<text top="777" left="108" width="702" height="15" font="4">search, but it runs on very large datasets without crashing. §B.4 illustrates the architecture of</text>
<text top="800" left="108" width="161" height="14" font="4">Tuffy in more detail.</text>
<text top="818" left="133" width="677" height="15" font="4">While it is clear that this hybrid approach is at least as scalable as a direct memory imple-</text>
<text top="838" left="108" width="702" height="17" font="4">mentation, such as Alchemy; in fact, there are cases where Tuffy can run in-memory search</text>
<text top="858" left="108" width="702" height="17" font="4">while Alchemy would crash. The reason is that the space requirement of a purely in-memory</text>
<text top="879" left="108" width="702" height="15" font="4">implementation is determined by the peak memory footprint throughout grounding and search,</text>
<text top="899" left="108" width="702" height="17" font="4">whereas Tuffy needs main memory only for search. For example, on a dataset called Relational</text>
<text top="919" left="108" width="702" height="17" font="4">Classiﬁcation (RC), Alchemy allocated 2.8 GB of RAM only to produce 4.8 MB of ground clauses.</text>
<text top="940" left="108" width="304" height="17" font="4">On RC, Tuffy uses only 19 MB of RAM.</text>
<text top="1069" left="455" width="8" height="15" font="4">7</text>
</page>
<page number="8" position="absolute" top="0" left="0" height="1188" width="918">
<text top="112" left="108" width="26" height="16" font="1">3.3</text>
<text top="112" left="154" width="328" height="16" font="1">Partitioning to Improve Performance</text>
<text top="144" left="108" width="702" height="17" font="4">In the following two sections, we study how to further improve Tuffy’s space and time eﬃciency</text>
<text top="164" left="108" width="702" height="15" font="4">without sacriﬁcing its scalability. The underlying idea is simple: we will try to partition the data.</text>
<text top="185" left="108" width="702" height="15" font="4">By splitting the problem into smaller pieces, we can reduce the memory footprint and introduce</text>
<text top="205" left="108" width="702" height="15" font="4">parallelism, which conceptually breaks the sequential nature of the search. These are expected</text>
<text top="225" left="108" width="702" height="15" font="4">beneﬁts of partitioning. An unexpected beneﬁt is an exponentially increase of the eﬀective search</text>
<text top="246" left="108" width="281" height="15" font="4">speed, a point that we return to below.</text>
<text top="266" left="133" width="677" height="17" font="4">First, observe that the logical forms of MLNs often result in an MRF with multiple disjoint</text>
<text top="286" left="108" width="702" height="15" font="4">components (see §B.5). For example, on the RC dataset there are 489 components. Let G be</text>
<text top="307" left="108" width="210" height="15" font="4">an MRF with components G</text>
<text top="312" left="318" width="6" height="11" font="5">1</text>
<text top="307" left="325" width="52" height="15" font="4">, · · · , G</text>
<text top="312" left="377" width="7" height="11" font="5">k</text>
<text top="307" left="385" width="396" height="15" font="4">; let I be a truth assignment to the atoms in G and I</text>
<text top="312" left="781" width="4" height="11" font="5">i</text>
<text top="307" left="793" width="17" height="15" font="4">its</text>
<text top="327" left="108" width="126" height="15" font="4">projection over G</text>
<text top="332" left="234" width="4" height="11" font="5">i</text>
<text top="327" left="239" width="183" height="15" font="4">. Then, it’s clear that ∀I:</text>
<text top="360" left="361" width="28" height="15" font="4">cost</text>
<text top="356" left="390" width="10" height="11" font="5">G</text>
<text top="360" left="400" width="38" height="15" font="4">(I) =</text>
<text top="383" left="443" width="37" height="11" font="5">1≤i≤k</text>
<text top="360" left="483" width="28" height="15" font="4">cost</text>
<text top="356" left="512" width="10" height="11" font="5">G</text>
<text top="360" left="522" width="4" height="8" font="6">i</text>
<text top="360" left="527" width="14" height="15" font="4">(I</text>
<text top="366" left="541" width="4" height="11" font="5">i</text>
<text top="360" left="546" width="11" height="15" font="4">).</text>
<text top="411" left="108" width="245" height="15" font="4">Hence, instead of minimizing cost</text>
<text top="408" left="353" width="10" height="11" font="5">G</text>
<text top="411" left="364" width="401" height="15" font="4">(I) directly, it suﬃces to minimize each individual cost</text>
<text top="408" left="765" width="10" height="11" font="5">G</text>
<text top="412" left="775" width="4" height="8" font="6">i</text>
<text top="411" left="780" width="14" height="15" font="4">(I</text>
<text top="416" left="794" width="4" height="11" font="5">i</text>
<text top="411" left="799" width="11" height="15" font="4">).</text>
<text top="431" left="108" width="590" height="15" font="4">The beneﬁt is that, even if G itself does not ﬁt in memory, it is possible that each G</text>
<text top="437" left="698" width="4" height="11" font="5">i</text>
<text top="431" left="708" width="102" height="15" font="4">does. As such,</text>
<text top="451" left="108" width="144" height="15" font="4">we can solve each G</text>
<text top="457" left="252" width="4" height="11" font="5">i</text>
<text top="451" left="262" width="530" height="15" font="4">with in-memory search one by one, and ﬁnally merge the results together.</text>
<text top="472" left="133" width="677" height="15" font="4">Component detection is done after the grounding phase and before the search phase, as follows.</text>
<text top="492" left="108" width="702" height="15" font="4">We maintain an in-memory union-ﬁnd structure over the nodes, and scan the clause table while</text>
<text top="512" left="108" width="702" height="15" font="4">updating the union-ﬁnd structure. The end result is the set of connected components in the MRF.</text>
<text top="533" left="108" width="423" height="15" font="4">An immediate issue raised by partitioning is I/O eﬃciency.</text>
<text top="575" left="108" width="182" height="15" font="4">Eﬃcient Data Loading</text>
<text top="575" left="306" width="504" height="15" font="4">Once an MRF is split into components, loading in and running inference</text>
<text top="596" left="108" width="702" height="15" font="4">on each component sequentially one by one may incur many I/O operations, as there may be many</text>
<text top="616" left="108" width="702" height="15" font="4">partitions. For example, the MRF of the Information Extraction (IE) dataset contains thousands</text>
<text top="636" left="108" width="702" height="15" font="4">of 2-cliques and 3-cliques. One solution is to group the components into batches. The goal is to</text>
<text top="656" left="108" width="702" height="15" font="4">minimize the total number of batches (and thereby the I/O cost of loading), and the constraint is</text>
<text top="677" left="108" width="702" height="15" font="4">that each batch cannot exceed the memory budget. This is essentially the bin packing problem,</text>
<text top="697" left="108" width="418" height="15" font="4">and we implement the First Fit Decreasing algorithm [28].</text>
<text top="717" left="133" width="677" height="17" font="4">Once the partitions are in memory, we can take advantage of parallelism. In Tuffy, we execute</text>
<text top="738" left="108" width="702" height="15" font="4">threads using a round-robin policy. It is future work to consider more advanced thread scheduling</text>
<text top="758" left="108" width="537" height="15" font="4">policies, such as the Gittins Index in the multi-armed bandit literature [10].</text>
<text top="801" left="108" width="61" height="15" font="4">Quality</text>
<text top="801" left="185" width="625" height="15" font="4">Although processing each component individually produces solutions that are no worse</text>
<text top="821" left="108" width="702" height="15" font="4">than processing the whole graph at once, we give an example to illustrate that independently</text>
<text top="841" left="108" width="558" height="15" font="4">processing each component may result in exponentially faster speed of search.</text>
<text top="874" left="108" width="702" height="15" font="4">Example 1 Consider an MRF consisting of N identical connected components each containing</text>
<text top="895" left="108" width="101" height="15" font="4">two atoms {X</text>
<text top="900" left="209" width="4" height="11" font="5">i</text>
<text top="895" left="214" width="17" height="15" font="4">, Y</text>
<text top="900" left="231" width="4" height="11" font="5">i</text>
<text top="894" left="236" width="205" height="15" font="4">} and three weighted clauses</text>
<text top="926" left="350" width="28" height="15" font="4">{(X</text>
<text top="932" left="378" width="4" height="11" font="5">i</text>
<text top="926" left="384" width="45" height="15" font="4">, 1), (Y</text>
<text top="932" left="428" width="4" height="11" font="5">i</text>
<text top="926" left="434" width="49" height="15" font="4">, 1), (X</text>
<text top="932" left="483" width="4" height="11" font="5">i</text>
<text top="926" left="491" width="24" height="15" font="4">∨ Y</text>
<text top="932" left="515" width="4" height="11" font="5">i</text>
<text top="926" left="520" width="47" height="15" font="4">, −1)},</text>
<text top="958" left="108" width="702" height="15" font="4">where i = 1 . . . N . Based on how WalkSAT works, it’s not hard to show that, if N = 1, starting</text>
<text top="979" left="108" width="343" height="15" font="4">from a random state, the expected hitting time</text>
<text top="976" left="451" width="6" height="11" font="5">4</text>
<text top="979" left="464" width="204" height="15" font="4">of the optimal state, i.e. (X</text>
<text top="984" left="668" width="6" height="11" font="5">1</text>
<text top="979" left="675" width="17" height="15" font="4">, Y</text>
<text top="984" left="691" width="6" height="11" font="5">1</text>
<text top="979" left="699" width="111" height="15" font="4">) = (1, 1), is no</text>
<text top="1007" left="127" width="5" height="8" font="6">4</text>
<text top="1009" left="133" width="677" height="12" font="7">The hitting time is a standard notion from Markov Chains [9], it is a random variable that represents the number</text>
<text top="1026" left="108" width="405" height="12" font="7">of steps taken by WalkSAT to reach an optimum for the ﬁrst time.</text>
<text top="1069" left="455" width="8" height="15" font="4">8</text>
</page>
<page number="9" position="absolute" top="0" left="0" height="1188" width="918">
<text top="126" left="415" width="20" height="15" font="2">G1 </text>
<text top="126" left="486" width="20" height="15" font="2">G2 </text>
<text top="119" left="456" width="10" height="13" font="7">e </text>
<text top="131" left="437" width="9" height="13" font="7">a </text>
<text top="131" left="475" width="10" height="13" font="7">b </text>
<text top="180" left="404" width="110" height="15" font="4">Figure 2: Ex. 2</text>
<text top="232" left="108" width="702" height="15" font="4">more than 4. Therefore, if we run WalkSAT on each component separately, the expected runtime</text>
<text top="252" left="108" width="702" height="15" font="4">of reaching the optimum is no more than 4N . Now consider the case where we run WalkSAT on</text>
<text top="273" left="108" width="702" height="15" font="4">the whole MRF. Intuitively, reaching the optimal state requires “ﬁxing” suboptimal components</text>
<text top="293" left="108" width="702" height="15" font="4">one by one. As the number of optimal components increases, however, it becomes more and more</text>
<text top="313" left="108" width="702" height="15" font="4">likely that one step of WalkSAT “breaks” an optimal component instead of ﬁxing a suboptimal</text>
<text top="334" left="108" width="702" height="15" font="4">component. Such check and balance makes it very diﬃcult for WalkSAT to reach the optimum.</text>
<text top="354" left="108" width="526" height="15" font="4">Indeed, calculation in §B.6 shows that the expected run time is at least 2</text>
<text top="351" left="634" width="10" height="11" font="5">N</text>
<text top="354" left="651" width="154" height="15" font="4">– an exponential gap!</text>
<text top="392" left="133" width="677" height="15" font="4">To generalize this example, we need some notations. Let G be an MRF with components</text>
<text top="413" left="108" width="13" height="15" font="4">G</text>
<text top="418" left="121" width="6" height="11" font="5">1</text>
<text top="413" left="128" width="49" height="15" font="4">, . . . , G</text>
<text top="418" left="177" width="10" height="11" font="5">N</text>
<text top="413" left="189" width="187" height="15" font="4">. For i = 1, . . . , N , let O</text>
<text top="418" left="376" width="4" height="11" font="5">i</text>
<text top="413" left="388" width="242" height="15" font="4">be the set of optimal states of G</text>
<text top="418" left="630" width="4" height="11" font="5">i</text>
<text top="413" left="635" width="55" height="15" font="4">, and S</text>
<text top="418" left="690" width="4" height="11" font="5">i</text>
<text top="413" left="702" width="108" height="15" font="4">the set of non-</text>
<text top="433" left="108" width="138" height="15" font="4">optimal states of G</text>
<text top="439" left="246" width="4" height="11" font="5">i</text>
<text top="433" left="256" width="280" height="15" font="4">that diﬀer only by one bit from some x</text>
<text top="429" left="536" width="6" height="11" font="5">∗</text>
<text top="432" left="547" width="28" height="15" font="4">∈ O</text>
<text top="439" left="575" width="4" height="11" font="5">i</text>
<text top="433" left="580" width="44" height="15" font="4">; let P</text>
<text top="439" left="624" width="4" height="11" font="5">i</text>
<text top="433" left="629" width="181" height="15" font="4">(x → y) be the transition</text>
<text top="453" left="108" width="273" height="15" font="4">probability of WalkSAT running on G</text>
<text top="459" left="381" width="4" height="11" font="5">i</text>
<text top="453" left="386" width="424" height="15" font="4">, i.e., the probability that one step of WalkSAT would take</text>
<text top="474" left="108" width="13" height="15" font="4">G</text>
<text top="479" left="121" width="4" height="11" font="5">i</text>
<text top="474" left="132" width="256" height="15" font="4">from x to y. Let x be a state of G</text>
<text top="479" left="388" width="4" height="11" font="5">i</text>
<text top="474" left="394" width="96" height="15" font="4">, denote by v</text>
<text top="479" left="490" width="4" height="11" font="5">i</text>
<text top="474" left="495" width="289" height="15" font="4">(x) the number of violated clauses in G</text>
<text top="479" left="784" width="4" height="11" font="5">i</text>
<text top="474" left="795" width="15" height="15" font="4">at</text>
<text top="494" left="108" width="101" height="15" font="4">state x; deﬁne</text>
<text top="516" left="289" width="10" height="15" font="4">α</text>
<text top="521" left="299" width="4" height="11" font="5">i</text>
<text top="516" left="304" width="39" height="15" font="4">(x) =</text>
<text top="539" left="348" width="25" height="11" font="5">y∈O</text>
<text top="543" left="373" width="4" height="8" font="6">i</text>
<text top="516" left="381" width="11" height="15" font="4">P</text>
<text top="521" left="391" width="4" height="11" font="5">i</text>
<text top="516" left="396" width="77" height="15" font="4">(x → y), β</text>
<text top="521" left="473" width="4" height="11" font="5">i</text>
<text top="516" left="479" width="39" height="15" font="4">(x) =</text>
<text top="539" left="522" width="23" height="11" font="5">y∈S</text>
<text top="543" left="545" width="4" height="8" font="6">i</text>
<text top="516" left="553" width="11" height="15" font="4">P</text>
<text top="521" left="563" width="4" height="11" font="5">i</text>
<text top="516" left="568" width="61" height="15" font="4">(x → y).</text>
<text top="563" left="108" width="357" height="15" font="4">For any non-empty subset H ⊆ {1, . . . , N }, deﬁne</text>
<text top="609" left="330" width="53" height="15" font="4">r(H) =</text>
<text top="597" left="392" width="27" height="15" font="4">min</text>
<text top="603" left="419" width="23" height="11" font="5">i∈H</text>
<text top="597" left="447" width="27" height="15" font="4">min</text>
<text top="603" left="474" width="25" height="11" font="5">x∈O</text>
<text top="607" left="499" width="4" height="8" font="6">i</text>
<text top="597" left="507" width="8" height="15" font="4">v</text>
<text top="603" left="515" width="4" height="11" font="5">i</text>
<text top="597" left="520" width="31" height="15" font="4">(x)β</text>
<text top="603" left="552" width="4" height="11" font="5">i</text>
<text top="597" left="557" width="22" height="15" font="4">(x)</text>
<text top="620" left="389" width="30" height="15" font="4">max</text>
<text top="625" left="419" width="23" height="11" font="5">i∈H</text>
<text top="620" left="447" width="30" height="15" font="4">max</text>
<text top="625" left="478" width="23" height="11" font="5">x∈S</text>
<text top="629" left="501" width="4" height="8" font="6">i</text>
<text top="620" left="509" width="8" height="15" font="4">v</text>
<text top="625" left="517" width="4" height="11" font="5">i</text>
<text top="620" left="522" width="33" height="15" font="4">(x)α</text>
<text top="625" left="555" width="4" height="11" font="5">i</text>
<text top="620" left="560" width="22" height="15" font="4">(x)</text>
<text top="609" left="584" width="5" height="15" font="4">.</text>
<text top="654" left="108" width="702" height="15" font="4">Theorem 3.1. Let H be any non-empty subset of {1, . . . , N } s.t. r = r(H) &gt; 0, then Whole-</text>
<text top="675" left="108" width="271" height="15" font="4">MRF WalkSAT on G takes at least 2</text>
<text top="671" left="379" width="63" height="11" font="5">|H|r/(2+r)</text>
<text top="675" left="450" width="360" height="15" font="4">more steps than component-wise WalkSAT on the</text>
<text top="695" left="108" width="125" height="15" font="4">components of G.</text>
<text top="729" left="108" width="241" height="15" font="4">The proof can be found in §B.6.</text>
<text top="729" left="374" width="436" height="15" font="4">In the worst case, r = 0 – i.e., WalkSAT never jumps out</text>
<text top="749" left="108" width="635" height="15" font="4">of an optimal state in all components – and partitioning would become pure overhead.</text>
<text top="749" left="764" width="46" height="15" font="4">On an</text>
<text top="769" left="108" width="702" height="15" font="4">information extraction (IE) benchmark dataset, there is some H with |H| = 1196 and r(H) = 0.5.</text>
<text top="790" left="108" width="290" height="15" font="4">Thus, the gap on this dataset is at least 2</text>
<text top="787" left="398" width="19" height="11" font="5">200</text>
<text top="789" left="422" width="34" height="15" font="4">≈ 10</text>
<text top="787" left="456" width="13" height="11" font="5">60</text>
<text top="790" left="469" width="341" height="17" font="4">. In practice, this explains why Tuffy produces</text>
<text top="810" left="108" width="702" height="17" font="4">lower cost solutions in minutes than non-partition aware approaches such as Alchemy produce</text>
<text top="830" left="108" width="112" height="15" font="4">even after days.</text>
<text top="873" left="108" width="26" height="16" font="1">3.4</text>
<text top="873" left="154" width="242" height="16" font="1">Further Partitioning MRFs</text>
<text top="905" left="108" width="702" height="15" font="4">Although our algorithms are more scalable than prior approaches, if the largest component does</text>
<text top="925" left="108" width="702" height="15" font="4">not ﬁt in memory then we are forced to run the in-RDBMS version of inference, which is much</text>
<text top="946" left="108" width="702" height="15" font="4">slower. Intuitively, if the graph is only weakly connected, then we should still be able to get the</text>
<text top="966" left="108" width="576" height="15" font="4">exponential speed up of partitioning. To gain intuition, we consider an example.</text>
<text top="1000" left="108" width="540" height="15" font="4">Example 2 Consider an MRF consisting of two equally sized subgraphs G</text>
<text top="1005" left="648" width="6" height="11" font="5">1</text>
<text top="1000" left="660" width="44" height="15" font="4">and G</text>
<text top="1005" left="704" width="6" height="11" font="5">2</text>
<text top="1000" left="711" width="99" height="15" font="4">, plus an edge</text>
<text top="1020" left="108" width="655" height="15" font="4">e = (a, b) between them (Figure 2). Suppose that the expected hitting time of WalkSAT on G</text>
<text top="1026" left="763" width="4" height="11" font="5">i</text>
<text top="1020" left="772" width="29" height="15" font="4">is H</text>
<text top="1026" left="800" width="4" height="11" font="5">i</text>
<text top="1020" left="805" width="5" height="15" font="4">.</text>
<text top="1069" left="455" width="8" height="15" font="4">9</text>
</page>
<page number="10" position="absolute" top="0" left="0" height="1188" width="918">
<text top="113" left="108" width="56" height="15" font="4">Since H</text>
<text top="119" left="164" width="6" height="11" font="5">1</text>
<text top="113" left="177" width="45" height="15" font="4">and H</text>
<text top="119" left="222" width="6" height="11" font="5">2</text>
<text top="113" left="235" width="575" height="15" font="4">are essentially independent, the hitting time of WalkSAT on G could be roughly</text>
<text top="133" left="108" width="14" height="15" font="4">H</text>
<text top="139" left="122" width="6" height="11" font="5">1</text>
<text top="133" left="129" width="14" height="15" font="4">H</text>
<text top="139" left="142" width="6" height="11" font="5">2</text>
<text top="133" left="149" width="661" height="15" font="4">. On the other hand, consider the following scheme: enumerate all possible truth assignments</text>
<text top="154" left="108" width="702" height="15" font="4">to one of the boundary variables {a, b}, say a – of which there are two – and conditioning on each</text>
<text top="174" left="108" width="236" height="15" font="4">assignment, run WalkSAT on G</text>
<text top="180" left="344" width="6" height="11" font="5">1</text>
<text top="174" left="358" width="46" height="15" font="4">and G</text>
<text top="180" left="404" width="6" height="11" font="5">2</text>
<text top="174" left="418" width="392" height="15" font="4">independently. Clearly, the overall hitting time is no</text>
<text top="194" left="108" width="109" height="15" font="4">more than 2(H</text>
<text top="200" left="217" width="6" height="11" font="5">1</text>
<text top="194" left="228" width="30" height="15" font="4">+ H</text>
<text top="200" left="258" width="6" height="11" font="5">2</text>
<text top="194" left="265" width="284" height="15" font="4">), which is a huge improvement over H</text>
<text top="200" left="549" width="6" height="11" font="5">1</text>
<text top="194" left="556" width="14" height="15" font="4">H</text>
<text top="200" left="569" width="6" height="11" font="5">2</text>
<text top="194" left="583" width="54" height="15" font="4">since H</text>
<text top="200" left="637" width="4" height="11" font="5">i</text>
<text top="194" left="648" width="162" height="15" font="4">is usually a high-order</text>
<text top="215" left="108" width="339" height="15" font="4">polynomial or even exponential in the size of G</text>
<text top="220" left="447" width="4" height="11" font="5">i</text>
<text top="215" left="452" width="5" height="15" font="4">.</text>
<text top="248" left="133" width="677" height="15" font="4">To capitalize on this idea, we need to address two challenges: 1) designing an eﬃcient MRF</text>
<text top="269" left="108" width="702" height="15" font="4">partitioning algorithm; and 2) designing an eﬀective partition-aware search algorithm. We address</text>
<text top="289" left="108" width="152" height="15" font="4">each of them in turn.</text>
<text top="332" left="108" width="150" height="15" font="4">MRF Partitioning</text>
<text top="332" left="274" width="536" height="15" font="4">Intuitively, to maximally utilize the memory budget, we want to partition</text>
<text top="353" left="108" width="702" height="15" font="4">the MRF into roughly equal sizes; to minimize information loss, we want to minimize total weight</text>
<text top="373" left="108" width="702" height="15" font="4">of clauses that span over multiple partitions, i.e., the cut size. To capture this notion, we deﬁne a</text>
<text top="393" left="108" width="504" height="15" font="4">balanced bisection of a hypergraph G = (V, E) as a partition of V = V</text>
<text top="399" left="612" width="6" height="11" font="5">1</text>
<text top="392" left="623" width="24" height="15" font="4">∪ V</text>
<text top="399" left="647" width="6" height="11" font="5">2</text>
<text top="393" left="660" width="86" height="15" font="4">such that |V</text>
<text top="399" left="746" width="6" height="11" font="5">1</text>
<text top="392" left="753" width="40" height="15" font="4">| = |V</text>
<text top="399" left="794" width="6" height="11" font="5">2</text>
<text top="392" left="801" width="9" height="15" font="4">|.</text>
<text top="414" left="108" width="184" height="15" font="4">The cost of a bisection (V</text>
<text top="419" left="292" width="6" height="11" font="5">1</text>
<text top="414" left="299" width="17" height="15" font="4">, V</text>
<text top="419" left="316" width="6" height="11" font="5">2</text>
<text top="414" left="323" width="122" height="15" font="4">) is |{e ∈ E|e ∩ V</text>
<text top="419" left="444" width="6" height="11" font="5">1</text>
<text top="414" left="456" width="98" height="15" font="4">= ∅ and e ∩ V</text>
<text top="419" left="554" width="6" height="11" font="5">2</text>
<text top="414" left="566" width="43" height="15" font="4">= ∅}|.</text>
<text top="447" left="108" width="702" height="15" font="4">Theorem 3.2. Consider the MLN Γ given by the single rule p(x), r(x, y) → p(y) where r is an</text>
<text top="468" left="108" width="702" height="15" font="4">evidence predicate. Then, the problem of ﬁnding a minimum-cost balanced bisection of the MRF</text>
<text top="488" left="108" width="462" height="15" font="4">that results from Γ is NP-hard in the size of the evidence (data).</text>
<text top="522" left="108" width="702" height="15" font="4">The proof (§B.7) is by reduction to the graph minimum bisection problem [15], which is hard</text>
<text top="542" left="108" width="702" height="15" font="4">to approximate (unless P = NP, there is no PTAS). In fact, the problem we are facing (multi-</text>
<text top="562" left="108" width="702" height="15" font="4">way hypergraph partitioning) is more challenging than graph bisection, and has been extensively</text>
<text top="583" left="108" width="702" height="15" font="4">studied [13, 25]. And so, we design a simple, greedy partitioning algorithm: it assigns each clause</text>
<text top="603" left="108" width="702" height="15" font="4">to a bin in descending order by clause weight, subject to the constraint that no component in the</text>
<text top="623" left="108" width="609" height="15" font="4">resulting graph is larger than an input parameter β. We include pseudocode in §B.8.</text>
<text top="666" left="108" width="188" height="15" font="4">Partition-aware Search</text>
<text top="666" left="313" width="497" height="15" font="4">We need to reﬁne the search procedure to be aware of partitions: the</text>
<text top="687" left="108" width="702" height="15" font="4">central challenge is that a clause in the cut may depend on atoms in two distinct partitions. Hence,</text>
<text top="707" left="108" width="702" height="15" font="4">there are dependencies between the partitions. We exploit the idea in Example 2 to design the</text>
<text top="727" left="108" width="702" height="15" font="4">following partition-aware search scheme – which is an instance of the Gauss-Seidel method from</text>
<text top="748" left="108" width="347" height="15" font="4">nonlinear optimization [3, pg. 219]. Denote by X</text>
<text top="753" left="455" width="6" height="11" font="5">1</text>
<text top="748" left="462" width="50" height="15" font="4">, . . . , X</text>
<text top="753" left="512" width="7" height="11" font="5">k</text>
<text top="748" left="525" width="285" height="15" font="4">the states (i.e., truth assignments to the</text>
<text top="768" left="108" width="303" height="15" font="4">atoms) of the partitions. First initialize X</text>
<text top="774" left="411" width="4" height="11" font="5">i</text>
<text top="768" left="421" width="27" height="15" font="4">= x</text>
<text top="765" left="448" width="6" height="11" font="5">0</text>
<text top="776" left="448" width="4" height="11" font="5">i</text>
<text top="768" left="461" width="349" height="15" font="4">for i = 1 . . . k. For t = 1 . . . T , for i = 1 . . . k, run</text>
<text top="788" left="108" width="107" height="15" font="4">WalkSAT on x</text>
<text top="785" left="215" width="21" height="11" font="5">t−1</text>
<text top="796" left="215" width="4" height="11" font="5">i</text>
<text top="788" left="243" width="129" height="15" font="4">conditioned on {x</text>
<text top="786" left="372" width="5" height="11" font="5">t</text>
<text top="796" left="372" width="5" height="11" font="5">j</text>
<text top="788" left="379" width="118" height="15" font="4">|1 ≤ j &lt; i} ∪ {x</text>
<text top="785" left="496" width="21" height="11" font="5">t−1</text>
<text top="796" left="496" width="5" height="11" font="5">j</text>
<text top="788" left="518" width="169" height="15" font="4">|i &lt; j ≤ k} to obtain x</text>
<text top="786" left="687" width="5" height="11" font="5">t</text>
<text top="796" left="687" width="4" height="11" font="5">i</text>
<text top="788" left="693" width="117" height="15" font="4">. Finally, return</text>
<text top="810" left="108" width="18" height="15" font="4">{x</text>
<text top="808" left="126" width="7" height="11" font="5">T</text>
<text top="819" left="126" width="4" height="11" font="5">i</text>
<text top="810" left="135" width="84" height="15" font="4">|1 ≤ i ≤ k}.</text>
<text top="859" left="108" width="12" height="19" font="3">4</text>
<text top="859" left="144" width="133" height="19" font="3">Experiments</text>
<text top="899" left="108" width="702" height="17" font="4">In this section, we validate ﬁrst that our system Tuffy is orders of magnitude more scalable and</text>
<text top="920" left="108" width="702" height="15" font="4">eﬃcient than prior approaches. We then validate that each of our techniques contributes to the</text>
<text top="940" left="108" width="34" height="15" font="4">goal.</text>
<text top="983" left="108" width="163" height="15" font="4">Experimental Setup</text>
<text top="983" left="288" width="522" height="17" font="4">We select Alchemy, the currently most widely used MLN system, as our</text>
<text top="1003" left="108" width="702" height="17" font="4">comparison point. Alchemy and Tuffy are implemented in C++ and Java, respectively. The</text>
<text top="1024" left="108" width="702" height="17" font="4">RDBMS used by Tuffy is PostgreSQL 8.4. Unless speciﬁed otherwise, all experiments are run</text>
<text top="1069" left="451" width="16" height="15" font="4">10</text>
</page>
<page number="11" position="absolute" top="0" left="0" height="1188" width="918">
<text top="113" left="108" width="702" height="15" font="4">on an Intel Core2 at 2.4GHz with 4 GB of RAM running Red Hat Enterprise Linux 5. For fair</text>
<text top="133" left="108" width="594" height="17" font="4">comparison, in all experiments Tuffy runs a single thread unless otherwise noted.</text>
<text top="177" left="108" width="71" height="15" font="4">Datasets</text>
<text top="177" left="195" width="615" height="17" font="4">We run Alchemy and Tuffy on four datasets; three of them (including their MLNs)</text>
<text top="197" left="108" width="702" height="17" font="4">are taken directly from the Alchemy website [7]: Link Prediction (LP), given an administrative</text>
<text top="217" left="108" width="702" height="15" font="4">database of a CS department, the goal is to predict student-adviser relationships; Information</text>
<text top="238" left="108" width="702" height="15" font="4">Extraction (IE), given a set of Citeseer citations, the goal is to extract from them structured records</text>
<text top="258" left="108" width="702" height="15" font="4">based on some domain-speciﬁc heuristics; and Entity Resolution (ER), which is to deduplicate</text>
<text top="278" left="108" width="702" height="15" font="4">citation records based on word similarity. These tasks have been extensively used in prior work.</text>
<text top="299" left="108" width="702" height="15" font="4">The last task, Relational Classiﬁcation (RC), performs classiﬁcation on the Cora dataset [16]; RC</text>
<text top="319" left="108" width="548" height="15" font="4">contains all the rules in Figure 1. Table 1 contains statistics about the data.</text>
<text top="354" left="436" width="22" height="13" font="2">LP</text>
<text top="354" left="499" width="18" height="13" font="2">IE</text>
<text top="354" left="551" width="25" height="13" font="2">RC</text>
<text top="354" left="601" width="24" height="13" font="2">ER</text>
<text top="373" left="293" width="68" height="13" font="2">#relations</text>
<text top="373" left="443" width="15" height="13" font="2">22</text>
<text top="373" left="502" width="15" height="13" font="2">18</text>
<text top="373" left="568" width="7" height="13" font="2">4</text>
<text top="373" left="610" width="15" height="13" font="2">10</text>
<text top="391" left="293" width="43" height="13" font="2">#rules</text>
<text top="391" left="443" width="15" height="13" font="2">94</text>
<text top="391" left="498" width="19" height="13" font="2">1K</text>
<text top="391" left="561" width="15" height="13" font="2">15</text>
<text top="391" left="594" width="31" height="13" font="2">3.8K</text>
<text top="409" left="293" width="59" height="13" font="2">#entities</text>
<text top="409" left="435" width="22" height="13" font="2">302</text>
<text top="409" left="486" width="31" height="13" font="2">2.6K</text>
<text top="409" left="549" width="27" height="13" font="2">51K</text>
<text top="409" left="602" width="22" height="13" font="2">510</text>
<text top="426" left="293" width="112" height="13" font="2">#evidence tuples</text>
<text top="426" left="435" width="22" height="13" font="2">731</text>
<text top="426" left="476" width="40" height="13" font="2">0.25M</text>
<text top="426" left="535" width="40" height="13" font="2">0.43M</text>
<text top="426" left="602" width="22" height="13" font="2">676</text>
<text top="444" left="293" width="93" height="13" font="2">#query atoms</text>
<text top="444" left="427" width="31" height="13" font="2">4.6K</text>
<text top="444" left="476" width="40" height="13" font="2">0.34M</text>
<text top="444" left="549" width="27" height="13" font="2">10K</text>
<text top="444" left="598" width="27" height="13" font="2">16K</text>
<text top="462" left="293" width="90" height="13" font="2">#components</text>
<text top="462" left="450" width="7" height="13" font="2">1</text>
<text top="462" left="487" width="30" height="13" font="2">5341</text>
<text top="462" left="553" width="22" height="13" font="2">489</text>
<text top="462" left="617" width="7" height="13" font="2">1</text>
<text top="498" left="365" width="189" height="15" font="4">Table 1: Dataset statistics</text>
<text top="562" left="108" width="26" height="16" font="1">4.1</text>
<text top="562" left="154" width="207" height="16" font="1">High-level Performance</text>
<text top="594" left="108" width="702" height="17" font="4">We empirically demonstrate that Tuffy with all the techniques we have described has faster</text>
<text top="614" left="108" width="702" height="15" font="4">grounding, higher search speed, lower memory usage, and in some cases produces much better</text>
<text top="634" left="108" width="702" height="17" font="4">solutions than a competitor main memory approach, Alchemy. Recall that the name of the game</text>
<text top="655" left="108" width="702" height="17" font="4">is to produce low-cost solutions quickly. With this in mind, we run Tuffy and Alchemy on each</text>
<text top="675" left="108" width="702" height="15" font="4">dataset for 7500 seconds, and track the cost of the best solution found up to any moment; on</text>
<text top="695" left="108" width="702" height="15" font="4">datasets that have multiple components, namely IE and RC, we apply the partitioning strategy</text>
<text top="715" left="108" width="702" height="17" font="4">in §3.3 on Tuffy. As shown in Figure 3, Tuffy often reaches a best solution within orders of</text>
<text top="736" left="108" width="702" height="17" font="4">magnitude less time than Alchemy; secondly, the result quality of Tuffy is at least as good as –</text>
<text top="756" left="108" width="702" height="17" font="4">sometimes substantially better (e.g., on IE and RC) than – Alchemy. Here, we have zoomed the</text>
<text top="776" left="108" width="702" height="15" font="4">time axes into interesting areas. Since “solution cost” is undeﬁned during grounding, each curve</text>
<text top="797" left="108" width="702" height="15" font="4">begins only when grounding is completed. We analyze the experiment results in more details in</text>
<text top="817" left="108" width="157" height="15" font="4">the following sections.</text>
<text top="860" left="108" width="26" height="16" font="1">4.2</text>
<text top="860" left="154" width="278" height="16" font="1">Eﬀect of Bottom-up Grounding</text>
<text top="892" left="108" width="702" height="17" font="4">We validate that the RDBMS-based grounding approach in Tuffy allows us to complete the</text>
<text top="912" left="108" width="702" height="17" font="4">grounding process orders of magnitude more eﬃciently than Alchemy. To make this point, we</text>
<text top="932" left="108" width="702" height="17" font="4">run Tuffy and Alchemy on the four datasets, and show their grounding time in Table 2. We can</text>
<text top="953" left="108" width="702" height="17" font="4">see that Tuffy outperforms Alchemy by orders of magnitude at run time in the grounding phase</text>
<text top="973" left="108" width="702" height="15" font="4">(a factor of 225 on the ER dataset). To understand the diﬀerences, we dug deeper with a lesion</text>
<text top="993" left="108" width="702" height="15" font="4">study, and found that sort join and hash join algorithms (along with predicate pushdown) are the</text>
<text top="1014" left="108" width="702" height="17" font="4">key components of the RDBMS that speeds up the grounding process of Tuffy (§C.2). Tuffy</text>
<text top="1069" left="451" width="16" height="15" font="4">11</text>
</page>
<page number="12" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="9" size="11" family="Times" color="#000000"/>
	<fontspec id="10" size="12" family="Times" color="#000000"/>
	<fontspec id="11" size="14" family="Times" color="#000000"/>
<text top="182" left="471" width="44" height="13" font="9"><b>1.0E+03</b></text>
<text top="150" left="471" width="44" height="13" font="9"><b>2.0E+03</b></text>
<text top="117" left="471" width="44" height="13" font="9"><b>3.0E+03</b></text>
<text top="200" left="524" width="7" height="13" font="9"><b>0</b></text>
<text top="200" left="582" width="13" height="13" font="9"><b>20</b></text>
<text top="200" left="645" width="13" height="13" font="9"><b>40</b></text>
<text top="157" left="465" width="0" height="15" font="10"><b>co</b></text>
<text top="143" left="465" width="0" height="15" font="10"><b>st</b></text>
<text top="132" left="465" width="0" height="15" font="10"><b> </b></text>
<text top="117" left="607" width="16" height="17" font="11"><b>IE </b></text>
<text top="132" left="619" width="62" height="17" font="4">Alchemy </text>
<text top="172" left="555" width="38" height="17" font="4">Tuffy </text>
<text top="183" left="241" width="44" height="13" font="9"><b>0.0E+00</b></text>
<text top="161" left="241" width="44" height="13" font="9"><b>1.0E+04</b></text>
<text top="139" left="241" width="44" height="13" font="9"><b>2.0E+04</b></text>
<text top="117" left="241" width="44" height="13" font="9"><b>3.0E+04</b></text>
<text top="200" left="294" width="7" height="13" font="9"><b>0</b></text>
<text top="200" left="363" width="13" height="13" font="9"><b>50</b></text>
<text top="200" left="433" width="20" height="13" font="9"><b>100</b></text>
<text top="158" left="235" width="0" height="15" font="10"><b>cos</b></text>
<text top="137" left="235" width="0" height="15" font="10"><b>t </b></text>
<text top="120" left="342" width="20" height="17" font="11"><b>LP </b></text>
<text top="142" left="380" width="62" height="17" font="4">Alchemy </text>
<text top="142" left="321" width="38" height="17" font="4">Tuffy </text>
<text top="287" left="470" width="44" height="13" font="9"><b>0.0E+00</b></text>
<text top="254" left="470" width="44" height="13" font="9"><b>1.0E+05</b></text>
<text top="222" left="470" width="44" height="13" font="9"><b>2.0E+05</b></text>
<text top="304" left="523" width="7" height="13" font="9"><b>0</b></text>
<text top="304" left="551" width="142" height="13" font="9"><b>2000 4000 6000 8000</b></text>
<text top="262" left="464" width="0" height="15" font="10"><b>cos</b></text>
<text top="242" left="464" width="0" height="15" font="10"><b>t </b></text>
<text top="220" left="602" width="21" height="17" font="11"><b>ER </b></text>
<text top="242" left="535" width="163" height="13" font="7">Alchemy grounding took 7 hr. </text>
<text top="258" left="585" width="38" height="17" font="4">Tuffy </text>
<text top="287" left="241" width="44" height="13" font="9"><b>0.0E+00</b></text>
<text top="265" left="241" width="44" height="13" font="9"><b>2.0E+03</b></text>
<text top="244" left="241" width="44" height="13" font="9"><b>4.0E+03</b></text>
<text top="222" left="241" width="44" height="13" font="9"><b>6.0E+03</b></text>
<text top="304" left="294" width="7" height="13" font="9"><b>0</b></text>
<text top="304" left="325" width="27" height="13" font="9"><b>2000</b></text>
<text top="304" left="367" width="27" height="13" font="9"><b>4000</b></text>
<text top="304" left="409" width="27" height="13" font="9"><b>6000</b></text>
<text top="262" left="235" width="0" height="15" font="10"><b>cos</b></text>
<text top="242" left="235" width="0" height="15" font="10"><b>t </b></text>
<text top="224" left="341" width="22" height="17" font="11"><b>RC </b></text>
<text top="242" left="385" width="62" height="17" font="4">Alchemy </text>
<text top="254" left="330" width="38" height="17" font="4">Tuffy </text>
<text top="347" left="183" width="552" height="17" font="4">Figure 3: Time-cost plots of Alchemy vs. Tuffy; the x axes are time (sec)</text>
<text top="400" left="108" width="702" height="17" font="4">obviates the need for Alchemy to reimplement all of the optimization techniques in an RDBMS</text>
<text top="420" left="108" width="94" height="15" font="4">from scratch.</text>
<text top="453" left="416" width="24" height="15" font="4">LP</text>
<text top="453" left="458" width="20" height="15" font="4">IE</text>
<text top="453" left="506" width="27" height="15" font="4">RC</text>
<text top="453" left="571" width="26" height="15" font="4">ER</text>
<text top="476" left="320" width="73" height="14" font="4">Alchemy</text>
<text top="474" left="423" width="16" height="15" font="4">48</text>
<text top="474" left="461" width="16" height="15" font="4">13</text>
<text top="474" left="496" width="37" height="15" font="4">3,913</text>
<text top="474" left="552" width="45" height="15" font="4">23,891</text>
<text top="497" left="332" width="50" height="14" font="4">Tuffy</text>
<text top="494" left="432" width="8" height="15" font="4">6</text>
<text top="494" left="461" width="16" height="15" font="4">13</text>
<text top="494" left="517" width="16" height="15" font="4">40</text>
<text top="494" left="573" width="25" height="15" font="4">106</text>
<text top="532" left="350" width="218" height="15" font="4">Table 2: Grounding time (sec)</text>
<text top="599" left="108" width="26" height="16" font="1">4.3</text>
<text top="599" left="154" width="261" height="16" font="1">Eﬀect of Hybrid Architecture</text>
<text top="631" left="108" width="702" height="17" font="4">We validate two technical claims: (1) the hybrid memory management strategy of Tuffy (even</text>
<text top="651" left="108" width="702" height="15" font="4">without our partitioning optimizations) has comparable search rates to existing main memory</text>
<text top="671" left="108" width="702" height="17" font="4">implementations (and much faster than RDBMS-based implementation) and (2) Tuffy maintains</text>
<text top="692" left="108" width="702" height="15" font="4">a much smaller memory footprint (again without partitioning). Thus, we compare three approaches:</text>
<text top="712" left="108" width="702" height="17" font="4">(1) Tuffy without the partitioning optimizations, called Tuffy-p (read: Tuﬀy minus p), (2) a</text>
<text top="732" left="108" width="702" height="17" font="4">version of Tuffy (also without partitioning) that implements RDBMS-based WalkSAT (detailed</text>
<text top="752" left="108" width="296" height="17" font="4">in §B.3), Tuffy-mm, and (3) Alchemy.</text>
<text top="773" left="133" width="677" height="15" font="4">Figure 4 illustrates the time-cost plots on LP and RC of all three approaches. We see from</text>
<text top="793" left="108" width="702" height="17" font="4">RC that Tuffy-p is able to ground much more quickly than Alchemy (40s compared to 3913s).</text>
<text top="813" left="108" width="702" height="17" font="4">Additionally, we see that, compared to Tuffy-mm, Tuffy-p’s in-memory search is orders of</text>
<text top="834" left="108" width="702" height="15" font="4">magnitude faster at getting to their best reported solution (both approaches ﬁnish grounding at</text>
<text top="854" left="108" width="702" height="15" font="4">the same time, and so start search at the same time). To understand why, we measure the ﬂipping</text>
<text top="874" left="108" width="702" height="15" font="4">rate, which is the number of steps performed by WalkSAT per second. As shown in Table 3, the</text>
<text top="895" left="108" width="702" height="17" font="4">reason is that Tuffy-mm has a dramatically lower ﬂipping rate. We discuss the performance</text>
<text top="915" left="108" width="433" height="15" font="4">bound of any RDBMS-based search implementation in §C.1.</text>
<text top="935" left="133" width="677" height="17" font="4">To validate our second claim, that Tuffy-p has a smaller memory footprint, we see in Table 4,</text>
<text top="956" left="108" width="702" height="17" font="4">that on all datasets, the memory footprint of Tuffy is no more than 5% of Alchemy. Drilling</text>
<text top="976" left="108" width="702" height="17" font="4">down, the reason is that the intermediate state size of Alchemy’s grounding process may be larger</text>
<text top="996" left="108" width="702" height="17" font="4">than the size of grounding results. For example, on the RC dataset, Alchemy allocated 2.8 GB</text>
<text top="1017" left="108" width="702" height="17" font="4">of RAM only to produce 4.8 MB of ground clauses. While Alchemy has to hold everything in</text>
<text top="1069" left="451" width="16" height="15" font="4">12</text>
</page>
<page number="13" position="absolute" top="0" left="0" height="1188" width="918">
<text top="204" left="240" width="43" height="13" font="7">0.0E+00</text>
<text top="168" left="240" width="43" height="13" font="7">1.0E+04</text>
<text top="132" left="240" width="43" height="13" font="7">2.0E+04</text>
<text top="221" left="292" width="7" height="13" font="7">0</text>
<text top="221" left="341" width="27" height="13" font="7">1000</text>
<text top="221" left="400" width="27" height="13" font="7">2000</text>
<text top="167" left="233" width="0" height="15" font="10"><b>co</b></text>
<text top="152" left="233" width="0" height="15" font="10"><b>st</b></text>
<text top="141" left="233" width="0" height="15" font="10"><b> </b></text>
<text top="240" left="339" width="64" height="15" font="10"><b>time (sec) </b></text>
<text top="116" left="367" width="20" height="17" font="11"><b>LP </b></text>
<text top="155" left="345" width="97" height="15" font="2">Alchemy (solid) </text>
<text top="139" left="330" width="88" height="15" font="2">Tuffy-p (dash) </text>
<text top="174" left="380" width="63" height="15" font="2">Tuffy-mm </text>
<text top="204" left="473" width="43" height="13" font="7">0.0E+00</text>
<text top="163" left="473" width="43" height="13" font="7">2.0E+05</text>
<text top="122" left="473" width="43" height="13" font="7">4.0E+05</text>
<text top="221" left="525" width="7" height="13" font="7">0</text>
<text top="221" left="591" width="27" height="13" font="7">4000</text>
<text top="221" left="667" width="27" height="13" font="7">8000</text>
<text top="167" left="466" width="0" height="15" font="10"><b>co</b></text>
<text top="152" left="466" width="0" height="15" font="10"><b>st</b></text>
<text top="141" left="466" width="0" height="15" font="10"><b> </b></text>
<text top="240" left="574" width="64" height="15" font="10"><b>time (sec) </b></text>
<text top="120" left="600" width="22" height="17" font="11"><b>RC </b></text>
<text top="159" left="634" width="56" height="15" font="2">Alchemy </text>
<text top="189" left="550" width="47" height="15" font="2">Tuffy-p </text>
<text top="139" left="540" width="63" height="15" font="2">Tuffy-mm </text>
<text top="277" left="108" width="702" height="17" font="4">Figure 4: Time-cost plots of Alchemy vs. Tuffy-p (i.e., Tuffy without partitioning) vs. Tuffy-</text>
<text top="297" left="108" width="325" height="17" font="4">mm (i.e., Tuffy with RDBMS-based search)</text>
<text top="336" left="421" width="24" height="15" font="4">LP</text>
<text top="336" left="488" width="20" height="15" font="4">IE</text>
<text top="336" left="543" width="27" height="15" font="4">RC</text>
<text top="336" left="591" width="26" height="15" font="4">ER</text>
<text top="360" left="301" width="73" height="14" font="4">Alchemy</text>
<text top="357" left="401" width="44" height="15" font="4">0.20M</text>
<text top="357" left="485" width="23" height="15" font="4">1M</text>
<text top="357" left="537" width="34" height="15" font="4">1.9K</text>
<text top="357" left="589" width="34" height="15" font="4">0.9K</text>
<text top="381" left="295" width="84" height="14" font="4">Tuffy-mm</text>
<text top="378" left="424" width="21" height="15" font="4">0.9</text>
<text top="378" left="491" width="16" height="15" font="4">13</text>
<text top="378" left="549" width="21" height="15" font="4">0.9</text>
<text top="378" left="593" width="29" height="15" font="4">0.03</text>
<text top="402" left="305" width="65" height="14" font="4">Tuffy-p</text>
<text top="399" left="401" width="44" height="15" font="4">0.11M</text>
<text top="399" left="464" width="44" height="15" font="4">0.39M</text>
<text top="399" left="526" width="44" height="15" font="4">0.17M</text>
<text top="399" left="589" width="34" height="15" font="4">7.9K</text>
<text top="436" left="331" width="255" height="15" font="4">Table 3: Flipping rates (#ﬂips/sec)</text>
<text top="488" left="108" width="702" height="17" font="4">memory, Tuffy only needs to load the grounding result from the RDBMS at the end of grounding.</text>
<text top="509" left="108" width="702" height="17" font="4">It follows that, given the same resources, there are MLNs that Tuffy can handle eﬃciently while</text>
<text top="532" left="108" width="702" height="14" font="4">Alchemy would crash. Indeed, on a dataset called “ER+” which is twice as large as ER, Alchemy</text>
<text top="549" left="108" width="428" height="15" font="4">exhausts all 4GB of RAM and crashes soon after launching</text>
<text top="547" left="536" width="6" height="11" font="5">5</text>
<text top="549" left="543" width="267" height="17" font="4">, whereas Tuffy runs normally with</text>
<text top="570" left="108" width="244" height="15" font="4">peak RAM usage of roughly 2GB.</text>
<text top="590" left="133" width="677" height="17" font="4">From these experiments, we conclude that the hybrid architecture is crucial to Tuffy’s overall</text>
<text top="610" left="108" width="68" height="15" font="4">eﬃciency.</text>
<text top="653" left="108" width="26" height="16" font="1">4.4</text>
<text top="653" left="154" width="187" height="16" font="1">Eﬀect of Partitioning</text>
<text top="685" left="108" width="702" height="15" font="4">In this section, we validate that, when there are multiple components in the data, partitioning not</text>
<text top="705" left="108" width="702" height="17" font="4">only improves Tuffy’s space eﬃciency, but – due to Theorem 3.1 – may actually enable Tuffy</text>
<text top="726" left="108" width="702" height="17" font="4">to ﬁnd substantially higher quality results. We compare Tuffy’s performance (with partitioning</text>
<text top="746" left="108" width="535" height="17" font="4">enabled) against Tuffy-p: a version of Tuffy with partitioning disabled.</text>
<text top="766" left="133" width="677" height="17" font="4">We run the search phase on each of the four datasets using three approaches: Alchemy,</text>
<text top="790" left="108" width="702" height="14" font="4">Tuffy-p, and Tuffy (with partitioning). Tuffy-p and Alchemy run WalkSAT on the whole</text>
<text top="807" left="108" width="87" height="15" font="4">MRF for 10</text>
<text top="804" left="195" width="6" height="11" font="5">7</text>
<text top="807" left="208" width="602" height="17" font="4">steps. Tuffy runs WalkSAT on each component in the MRF independently, each</text>
<text top="827" left="108" width="98" height="15" font="4">component G</text>
<text top="833" left="206" width="4" height="11" font="5">i</text>
<text top="827" left="218" width="86" height="15" font="4">receiving 10</text>
<text top="825" left="304" width="6" height="11" font="5">7</text>
<text top="826" left="311" width="17" height="15" font="4">|G</text>
<text top="833" left="329" width="4" height="11" font="5">i</text>
<text top="826" left="334" width="155" height="15" font="4">|/|G| steps, where |G</text>
<text top="833" left="489" width="4" height="11" font="5">i</text>
<text top="826" left="494" width="316" height="15" font="4">| and |G| are the numbers of atoms in this</text>
<text top="857" left="127" width="5" height="8" font="6">5</text>
<text top="860" left="133" width="489" height="14" font="7">We verify on a separate machine that Alchemy requires at least 23GB of RAM.</text>
<text top="908" left="422" width="24" height="15" font="4">LP</text>
<text top="908" left="502" width="20" height="15" font="4">IE</text>
<text top="908" left="566" width="27" height="15" font="4">RC</text>
<text top="908" left="642" width="26" height="15" font="4">ER</text>
<text top="929" left="267" width="84" height="15" font="4">clause table</text>
<text top="929" left="393" width="53" height="15" font="4">5.2 MB</text>
<text top="929" left="469" width="53" height="15" font="4">0.6 MB</text>
<text top="929" left="540" width="53" height="15" font="4">4.8 MB</text>
<text top="929" left="612" width="57" height="15" font="4">164 MB</text>
<text top="952" left="250" width="118" height="14" font="4">Alchemy RAM</text>
<text top="949" left="390" width="57" height="15" font="4">411 MB</text>
<text top="949" left="465" width="57" height="15" font="4">206 MB</text>
<text top="949" left="542" width="51" height="15" font="4">2.8 GB</text>
<text top="949" left="617" width="51" height="15" font="4">3.5 GB</text>
<text top="973" left="254" width="110" height="14" font="4">Tuffy-p RAM</text>
<text top="970" left="406" width="40" height="15" font="4">9 MB</text>
<text top="970" left="481" width="40" height="15" font="4">8 MB</text>
<text top="970" left="545" width="48" height="15" font="4">19 MB</text>
<text top="970" left="612" width="57" height="15" font="4">184 MB</text>
<text top="1008" left="191" width="536" height="17" font="4">Table 4: Space eﬃciency of Alchemy vs. Tuffy-p (without partitioning)</text>
<text top="1069" left="451" width="16" height="15" font="4">13</text>
</page>
<page number="14" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="12" size="17" family="Times" color="#000000"/>
<text top="113" left="108" width="576" height="15" font="4">component and the MRF, respectively. This is weighted round-robin scheduling.</text>
<text top="149" left="426" width="24" height="15" font="4">LP</text>
<text top="149" left="484" width="20" height="15" font="4">IE</text>
<text top="149" left="538" width="27" height="15" font="4">RC</text>
<text top="149" left="608" width="26" height="15" font="4">ER</text>
<text top="170" left="289" width="98" height="15" font="4">#components</text>
<text top="170" left="442" width="8" height="15" font="4">1</text>
<text top="170" left="471" width="33" height="15" font="4">5341</text>
<text top="170" left="541" width="25" height="15" font="4">489</text>
<text top="170" left="627" width="8" height="15" font="4">1</text>
<text top="194" left="283" width="110" height="14" font="4">Tuffy-p RAM</text>
<text top="191" left="415" width="35" height="15" font="4">9MB</text>
<text top="191" left="469" width="35" height="15" font="4">8MB</text>
<text top="191" left="522" width="43" height="15" font="4">19MB</text>
<text top="191" left="584" width="51" height="15" font="4">184MB</text>
<text top="215" left="291" width="96" height="14" font="4">Tuffy RAM</text>
<text top="212" left="415" width="35" height="15" font="4">9MB</text>
<text top="212" left="469" width="35" height="15" font="4">8MB</text>
<text top="212" left="522" width="43" height="15" font="4">15MB</text>
<text top="212" left="584" width="51" height="15" font="4">184MB</text>
<text top="236" left="289" width="99" height="14" font="4">Tuffy-p cost</text>
<text top="233" left="418" width="33" height="15" font="4">2534</text>
<text top="233" left="471" width="33" height="15" font="4">1933</text>
<text top="233" left="532" width="33" height="15" font="4">1943</text>
<text top="233" left="594" width="41" height="15" font="4">18717</text>
<text top="257" left="296" width="85" height="14" font="4">Tuffy cost</text>
<text top="254" left="418" width="33" height="15" font="4">2534</text>
<text top="254" left="471" width="33" height="15" font="4">1635</text>
<text top="254" left="532" width="33" height="15" font="4">1281</text>
<text top="254" left="594" width="41" height="15" font="4">18717</text>
<text top="291" left="169" width="579" height="17" font="4">Table 5: Performance of Tuffy vs. Tuffy-p (i.e., Tuffy without partitioning)</text>
<text top="440" left="241" width="27" height="13" font="7">1000</text>
<text top="418" left="241" width="27" height="13" font="7">1400</text>
<text top="395" left="241" width="27" height="13" font="7">1800</text>
<text top="373" left="241" width="27" height="13" font="7">2200</text>
<text top="350" left="241" width="27" height="13" font="7">2600</text>
<text top="458" left="277" width="7" height="13" font="7">0</text>
<text top="458" left="319" width="14" height="13" font="7">20</text>
<text top="458" left="364" width="14" height="13" font="7">40</text>
<text top="458" left="409" width="14" height="13" font="7">60</text>
<text top="458" left="455" width="14" height="13" font="7">80</text>
<text top="403" left="235" width="0" height="15" font="10"><b>co</b></text>
<text top="389" left="235" width="0" height="15" font="10"><b>st</b></text>
<text top="378" left="235" width="0" height="15" font="10"><b> </b></text>
<text top="477" left="340" width="64" height="15" font="10"><b>time (sec) </b></text>
<text top="350" left="381" width="20" height="20" font="12"><b>IE </b></text>
<text top="430" left="385" width="31" height="13" font="7">Tuffy </text>
<text top="360" left="286" width="89" height="13" font="7">Tuffy-p (dotted) </text>
<text top="376" left="286" width="86" height="13" font="7">Alchemy (solid) </text>
<text top="440" left="490" width="7" height="13" font="7">0</text>
<text top="410" left="470" width="27" height="13" font="7">1000</text>
<text top="380" left="470" width="27" height="13" font="7">2000</text>
<text top="350" left="470" width="27" height="13" font="7">3000</text>
<text top="458" left="506" width="7" height="13" font="7">0</text>
<text top="458" left="556" width="20" height="13" font="7">100</text>
<text top="458" left="612" width="20" height="13" font="7">200</text>
<text top="458" left="669" width="20" height="13" font="7">300</text>
<text top="403" left="464" width="0" height="15" font="10"><b>cos</b></text>
<text top="383" left="464" width="0" height="15" font="10"><b>t </b></text>
<text top="477" left="564" width="64" height="15" font="10"><b>time (sec) </b></text>
<text top="350" left="566" width="26" height="20" font="12"><b>RC </b></text>
<text top="390" left="605" width="31" height="13" font="7">Tuffy </text>
<text top="358" left="615" width="42" height="13" font="7">Tuffy-p </text>
<text top="429" left="522" width="167" height="12" font="5">Alchemy grounding took over 1 hr. </text>
<text top="518" left="158" width="601" height="17" font="4">Figure 5: Time-cost plots of Tuffy vs Tuffy-p (i.e., Tuffy without partitioning)</text>
<text top="559" left="133" width="677" height="15" font="4">As shown in Table 5, when there are multiple components in the MRF, partitioning allows</text>
<text top="582" left="108" width="702" height="14" font="4">Tuffy to use less memory than Tuffy-p. (The IE dataset is too small to yield notable diﬀerences).</text>
<text top="599" left="108" width="702" height="17" font="4">We see that Tuffy’s component-wise inference produces signiﬁcantly better results than Tuffy-</text>
<text top="620" left="108" width="702" height="15" font="4">p. We then extend the run time of all systems. As shown in Figure 5, there continues to be a</text>
<text top="640" left="108" width="702" height="17" font="4">gap between Tuffy’s component-wise search approach and the original WalkSAT running on the</text>
<text top="660" left="108" width="702" height="15" font="4">whole MRF. This gap is predicted by our theoretical analysis in §3.3. Thus, we have veriﬁed that</text>
<text top="681" left="108" width="685" height="17" font="4">partitioning makes Tuffy substantially more eﬃcient in terms of both space and search speed.</text>
<text top="701" left="133" width="677" height="17" font="4">We also validate that Tuffy’s loading and parallelism makes a substantial diﬀerence: without</text>
<text top="721" left="108" width="438" height="17" font="4">our batch loading technique, Tuffy takes 448s to perform 10</text>
<text top="719" left="546" width="6" height="11" font="5">6</text>
<text top="721" left="559" width="251" height="15" font="4">search steps per component on RC,</text>
<text top="742" left="108" width="702" height="15" font="4">while 117s to perform the same operation with batch loading. With the addition of 8 threads (on</text>
<text top="762" left="108" width="702" height="15" font="4">8 cores), we further reduce the runtime to 28s. Additional loading and parallelism experiments</text>
<text top="782" left="108" width="702" height="15" font="4">in §C.3 support our claim that our loading algorithm and partitioning algorithm contribute to</text>
<text top="803" left="108" width="200" height="15" font="4">improving processing speed.</text>
<text top="845" left="108" width="26" height="16" font="1">4.5</text>
<text top="845" left="154" width="261" height="16" font="1">Eﬀect of Further Partitioning</text>
<text top="877" left="108" width="702" height="15" font="4">To validate our claim that splitting MRF components can further improve both space eﬃciency and</text>
<text top="898" left="108" width="702" height="17" font="4">sometimes also search quality (§3.4), we run Tuffy on RC, ER, and LP with diﬀerent memory</text>
<text top="918" left="108" width="702" height="15" font="4">budgets – which are fed to the partitioning algorithm as the bound of partition size. On each</text>
<text top="938" left="108" width="702" height="17" font="4">dataset, we give Tuffy three memory budgets, with the largest one corresponding to the case</text>
<text top="959" left="108" width="702" height="15" font="4">when no components are split; note that according to the partitioning algorithm, the memory</text>
<text top="979" left="108" width="702" height="15" font="4">budget is inversely correlated to partitioning granularity. Figure 6 shows the experiment results.</text>
<text top="999" left="108" width="702" height="15" font="4">On RC, we see another improvement of the result quality (cf. Figure 5). Similar to Example 2, we</text>
<text top="1020" left="108" width="702" height="15" font="4">believe the reason to be graph sparsity: “13MB” cuts only about 420 out of the total 10K clauses.</text>
<text top="1069" left="451" width="16" height="15" font="4">14</text>
</page>
<page number="15" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="13" size="16" family="Times" color="#000000"/>
<text top="232" left="181" width="30" height="15" font="2">0E+0</text>
<text top="191" left="181" width="30" height="15" font="2">1E+3</text>
<text top="149" left="181" width="29" height="15" font="2">2E+3</text>
<text top="108" left="181" width="29" height="15" font="2">3E+3</text>
<text top="251" left="220" width="7" height="15" font="2">0</text>
<text top="251" left="252" width="23" height="15" font="2">100</text>
<text top="251" left="290" width="23" height="15" font="2">200</text>
<text top="251" left="329" width="23" height="15" font="2">300</text>
<text top="178" left="174" width="0" height="17" font="11"><b>cos</b></text>
<text top="156" left="174" width="0" height="17" font="11"><b>t </b></text>
<text top="272" left="248" width="72" height="17" font="11"><b>time (sec) </b></text>
<text top="109" left="277" width="22" height="17" font="11"><b>RC </b></text>
<text top="126" left="311" width="40" height="17" font="4">15MB</text>
<text top="146" left="311" width="40" height="17" font="4">13MB</text>
<text top="166" left="311" width="40" height="17" font="4">12MB</text>
<text top="232" left="375" width="41" height="15" font="2">2.4E+3</text>
<text top="191" left="375" width="41" height="15" font="2">2.6E+3</text>
<text top="149" left="375" width="41" height="15" font="2">2.8E+3</text>
<text top="108" left="375" width="41" height="15" font="2">3.0E+3</text>
<text top="251" left="425" width="7" height="15" font="2">0</text>
<text top="251" left="458" width="15" height="15" font="2">50</text>
<text top="251" left="490" width="59" height="15" font="2">100 150</text>
<text top="178" left="367" width="0" height="17" font="11"><b>cos</b></text>
<text top="156" left="367" width="0" height="17" font="11"><b>t </b></text>
<text top="272" left="449" width="72" height="17" font="11"><b>time (sec) </b></text>
<text top="111" left="467" width="22" height="19" font="13"><b>LP </b></text>
<text top="137" left="506" width="32" height="17" font="4">9MB</text>
<text top="156" left="506" width="32" height="17" font="4">5MB</text>
<text top="176" left="506" width="44" height="17" font="4">3.5MB</text>
<text top="232" left="575" width="30" height="15" font="2">0E+0</text>
<text top="201" left="575" width="29" height="15" font="2">2E+4</text>
<text top="170" left="575" width="29" height="15" font="2">4E+4</text>
<text top="139" left="575" width="30" height="15" font="2">6E+4</text>
<text top="108" left="575" width="29" height="15" font="2">8E+4</text>
<text top="251" left="614" width="7" height="15" font="2">0</text>
<text top="251" left="644" width="102" height="15" font="2">500 1000 1500</text>
<text top="178" left="567" width="0" height="17" font="11"><b>cos</b></text>
<text top="156" left="567" width="0" height="17" font="11"><b>t </b></text>
<text top="272" left="640" width="72" height="17" font="11"><b>time (sec) </b></text>
<text top="111" left="666" width="24" height="19" font="13"><b>ER </b></text>
<text top="134" left="701" width="48" height="17" font="4">200MB</text>
<text top="155" left="701" width="48" height="17" font="4">100MB</text>
<text top="176" left="701" width="40" height="17" font="4">50MB</text>
<text top="288" left="217" width="485" height="17" font="4">Figure 6: Time-cost plots of Tuffy with diﬀerent memory budgets</text>
<text top="341" left="108" width="702" height="15" font="4">In contrast, while MRF partitioning lowers RAM usage considerably on ER, it also leads to slower</text>
<text top="361" left="108" width="702" height="15" font="4">convergence of result quality – which correlates with poor partitioning quality: the MRF of ER</text>
<text top="381" left="108" width="702" height="15" font="4">is quite dense and even 2-way partitioning (“100MB”) would cut over 1.4M out of the total 2M</text>
<text top="402" left="108" width="702" height="15" font="4">clauses. The dataset LP illustrates the interesting tradeoﬀ where a coarse partition is beneﬁcial</text>
<text top="422" left="108" width="620" height="15" font="4">whereas ﬁner grained partitions would be detrimental. We discuss this tradeoﬀ in §??.</text>
<text top="470" left="108" width="12" height="19" font="3">5</text>
<text top="470" left="144" width="325" height="19" font="3">Tradeoﬀs in MRF Partitioning</text>
<text top="510" left="108" width="702" height="15" font="4">Experiments in §4 show that, even when many clauses are cut due to partitioning, the search results</text>
<text top="530" left="108" width="702" height="15" font="4">can still be signiﬁcantly better than when no components are split (especially on the RC dataset).</text>
<text top="551" left="108" width="702" height="15" font="4">This is true even when a component is split into a relatively small number of pieces. To explain</text>
<text top="571" left="108" width="702" height="15" font="4">this phenomenon, note that the bound in Theorem 3.1 is rather conservative – speed-up of search</text>
<text top="591" left="108" width="374" height="15" font="4">is more dramatic than as predicted by Theorem 3.1.</text>
<text top="629" left="108" width="474" height="15" font="4">Example 1 Consider an MRF G with two identical components G</text>
<text top="635" left="582" width="6" height="11" font="5">1</text>
<text top="629" left="589" width="20" height="15" font="4">, G</text>
<text top="635" left="609" width="6" height="11" font="5">2</text>
<text top="629" left="616" width="194" height="15" font="4">, and let p be the stationary</text>
<text top="650" left="108" width="257" height="15" font="4">probability of the optima on each G</text>
<text top="655" left="365" width="4" height="11" font="5">i</text>
<text top="650" left="370" width="440" height="15" font="4">. Then, after entering a communication class containing some</text>
<text top="670" left="108" width="702" height="15" font="4">optimum, component-wise WalkSAT would need an expected total of 2/p steps to reach the optima;</text>
<text top="690" left="108" width="482" height="15" font="4">whereas running WalkSAT on G as a whole would require roughly</text>
<text top="688" left="590" width="6" height="11" font="5">6</text>
<text top="690" left="604" width="25" height="15" font="4">1/p</text>
<text top="688" left="628" width="6" height="11" font="5">2</text>
<text top="690" left="642" width="147" height="15" font="4">steps. When p = 10</text>
<text top="687" left="788" width="16" height="11" font="5">−4</text>
<text top="690" left="805" width="5" height="15" font="4">,</text>
<text top="711" left="108" width="222" height="15" font="4">the diﬀerence is between 2 ∗ 10</text>
<text top="708" left="330" width="6" height="11" font="5">4</text>
<text top="711" left="343" width="48" height="15" font="4">and 10</text>
<text top="708" left="391" width="6" height="11" font="5">8</text>
<text top="711" left="398" width="412" height="15" font="4">. In contrast, by focusing on the optimal states and their</text>
<text top="731" left="108" width="445" height="15" font="4">neighbors, Theorem 3.1 only predicts a gap of no more than 2</text>
<text top="728" left="553" width="6" height="11" font="5">2</text>
<text top="731" left="560" width="5" height="15" font="4">.</text>
<text top="769" left="133" width="677" height="15" font="4">The implication of this observation is that, even when the largest component in the MRF is</text>
<text top="790" left="108" width="702" height="15" font="4">smaller than the RAM, we may still want to partition the components to even smaller pieces. This</text>
<text top="810" left="108" width="702" height="15" font="4">raises an interesting question: How do we decide the optimal partitioning granularity? Furthermore,</text>
<text top="830" left="108" width="702" height="15" font="4">given two partitioning schemes, how do we decide which one is better, i.e., produces better search</text>
<text top="851" left="108" width="702" height="15" font="4">results? To answer those questions, we have to characterize the eﬀect of partitioning granularity</text>
<text top="871" left="108" width="235" height="15" font="4">and cut size on inference quality.</text>
<text top="891" left="133" width="677" height="15" font="4">Let us introduce a few deﬁnitions. An atom is called iTrue (resp. iFalse) if it appears in a</text>
<text top="912" left="108" width="702" height="15" font="4">positive (resp. negative) literal of a positive-weighted ground clause, or in a negative (resp. positive)</text>
<text top="932" left="108" width="702" height="15" font="4">literal of a negative-weighted ground clause. If an atom is both iTrue and iFalse, it is called critical.</text>
<text top="952" left="108" width="702" height="15" font="4">Intuitively, it is the critical atoms that are responsible for making WalkSAT “oscillate” around the</text>
<text top="973" left="108" width="702" height="15" font="4">optima and thereby diminishing p, which in turn widens the gap in the above example. Hence,</text>
<text top="993" left="108" width="702" height="15" font="4">we use the number of critical atoms to estimate how hard it is for WalkSAT to ﬁnd an optimal</text>
<text top="1022" left="127" width="5" height="8" font="6">6</text>
<text top="1025" left="133" width="654" height="12" font="7">That is assuming that the number of violated clauses in optimal states in both components are comparable.</text>
<text top="1069" left="451" width="16" height="15" font="4">15</text>
</page>
<page number="16" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="14" size="4" family="Helvetica" color="#000000"/>
	<fontspec id="15" size="4" family="Symbol" color="#000000"/>
<text top="113" left="108" width="505" height="15" font="4">solution. Since we expect WalkSAT’s hitting time to be superlinear</text>
<text top="110" left="613" width="6" height="11" font="5">7</text>
<text top="113" left="628" width="182" height="15" font="4">in the number of critical</text>
<text top="133" left="108" width="702" height="15" font="4">atoms, we prefer ﬁner partitioning granularity. However, ﬁne granularity also implies larger cut</text>
<text top="154" left="108" width="628" height="15" font="4">size, which would slow down the convergence rate of the Gauss-Seidel inference scheme.</text>
<text top="397" left="265" width="4" height="6" font="14">0</text>
<text top="388" left="295" width="9" height="6" font="14">0.2</text>
<text top="379" left="324" width="9" height="6" font="14">0.4</text>
<text top="371" left="355" width="9" height="6" font="14">0.6</text>
<text top="363" left="385" width="9" height="6" font="14">0.8</text>
<text top="354" left="414" width="4" height="6" font="14">1</text>
<text top="396" left="251" width="4" height="6" font="14">0</text>
<text top="384" left="223" width="9" height="6" font="14">0.1</text>
<text top="373" left="200" width="9" height="6" font="14">0.2</text>
<text top="362" left="177" width="9" height="6" font="14">0.3</text>
<text top="351" left="155" width="9" height="6" font="14">0.4</text>
<text top="339" left="132" width="9" height="6" font="14">0.5</text>
<text top="332" left="138" width="4" height="6" font="14">0</text>
<text top="307" left="131" width="11" height="6" font="14">500</text>
<text top="283" left="128" width="14" height="6" font="14">1000</text>
<text top="259" left="128" width="14" height="6" font="14">1500</text>
<text top="235" left="128" width="14" height="6" font="14">2000</text>
<text top="196" left="409" width="2" height="6" font="14"> </text>
<text top="400" left="326" width="4" height="8" font="15">α</text>
<text top="401" left="330" width="73" height="6" font="14">: Fraction of critical atoms</text>
<text top="409" left="326" width="61" height="6" font="14">in the largest partition</text>
<text top="396" left="146" width="4" height="8" font="15">β</text>
<text top="398" left="150" width="57" height="6" font="14">: Fraction of clauses</text>
<text top="405" left="178" width="26" height="6" font="14">in the cut</text>
<text top="391" left="146" width="2" height="6" font="14"> </text>
<text top="301" left="123" width="0" height="6" font="14">Lowest cost</text>
<text top="382" left="434" width="11" height="6" font="14">400</text>
<text top="357" left="434" width="11" height="6" font="14">600</text>
<text top="333" left="434" width="11" height="6" font="14">800</text>
<text top="309" left="434" width="14" height="6" font="14">1000</text>
<text top="284" left="434" width="14" height="6" font="14">1200</text>
<text top="260" left="434" width="14" height="6" font="14">1400</text>
<text top="235" left="434" width="14" height="6" font="14">1600</text>
<text top="210" left="434" width="14" height="6" font="14">1800</text>
<text top="428" left="237" width="103" height="12" font="7">(a) Overall trend</text>
<text top="347" left="812" width="4" height="6" font="14">0</text>
<text top="358" left="787" width="9" height="6" font="14">0.2</text>
<text top="370" left="762" width="9" height="6" font="14">0.4</text>
<text top="381" left="737" width="9" height="6" font="14">0.6</text>
<text top="393" left="712" width="9" height="6" font="14">0.8</text>
<text top="404" left="688" width="4" height="6" font="14">1</text>
<text top="363" left="501" width="4" height="6" font="14">0</text>
<text top="372" left="530" width="9" height="6" font="14">0.1</text>
<text top="380" left="565" width="9" height="6" font="14">0.2</text>
<text top="388" left="599" width="9" height="6" font="14">0.3</text>
<text top="397" left="633" width="9" height="6" font="14">0.4</text>
<text top="405" left="667" width="9" height="6" font="14">0.5</text>
<text top="356" left="501" width="4" height="6" font="14">0</text>
<text top="331" left="494" width="11" height="6" font="14">500</text>
<text top="307" left="490" width="14" height="6" font="14">1000</text>
<text top="283" left="490" width="14" height="6" font="14">1500</text>
<text top="259" left="490" width="14" height="6" font="14">2000</text>
<text top="204" left="806" width="2" height="6" font="14"> </text>
<text top="390" left="734" width="4" height="8" font="15">α</text>
<text top="392" left="738" width="73" height="6" font="14">: Fraction of critical atoms</text>
<text top="399" left="734" width="61" height="6" font="14">in the largest partition</text>
<text top="395" left="535" width="4" height="8" font="15">β</text>
<text top="396" left="539" width="57" height="6" font="14">: Fraction of clauses</text>
<text top="404" left="567" width="26" height="6" font="14">in the cut</text>
<text top="400" left="509" width="2" height="6" font="14"> </text>
<text top="324" left="486" width="0" height="6" font="14">Lowest cost</text>
<text top="428" left="592" width="118" height="12" font="7">(b) Function ﬁtting</text>
<text top="461" left="126" width="666" height="15" font="4">Figure 7: Eﬀect of partitioning granularity and cut size on search quality on the RC dataset.</text>
<text top="735" left="228" width="9" height="6" font="14">0.1</text>
<text top="732" left="249" width="9" height="6" font="14">0.2</text>
<text top="728" left="269" width="9" height="6" font="14">0.3</text>
<text top="725" left="289" width="9" height="6" font="14">0.4</text>
<text top="722" left="310" width="9" height="6" font="14">0.5</text>
<text top="718" left="330" width="9" height="6" font="14">0.6</text>
<text top="714" left="351" width="9" height="6" font="14">0.7</text>
<text top="711" left="371" width="9" height="6" font="14">0.8</text>
<text top="707" left="392" width="9" height="6" font="14">0.9</text>
<text top="704" left="412" width="4" height="6" font="14">1</text>
<text top="732" left="214" width="4" height="6" font="14">0</text>
<text top="714" left="189" width="9" height="6" font="14">0.2</text>
<text top="695" left="170" width="9" height="6" font="14">0.4</text>
<text top="676" left="150" width="9" height="6" font="14">0.6</text>
<text top="658" left="131" width="9" height="6" font="14">0.8</text>
<text top="649" left="127" width="14" height="6" font="14">2480</text>
<text top="634" left="127" width="14" height="6" font="14">2500</text>
<text top="619" left="127" width="14" height="6" font="14">2520</text>
<text top="604" left="127" width="14" height="6" font="14">2540</text>
<text top="589" left="127" width="14" height="6" font="14">2560</text>
<text top="574" left="127" width="14" height="6" font="14">2580</text>
<text top="560" left="127" width="14" height="6" font="14">2600</text>
<text top="533" left="407" width="2" height="6" font="14"> </text>
<text top="739" left="298" width="4" height="8" font="15">α</text>
<text top="741" left="302" width="72" height="6" font="14">: Fraction of critical atoms</text>
<text top="748" left="298" width="61" height="6" font="14">in the largest partition</text>
<text top="729" left="120" width="3" height="8" font="15">β</text>
<text top="731" left="123" width="57" height="6" font="14">: Fraction of clauses</text>
<text top="738" left="151" width="26" height="6" font="14">in the cut</text>
<text top="728" left="145" width="2" height="6" font="14"> </text>
<text top="624" left="122" width="0" height="6" font="14">Lowest cost</text>
<text top="705" left="432" width="26" height="6" font="14">2534.587</text>
<text top="684" left="432" width="26" height="6" font="14">2534.588</text>
<text top="661" left="432" width="26" height="6" font="14">2534.589</text>
<text top="639" left="432" width="23" height="6" font="14">2534.59</text>
<text top="617" left="432" width="26" height="6" font="14">2534.591</text>
<text top="594" left="432" width="26" height="6" font="14">2534.592</text>
<text top="573" left="432" width="26" height="6" font="14">2534.593</text>
<text top="550" left="432" width="26" height="6" font="14">2534.594</text>
<text top="766" left="237" width="103" height="12" font="7">(a) Overall trend</text>
<text top="728" left="636" width="4" height="6" font="14">0</text>
<text top="728" left="668" width="9" height="6" font="14">0.2</text>
<text top="726" left="702" width="9" height="6" font="14">0.4</text>
<text top="725" left="737" width="9" height="6" font="14">0.6</text>
<text top="723" left="772" width="9" height="6" font="14">0.8</text>
<text top="722" left="809" width="4" height="6" font="14">1</text>
<text top="728" left="636" width="4" height="6" font="14">0</text>
<text top="726" left="603" width="9" height="6" font="14">0.2</text>
<text top="724" left="573" width="9" height="6" font="14">0.4</text>
<text top="721" left="542" width="9" height="6" font="14">0.6</text>
<text top="719" left="511" width="9" height="6" font="14">0.8</text>
<text top="708" left="496" width="14" height="6" font="14">2480</text>
<text top="680" left="496" width="14" height="6" font="14">2500</text>
<text top="651" left="496" width="14" height="6" font="14">2520</text>
<text top="622" left="496" width="14" height="6" font="14">2540</text>
<text top="594" left="496" width="14" height="6" font="14">2560</text>
<text top="566" left="496" width="14" height="6" font="14">2580</text>
<text top="537" left="496" width="14" height="6" font="14">2600</text>
<text top="531" left="810" width="2" height="6" font="14"> </text>
<text top="738" left="678" width="4" height="8" font="15">α</text>
<text top="740" left="681" width="73" height="6" font="14">: Fraction of critical atoms</text>
<text top="747" left="685" width="61" height="6" font="14">in the largest partition</text>
<text top="737" left="548" width="3" height="8" font="15">β</text>
<text top="739" left="551" width="57" height="6" font="14">: Fraction of clauses</text>
<text top="746" left="564" width="26" height="6" font="14">in the cut</text>
<text top="720" left="515" width="2" height="6" font="14"> </text>
<text top="638" left="491" width="0" height="6" font="14">Lowest cost</text>
<text top="766" left="592" width="118" height="12" font="7">(b) Function ﬁtting</text>
<text top="800" left="127" width="664" height="15" font="4">Figure 8: Eﬀect of partitioning granularity and cut size on search quality on the LP dataset.</text>
<text top="840" left="133" width="677" height="15" font="4">To study the tradeoﬀ between critical atoms and cut size, we conduct the following experiment.</text>
<text top="860" left="108" width="702" height="15" font="4">On each of the three usable datasets (i.e., RC, LP, and RC), we select the largest component in</text>
<text top="880" left="108" width="702" height="15" font="4">the MRF, and partition it with various granularities: 2-way, 4-way, 8-way, and 16-way. For each</text>
<text top="901" left="108" width="702" height="15" font="4">granularity, we generate several hundred random partitioning schemes, and measure two quantities</text>
<text top="921" left="108" width="592" height="15" font="4">of each scheme: 1) α, which is the fraction of critical atoms in the largest partition</text>
<text top="918" left="700" width="6" height="11" font="5">8</text>
<text top="921" left="707" width="103" height="15" font="4">, serving as an</text>
<text top="941" left="108" width="702" height="15" font="4">estimate of per-partition WalkSAT search speed (lower α values are imply faster search speed); and</text>
<text top="962" left="108" width="702" height="15" font="4">2) β, which is the fraction of clauses in the cut, serving as an estimate of the Gauss-Seidel scheme’s</text>
<text top="990" left="127" width="5" height="8" font="6">7</text>
<text top="993" left="133" width="523" height="12" font="7">Note that naive exhaustive search has a run time exponential in the number of atoms.</text>
<text top="1007" left="127" width="5" height="8" font="6">8</text>
<text top="1009" left="133" width="677" height="12" font="7">As such, α is at least 1/k for k-way partitioning. In the experiments, we ensure that α ∈ [1/2k, 1/k] for k-way</text>
<text top="1026" left="108" width="569" height="12" font="7">partitioning, so that there are no overlaps of α values from the four partitioning granularities.</text>
<text top="1069" left="451" width="16" height="15" font="4">16</text>
</page>
<page number="17" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="16" size="2" family="Helvetica" color="#000000"/>
<text top="334" left="253" width="4" height="6" font="14">0</text>
<text top="326" left="287" width="9" height="6" font="14">0.2</text>
<text top="319" left="322" width="9" height="6" font="14">0.4</text>
<text top="313" left="356" width="9" height="6" font="14">0.6</text>
<text top="306" left="391" width="9" height="6" font="14">0.8</text>
<text top="299" left="426" width="4" height="6" font="14">1</text>
<text top="332" left="237" width="4" height="6" font="14">0</text>
<text top="320" left="211" width="9" height="6" font="14">0.2</text>
<text top="309" left="190" width="9" height="6" font="14">0.4</text>
<text top="297" left="169" width="9" height="6" font="14">0.6</text>
<text top="286" left="148" width="9" height="6" font="14">0.8</text>
<text top="275" left="133" width="4" height="6" font="14">1</text>
<text top="266" left="134" width="4" height="6" font="14">1</text>
<text top="247" left="128" width="9" height="6" font="14">1.5</text>
<text top="228" left="134" width="4" height="6" font="14">2</text>
<text top="209" left="128" width="9" height="6" font="14">2.5</text>
<text top="190" left="134" width="4" height="6" font="14">3</text>
<text top="171" left="128" width="9" height="6" font="14">3.5</text>
<text top="152" left="134" width="4" height="6" font="14">4</text>
<text top="137" left="143" width="13" height="6" font="14">x 10</text>
<text top="135" left="156" width="2" height="4" font="16">4</text>
<text top="121" left="420" width="2" height="6" font="14"> </text>
<text top="339" left="321" width="4" height="9" font="15">α</text>
<text top="341" left="325" width="77" height="6" font="14">: Fraction of critical atoms</text>
<text top="349" left="321" width="64" height="6" font="14">in the largest partition</text>
<text top="333" left="132" width="4" height="9" font="15">β</text>
<text top="335" left="135" width="60" height="6" font="14">: Fraction of clauses</text>
<text top="343" left="165" width="27" height="6" font="14">in the cut</text>
<text top="327" left="142" width="2" height="6" font="14"> </text>
<text top="228" left="123" width="0" height="6" font="14">Lowest cost</text>
<text top="309" left="446" width="9" height="6" font="14">1.6</text>
<text top="291" left="446" width="9" height="6" font="14">1.8</text>
<text top="272" left="446" width="4" height="6" font="14">2</text>
<text top="253" left="446" width="9" height="6" font="14">2.2</text>
<text top="235" left="446" width="9" height="6" font="14">2.4</text>
<text top="216" left="446" width="9" height="6" font="14">2.6</text>
<text top="197" left="446" width="9" height="6" font="14">2.8</text>
<text top="179" left="446" width="4" height="6" font="14">3</text>
<text top="160" left="446" width="9" height="6" font="14">3.2</text>
<text top="141" left="446" width="9" height="6" font="14">3.4</text>
<text top="123" left="446" width="9" height="6" font="14">3.6</text>
<text top="115" left="444" width="13" height="6" font="14">x 10</text>
<text top="113" left="457" width="2" height="4" font="16">4</text>
<text top="368" left="237" width="103" height="12" font="7">(a) Overall trend</text>
<text top="302" left="816" width="4" height="6" font="14">0</text>
<text top="312" left="785" width="9" height="6" font="14">0.2</text>
<text top="321" left="755" width="9" height="6" font="14">0.4</text>
<text top="330" left="724" width="9" height="6" font="14">0.6</text>
<text top="339" left="694" width="9" height="6" font="14">0.8</text>
<text top="348" left="663" width="4" height="6" font="14">1</text>
<text top="302" left="494" width="4" height="6" font="14">0</text>
<text top="312" left="520" width="9" height="6" font="14">0.2</text>
<text top="321" left="551" width="9" height="6" font="14">0.4</text>
<text top="330" left="581" width="9" height="6" font="14">0.6</text>
<text top="339" left="612" width="9" height="6" font="14">0.8</text>
<text top="348" left="648" width="4" height="6" font="14">1</text>
<text top="295" left="494" width="4" height="6" font="14">1</text>
<text top="277" left="489" width="9" height="6" font="14">1.5</text>
<text top="258" left="494" width="4" height="6" font="14">2</text>
<text top="239" left="489" width="9" height="6" font="14">2.5</text>
<text top="221" left="494" width="4" height="6" font="14">3</text>
<text top="202" left="489" width="9" height="6" font="14">3.5</text>
<text top="184" left="494" width="4" height="6" font="14">4</text>
<text top="168" left="504" width="13" height="6" font="14">x 10</text>
<text top="166" left="516" width="2" height="4" font="16">4</text>
<text top="141" left="810" width="2" height="6" font="14"> </text>
<text top="337" left="729" width="4" height="9" font="15">α</text>
<text top="339" left="733" width="75" height="6" font="14">: Fraction of critical atoms</text>
<text top="346" left="729" width="63" height="6" font="14">in the largest partition</text>
<text top="336" left="521" width="4" height="9" font="15">β</text>
<text top="338" left="524" width="59" height="6" font="14">: Fraction of clauses</text>
<text top="345" left="554" width="27" height="6" font="14">in the cut</text>
<text top="344" left="503" width="2" height="6" font="14"> </text>
<text top="257" left="484" width="0" height="6" font="14">Lowest cost</text>
<text top="368" left="592" width="118" height="12" font="7">(b) Function ﬁtting</text>
<text top="402" left="126" width="666" height="15" font="4">Figure 9: Eﬀect of partitioning granularity and cut size on search quality on the ER dataset.</text>
<text top="454" left="108" width="702" height="15" font="4">convergence speed (again, lower β values imply faster convergence). On each partitioning scheme,</text>
<text top="474" left="108" width="474" height="15" font="4">we run the Gauss-Seidel inference scheme with two rounds, and 10</text>
<text top="472" left="582" width="6" height="11" font="5">5</text>
<text top="474" left="594" width="216" height="15" font="4">WalkSAT steps in each round.</text>
<text top="495" left="108" width="702" height="15" font="4">Finally, we measure the lowest total cost from each partitioning scheme. We plot the results in</text>
<text top="515" left="108" width="139" height="15" font="4">Figures 7, 8, and 9.</text>
<text top="535" left="133" width="677" height="15" font="4">On the RC dataset, we observe that partition sizes are the deciding factor of result quality –</text>
<text top="556" left="108" width="702" height="15" font="4">as α decreases, result quality improves substantially (from roughly 1200 to roughly 500), despite</text>
<text top="576" left="108" width="702" height="15" font="4">increases in the cut size (i.e., β). As shown in Figure 7, the partitioning schemes in diﬀerent</text>
<text top="596" left="108" width="702" height="15" font="4">granularity groups form distinct strata. In particular, although the ﬁnest partitioning schemes cut</text>
<text top="617" left="108" width="702" height="15" font="4">almost half of the clauses, they still yield the best result quality. Note that RC has a relatively</text>
<text top="637" left="108" width="702" height="15" font="4">sparse MRF, and the normalized cut size β remains relatively small. For datasets like this, one</text>
<text top="657" left="108" width="635" height="15" font="4">should partition aggressively to both improve search quality and increase parallelization.</text>
<text top="678" left="133" width="677" height="15" font="4">On the LP dataset, we see that, as partition sizes decrease, the cut size increases more rapidly</text>
<text top="698" left="108" width="702" height="15" font="4">(compared to RC), but the result quality remains largely the same (almost always between 2500 and</text>
<text top="718" left="108" width="702" height="15" font="4">2560). For datasets like this, one should partition aggressively to take advantage of parallelization.</text>
<text top="739" left="133" width="677" height="15" font="4">On the ER dataset, as partition sizes decrease, the cut size increases even more rapidly (com-</text>
<text top="759" left="108" width="674" height="15" font="4">pared to LP), and the average result quality deteriorates signiﬁcantly (from roughly 2.1 ∗ 10</text>
<text top="756" left="782" width="6" height="11" font="5">4</text>
<text top="759" left="795" width="15" height="15" font="4">to</text>
<text top="779" left="108" width="111" height="15" font="4">roughly 3.5 ∗ 10</text>
<text top="776" left="219" width="6" height="11" font="5">4</text>
<text top="779" left="226" width="584" height="15" font="4">). Note that on ER, even 4-way partitioning already cuts almost all of the clauses</text>
<text top="800" left="108" width="351" height="15" font="4">(with β ≈ 0.8) with lowest costs around 2.4 ∗ 20</text>
<text top="797" left="459" width="6" height="11" font="5">4</text>
<text top="800" left="466" width="344" height="15" font="4">. For datasets like this, one should avoid parti-</text>
<text top="820" left="108" width="393" height="15" font="4">tioning so long as the MRF component ﬁts in memory.</text>
<text top="840" left="133" width="677" height="15" font="4">From those results, it is clear that both α and β play a crucial role in result quality. Given a</text>
<text top="861" left="108" width="702" height="15" font="4">partitioning scheme P , we use the following simple formula to estimate how well P will perform in</text>
<text top="881" left="108" width="168" height="15" font="4">terms of search quality:</text>
<text top="901" left="406" width="12" height="15" font="4">E</text>
<text top="907" left="418" width="8" height="11" font="5">P</text>
<text top="901" left="434" width="28" height="15" font="4">= α</text>
<text top="907" left="461" width="8" height="11" font="5">P</text>
<text top="901" left="475" width="26" height="15" font="4">+ β</text>
<text top="907" left="501" width="8" height="11" font="5">P</text>
<text top="931" left="133" width="677" height="15" font="4">Since smaller values of α and β are more desirable, one should favor partitionings with smaller</text>
<text top="952" left="108" width="12" height="15" font="4">E</text>
<text top="957" left="120" width="8" height="11" font="5">P</text>
<text top="952" left="135" width="675" height="15" font="4">values. To empirically validate this heuristic, on each of the three ﬁgures, we also plot the plane</text>
<text top="972" left="108" width="39" height="15" font="4">z = c</text>
<text top="977" left="147" width="6" height="11" font="5">1</text>
<text top="972" left="154" width="12" height="15" font="4">E</text>
<text top="978" left="166" width="8" height="11" font="5">P</text>
<text top="972" left="180" width="24" height="15" font="4">+ c</text>
<text top="977" left="204" width="6" height="11" font="5">2</text>
<text top="972" left="217" width="25" height="15" font="4">= c</text>
<text top="977" left="242" width="6" height="11" font="5">1</text>
<text top="972" left="249" width="82" height="15" font="4">(α + β) + c</text>
<text top="977" left="330" width="6" height="11" font="5">2</text>
<text top="972" left="343" width="61" height="15" font="4">(where c</text>
<text top="977" left="405" width="4" height="11" font="5">i</text>
<text top="972" left="416" width="394" height="15" font="4">are positive constants) that minimizes the least square</text>
<text top="992" left="108" width="702" height="15" font="4">error to the data points. Part (b) of each ﬁgure shows that this is a reasonable approximation of</text>
<text top="1013" left="108" width="319" height="15" font="4">the general trend. Thus, we conclude that E</text>
<text top="1018" left="427" width="8" height="11" font="5">P</text>
<text top="1013" left="442" width="28" height="15" font="4">= α</text>
<text top="1018" left="470" width="8" height="11" font="5">P</text>
<text top="1013" left="484" width="25" height="15" font="4">+ β</text>
<text top="1018" left="509" width="8" height="11" font="5">P</text>
<text top="1013" left="525" width="285" height="15" font="4">is a reasonable heuristic to estimate the</text>
<text top="1069" left="451" width="16" height="15" font="4">17</text>
</page>
<page number="18" position="absolute" top="0" left="0" height="1188" width="918">
<text top="113" left="108" width="306" height="15" font="4">“quality” of diﬀerent partitioning schemes.</text>
<text top="133" left="133" width="677" height="15" font="4">To further validate and reﬁne this simple heuristic, we plan to perform more extensive exper-</text>
<text top="154" left="108" width="702" height="15" font="4">iments with more diverse datasets. It is also interesting to develop a theory on this tradeoﬀ and</text>
<text top="174" left="108" width="579" height="15" font="4">investigate how to design partitioning algorithms that make use of this heuristic.</text>
<text top="222" left="108" width="12" height="19" font="3">6</text>
<text top="222" left="144" width="307" height="19" font="3">Conclusion and Future Work</text>
<text top="262" left="108" width="702" height="17" font="4">Motivated by a large set of data-rich applications, we study how to push MLN inference inside an</text>
<text top="282" left="108" width="702" height="17" font="4">RDBMS. We ﬁnd that the grounding phase of MLN inference performs many relational operations</text>
<text top="303" left="108" width="702" height="17" font="4">and that these operations are a substantial bottleneck in state-of-the-art MLN implementations</text>
<text top="323" left="108" width="702" height="17" font="4">such as Alchemy. By using an RDBMS, Tuffy not only achieves scalability, but also speeds up the</text>
<text top="343" left="108" width="702" height="15" font="4">grounding phase by orders of magnitude. We then develop a hybrid solution with RDBMS-based</text>
<text top="364" left="108" width="702" height="17" font="4">grounding and in-memory search. To further improve the space and time eﬃciency of Tuffy,</text>
<text top="384" left="108" width="702" height="15" font="4">we study a partitioning approach that allows for in-memory search even when the dataset does</text>
<text top="404" left="108" width="702" height="15" font="4">not ﬁt in memory. We identiﬁed and quantiﬁed a particular kind of speed-up theoretically and</text>
<text top="425" left="108" width="702" height="15" font="4">experimentally; it allows us to produce higher quality results in a shorter amount of time and to</text>
<text top="445" left="108" width="702" height="15" font="4">run on much larger datasets than were impossible with prior approaches. As future work, we plan</text>
<text top="465" left="108" width="702" height="15" font="4">to further study the tradeoﬀ of partitioning, and apply our main techniques (hybrid architecture</text>
<text top="486" left="108" width="260" height="15" font="4">and partitioning) to other problems.</text>
<text top="534" left="108" width="12" height="19" font="3">7</text>
<text top="534" left="144" width="191" height="19" font="3">Acknowledgement</text>
<text top="574" left="108" width="702" height="15" font="4">We gratefully acknowledge the support of Defense Advanced Research Projects Agency (DARPA)</text>
<text top="594" left="108" width="702" height="15" font="4">Machine Reading Program under Air Force Research Laboratory (AFRL) prime contract no.</text>
<text top="614" left="108" width="702" height="15" font="4">FA8750-09-C-0181. Any opinions, ﬁndings, and conclusion or recommendations expressed in this</text>
<text top="635" left="108" width="702" height="15" font="4">material are those of the authors and do not necessarily reﬂect the view of the DARPA, AFRL, or</text>
<text top="655" left="108" width="142" height="15" font="4">the US government.</text>
<text top="701" left="108" width="113" height="19" font="3">References</text>
<text top="738" left="115" width="695" height="13" font="2">[1] L. Antova, T. Jansen, C. Koch, and D. Olteanu. Fast and simple relational processing of uncertain</text>
<text top="756" left="139" width="140" height="13" font="2">data. In ICDE, 2008.</text>
<text top="783" left="115" width="695" height="13" font="2">[2] O. Benjelloun, A. Sarma, A. Halevy, M. Theobald, and J. Widom. Databases with uncertainty and</text>
<text top="801" left="139" width="159" height="13" font="2">lineage. VLDB J., 2008.</text>
<text top="828" left="115" width="695" height="13" font="2">[3] D. P. Bertsekas and J. N. Tsitsiklis. Parallel and distributed computation: Numerical methods. Prentice-</text>
<text top="846" left="139" width="70" height="13" font="2">Hall, 1989.</text>
<text top="873" left="115" width="657" height="13" font="2">[4] N. N. Dalvi and D. Suciu. Eﬃcient query evaluation on probabilistic databases. In VLDB, 2004.</text>
<text top="899" left="115" width="695" height="13" font="2">[5] A. Deshpande and S. Madden. MauveDB: Supporting model-based user views in database systems. In</text>
<text top="917" left="139" width="105" height="13" font="2">SIGMOD, 2006.</text>
<text top="944" left="115" width="640" height="13" font="2">[6] P. Domingos and D. Lowd. Markov Logic: An Interface Layer for Artiﬁcial Intelligence. 2009.</text>
<text top="971" left="115" width="415" height="14" font="2">[7] P. Domingos et al. http://alchemy.cs.washington.edu/.</text>
<text top="998" left="115" width="613" height="13" font="2">[8] R. Fagin, J. Y. Halpern, and N. Megiddo. A logic for reasoning about probabilities. 1990.</text>
<text top="1025" left="115" width="565" height="13" font="2">[9] W. Feller. An introduction to probability theory and its applications. Vol. I. 1950.</text>
<text top="1069" left="451" width="16" height="15" font="4">18</text>
</page>
<page number="19" position="absolute" top="0" left="0" height="1188" width="918">
<text top="114" left="108" width="634" height="13" font="2">[10] S. Guha and K. Munagala. Multi-armed bandits with metric switching costs. ICALP, 2009.</text>
<text top="141" left="108" width="702" height="13" font="2">[11] R. Jampani, F. Xu, M. Wu, L. L. Perez, C. M. Jermaine, and P. J. Haas. MCDB: a monte carlo</text>
<text top="159" left="139" width="381" height="13" font="2">approach to managing uncertain data. In SIGMOD, 2008.</text>
<text top="186" left="108" width="702" height="13" font="2">[12] B. Kanagal and A. Deshpande. Online ﬁltering, smoothing and probabilistic modeling of streaming</text>
<text top="204" left="139" width="140" height="13" font="2">data. In ICDE, 2008.</text>
<text top="231" left="108" width="702" height="13" font="2">[13] G. Karypis, R. Aggarwal, V. Kumar, and S. Shekhar. Multilevel hypergraph partitioning: Applications</text>
<text top="249" left="139" width="407" height="13" font="2">in VLSI domain. VLSI Systems, IEEE Transactions on, 2002.</text>
<text top="275" left="108" width="702" height="13" font="2">[14] H. Kautz, B. Selman, and Y. Jiang. A general stochastic approach to solving problems with hard and</text>
<text top="293" left="139" width="494" height="13" font="2">soft constraints. The Satisﬁability Problem: Theory and Applications, 1997.</text>
<text top="320" left="108" width="702" height="13" font="2">[15] S. Khot. Ruling out PTAS for graph min-bisection, densest subgraph and bipartite clique. In FOCS,</text>
<text top="338" left="139" width="34" height="13" font="2">2004.</text>
<text top="365" left="108" width="702" height="13" font="2">[16] A. McCallum, K. Nigam, J. Rennie, and K. Seymore. Automating the construction of internet portals</text>
<text top="383" left="139" width="395" height="13" font="2">with machine learning. Information Retrieval Journal, 2000.</text>
<text top="410" left="108" width="638" height="13" font="2">[17] J. Pearl. Probabilistic reasoning in intelligent systems: networks of plausible inference. 1988.</text>
<text top="437" left="108" width="576" height="13" font="2">[18] H. Poon and P. Domingos. Joint inference in information extraction. In AAAI ’07.</text>
<text top="464" left="108" width="69" height="13" font="2">[19] C. R´</text>
<text top="464" left="170" width="640" height="13" font="2">e, N. N. Dalvi, and D. Suciu. Eﬃcient top-k query evaluation on probabilistic data. In ICDE, 2007.</text>
<text top="491" left="108" width="69" height="13" font="2">[20] C. R´</text>
<text top="491" left="170" width="640" height="13" font="2">e, J. Letchner, M. Balazinska, and D. Suciu. Event queries on correlated probabilistic streams. In</text>
<text top="509" left="139" width="105" height="13" font="2">SIGMOD, 2008.</text>
<text top="535" left="108" width="573" height="13" font="2">[21] M. Richardson and P. Domingos. Markov logic networks. Machine Learning, 2006.</text>
<text top="562" left="108" width="660" height="13" font="2">[22] S. Riedel and I. Meza-Ruiz. Collective semantic role labeling with Markov logic. In CoNLL ’08.</text>
<text top="589" left="108" width="702" height="13" font="2">[23] P. Sen and A. Deshpande. Representing and querying correlated tuples in probabilistic databases. In</text>
<text top="607" left="139" width="81" height="13" font="2">ICDE, 2007.</text>
<text top="634" left="108" width="702" height="13" font="2">[24] P. Sen, A. Deshpande, and L. Getoor. PrDB: managing and exploiting rich correlations in probabilistic</text>
<text top="652" left="139" width="177" height="13" font="2">databases. VLDB J., 2009.</text>
<text top="679" left="108" width="702" height="13" font="2">[25] H. Simon and S. Teng. How good is recursive bisection? SIAM Journal on Scientiﬁc Computing, 1997.</text>
<text top="706" left="108" width="547" height="13" font="2">[26] P. Singla and P. Domingos. Entity resolution with Markov logic. In ICDE ’06.</text>
<text top="733" left="108" width="702" height="13" font="2">[27] P. Singla, H. Kautz, J. Luo, and A. Gallagher. Discovery of social relationships in consumer photo</text>
<text top="751" left="139" width="389" height="13" font="2">collections using Markov Logic. In CVPR Workshops 2008.</text>
<text top="778" left="108" width="442" height="13" font="2">[28] V. Vazirani. Approximation algorithms. Springer Verlag, 2001.</text>
<text top="804" left="108" width="702" height="13" font="2">[29] D. Z. Wang, E. Michelakis, M. N. Garofalakis, and J. M. Hellerstein. BayesStore: managing large,</text>
<text top="822" left="139" width="516" height="13" font="2">uncertain data repositories with probabilistic graphical models. PVLDB, 2008.</text>
<text top="849" left="108" width="688" height="13" font="2">[30] F. Wu and D. S. Weld. Automatically reﬁning the Wikipedia infobox ontology. In WWW ’08, 2008.</text>
<text top="1069" left="451" width="16" height="15" font="4">19</text>
</page>
<page number="20" position="absolute" top="0" left="0" height="1188" width="918">
<text top="110" left="108" width="18" height="19" font="3">A</text>
<text top="110" left="150" width="276" height="19" font="3">Material for Preliminaries</text>
<text top="149" left="108" width="31" height="16" font="1">A.1</text>
<text top="149" left="159" width="315" height="16" font="1">More Details on the MLN Program</text>
<text top="179" left="108" width="690" height="17" font="4">Rules in MLNs are expressive and may involve data in non-trivial ways. For example, consider F</text>
<text top="184" left="798" width="6" height="11" font="5">2</text>
<text top="179" left="805" width="5" height="15" font="4">:</text>
<text top="214" left="271" width="333" height="12" font="2">wrote(x, p1), wrote(x, p2), cat(p1, c) =&gt; cat(p2, c)</text>
<text top="212" left="619" width="15" height="13" font="2">(F</text>
<text top="218" left="635" width="6" height="9" font="8">2</text>
<text top="212" left="641" width="6" height="13" font="2">)</text>
<text top="247" left="113" width="697" height="15" font="4">Intuitively, this rule says that all the papers written by a particular person are likely to be in the</text>
<text top="267" left="108" width="454" height="15" font="4">same category. Rules may also have existential quantiﬁers: F</text>
<text top="273" left="562" width="6" height="11" font="5">4</text>
<text top="267" left="575" width="235" height="15" font="4">says “any paper in our database</text>
<text top="287" left="108" width="702" height="15" font="4">must have at least one author.” It is also a hard rule, which is indicated by the inﬁnite weight, and</text>
<text top="308" left="108" width="702" height="15" font="4">so no possible world may violate this rule. The weight of a formula may also be negative, which</text>
<text top="328" left="108" width="609" height="15" font="4">eﬀectively means that the negation of the formula is likely to hold. For example, F</text>
<text top="333" left="717" width="6" height="11" font="5">5</text>
<text top="328" left="730" width="80" height="15" font="4">models our</text>
<text top="348" left="108" width="702" height="17" font="4">belief that none or very few of the unlabeled papers belong to ‘Networking’. Tuffy supports all</text>
<text top="369" left="108" width="121" height="15" font="4">of these features.</text>
<text top="389" left="133" width="677" height="17" font="4">If the input MLN contains hard rules (indicated by a weight of +∞ or −∞), then we insist</text>
<text top="409" left="108" width="702" height="15" font="4">that the set of possible worlds (Inst) only contain worlds that satisfy every hard rule with +∞ and</text>
<text top="430" left="108" width="702" height="15" font="4">violate every rule with −∞. In practice, schemata have type information, and we can use this to</text>
<text top="450" left="108" width="702" height="15" font="4">remove nonsensical ground clauses, e.g., both attributes of refers are paper references, and so it</text>
<text top="470" left="108" width="504" height="15" font="4">is unnecessary to ground this predicate with another type, say person.</text>
<text top="513" left="108" width="31" height="16" font="1">A.2</text>
<text top="513" left="159" width="199" height="16" font="1">Markov Random Field</text>
<text top="545" left="108" width="702" height="15" font="4">A Boolean Markov Random Field (or Boolean Markov network is a model of the joint distribution</text>
<text top="565" left="108" width="275" height="15" font="4">of a set of Boolean random variables ¯</text>
<text top="565" left="370" width="57" height="15" font="4">X = (X</text>
<text top="571" left="427" width="6" height="11" font="5">1</text>
<text top="565" left="434" width="50" height="15" font="4">, . . . , X</text>
<text top="571" left="484" width="10" height="11" font="5">N</text>
<text top="565" left="496" width="314" height="15" font="4">). It is deﬁned by a hypergraph G = (X, E);</text>
<text top="586" left="108" width="607" height="15" font="4">for each hyperedge e ∈ E there is a potential function (aka “feature”) denoted φ</text>
<text top="591" left="715" width="6" height="11" font="5">e</text>
<text top="586" left="722" width="88" height="15" font="4">, which is a</text>
<text top="606" left="108" width="702" height="15" font="4">function from the values of the set of variables in e to non-negative real numbers. This deﬁnes a</text>
<text top="626" left="108" width="164" height="15" font="4">joint distribution Pr( ¯</text>
<text top="626" left="259" width="46" height="15" font="4">X = ¯</text>
<text top="626" left="296" width="94" height="15" font="4">x) as follows:</text>
<text top="670" left="365" width="37" height="15" font="4">Pr( ¯</text>
<text top="670" left="388" width="46" height="15" font="4">X = ¯</text>
<text top="670" left="425" width="33" height="15" font="4">x) =</text>
<text top="659" left="467" width="8" height="15" font="4">1</text>
<text top="681" left="464" width="11" height="15" font="4">Z</text>
<text top="693" left="481" width="24" height="11" font="5">e∈E</text>
<text top="670" left="508" width="10" height="15" font="4">φ</text>
<text top="675" left="518" width="6" height="11" font="5">e</text>
<text top="670" left="525" width="16" height="15" font="4">(¯</text>
<text top="670" left="531" width="9" height="15" font="4">x</text>
<text top="675" left="540" width="6" height="11" font="5">e</text>
<text top="670" left="547" width="6" height="15" font="4">)</text>
<text top="726" left="108" width="57" height="15" font="4">where ¯</text>
<text top="726" left="155" width="69" height="15" font="4">x ∈ {0, 1}</text>
<text top="721" left="225" width="10" height="11" font="5">N</text>
<text top="726" left="237" width="269" height="15" font="4">, Z is a normalization constant and ¯</text>
<text top="726" left="496" width="9" height="15" font="4">x</text>
<text top="731" left="506" width="6" height="11" font="5">e</text>
<text top="726" left="518" width="282" height="15" font="4">denotes the values of the variables in e.</text>
<text top="746" left="133" width="209" height="15" font="4">Fix a set of constants C = {c</text>
<text top="751" left="342" width="6" height="11" font="5">1</text>
<text top="746" left="349" width="43" height="15" font="4">, . . . , c</text>
<text top="751" left="393" width="12" height="11" font="5">M</text>
<text top="745" left="407" width="403" height="18" font="4">}. An MLN deﬁnes a Boolean Markov Random Field as</text>
<text top="766" left="108" width="702" height="15" font="4">follows: for each possible grounding of each predicate (i.e., atom), create a node (and so a Boolean</text>
<text top="787" left="108" width="702" height="15" font="4">random variable). For example, there will be a node refers(p1, p2) for each pair of papers p1, p2.</text>
<text top="807" left="108" width="133" height="15" font="4">For each formula F</text>
<text top="812" left="241" width="4" height="11" font="5">i</text>
<text top="807" left="250" width="560" height="15" font="4">we ground it in all possible ways, then we create a hyperedge e that contains the</text>
<text top="827" left="108" width="702" height="15" font="4">nodes corresponding to all terms in the formula. For example, the key constraint creates hyperedges</text>
<text top="848" left="108" width="702" height="15" font="4">for each paper and all of its potential categories. We refer to this graph as the ground network.</text>
<text top="868" left="108" width="598" height="15" font="4">Once we have the ground network, our task reduces to inference in Markov models.</text>
<text top="888" left="133" width="677" height="15" font="4">Explicitly representing such ground networks is prohibitively expensive and unnecessary. In</text>
<text top="908" left="108" width="702" height="15" font="4">practice, we only include non-evidence nodes and groundings that are relevant to answering the</text>
<text top="929" left="108" width="122" height="15" font="4">query (see §A.3).</text>
<text top="972" left="108" width="31" height="16" font="1">A.3</text>
<text top="972" left="159" width="327" height="16" font="1">Optimizing MLN Grounding Process</text>
<text top="1003" left="108" width="702" height="17" font="4">Conceptually, we might ground an MLN formula by enumerating all possible assignments to its</text>
<text top="1024" left="108" width="695" height="15" font="4">free variables. However, this is both impractical and unnecessary. For example, if we ground F</text>
<text top="1029" left="803" width="6" height="11" font="5">2</text>
<text top="1069" left="451" width="16" height="15" font="4">20</text>
</page>
<page number="21" position="absolute" top="0" left="0" height="1188" width="918">
<text top="113" left="108" width="377" height="15" font="4">exhaustively this way, the result would contain |D|</text>
<text top="110" left="485" width="6" height="11" font="5">4</text>
<text top="113" left="499" width="311" height="15" font="4">ground clauses. Fortunately, in practice a</text>
<text top="133" left="108" width="702" height="15" font="4">vast majority of ground clauses are satisﬁed by evidence regardless of the assignments to unknown</text>
<text top="154" left="108" width="603" height="15" font="4">truth values; we can safely discard such clauses [42]. Consider the ground clause g</text>
<text top="158" left="713" width="6" height="11" font="5">¯</text>
<text top="161" left="711" width="7" height="11" font="5">d</text>
<text top="154" left="725" width="30" height="15" font="4">of F</text>
<text top="159" left="755" width="6" height="11" font="5">2</text>
<text top="154" left="768" width="42" height="15" font="4">where</text>
<text top="170" left="111" width="8" height="15" font="4">¯</text>
<text top="174" left="108" width="640" height="15" font="4">d =(‘Joe’, ‘P2’, ‘P3’, ‘DB’). Suppose that wrote(‘Joe’, ‘P3’) is known to be false, then g</text>
<text top="178" left="750" width="6" height="11" font="5">¯</text>
<text top="181" left="748" width="7" height="11" font="5">d</text>
<text top="174" left="762" width="48" height="15" font="4">will be</text>
<text top="194" left="108" width="369" height="15" font="4">satisﬁed no matter how the other atoms are set (g</text>
<text top="199" left="480" width="6" height="11" font="5">¯</text>
<text top="202" left="477" width="7" height="11" font="5">d</text>
<text top="194" left="491" width="312" height="15" font="4">is an implication). Hence, we can ignore g</text>
<text top="199" left="805" width="6" height="11" font="5">¯</text>
<text top="202" left="803" width="7" height="11" font="5">d</text>
<text top="215" left="108" width="174" height="15" font="4">during the search phase.</text>
<text top="235" left="133" width="677" height="15" font="4">Pushing this idea further, [41] proposes a method called “lazy inference” which is implemented</text>
<text top="255" left="108" width="702" height="17" font="4">by Alchemy. Speciﬁcally, Alchemy works under the more aggressive hypothesis that most atoms</text>
<text top="276" left="108" width="702" height="15" font="4">will be false in the ﬁnal solution, and in fact throughout the entire execution. To make this idea</text>
<text top="296" left="108" width="702" height="15" font="4">precise, call a ground clause active if it can be violated by ﬂipping zero or more active atoms,</text>
<text top="316" left="108" width="540" height="15" font="4">where an atom is active if its value ﬂips at any point during execution.</text>
<text top="316" left="663" width="147" height="15" font="4">Observe that in the</text>
<text top="337" left="108" width="279" height="15" font="4">preceding example the ground clause g</text>
<text top="341" left="389" width="6" height="11" font="5">¯</text>
<text top="344" left="387" width="7" height="11" font="5">d</text>
<text top="337" left="399" width="411" height="17" font="4">is not active. Alchemy keeps only active ground clauses</text>
<text top="357" left="108" width="702" height="15" font="4">in memory, which can be much smaller than the full set ground clauses. Furthermore, as on-the-ﬂy</text>
<text top="377" left="108" width="702" height="17" font="4">incremental grounding is more expensive than batch grounding, Alchemy uses the following one-</text>
<text top="398" left="108" width="702" height="15" font="4">step look-ahead strategy: assume all atoms are inactive and compute active clauses; activate the</text>
<text top="418" left="108" width="702" height="15" font="4">atoms in the grounding result and recompute active clauses. This “look-ahead” procedure could</text>
<text top="438" left="108" width="702" height="17" font="4">be repeatedly applied until convergence, resulting in an active closure. Tuffy implements this</text>
<text top="459" left="108" width="128" height="15" font="4">closure algorithm.</text>
<text top="479" left="133" width="677" height="15" font="4">In addition, we use a pruning strategy that ensures grounding to focus on only predicates and</text>
<text top="499" left="108" width="702" height="15" font="4">rules that are relevant to the query. Similar ideas can be found in KBMC [46] inference and the</text>
<text top="520" left="108" width="386" height="15" font="4">use of Rete algorithm [33] in production rule systems.</text>
<text top="562" left="108" width="31" height="16" font="1">A.4</text>
<text top="562" left="159" width="223" height="16" font="1">The WalkSAT Algorithm</text>
<text top="594" left="108" width="503" height="15" font="4">For completeness, we list the pseudocode of WalkSAT in Algorithm 1.</text>
<text top="631" left="108" width="299" height="17" font="4">Algorithm 1 The WalkSAT Algorithm</text>
<text top="655" left="108" width="193" height="15" font="4">Input: A: an set of atoms</text>
<text top="676" left="108" width="324" height="15" font="4">Input: C: an set of weighted ground clauses</text>
<text top="696" left="108" width="204" height="15" font="4">Input: MaxFlips, MaxTries</text>
<text top="716" left="108" width="83" height="15" font="4">Output: σ</text>
<text top="713" left="191" width="6" height="11" font="5">∗</text>
<text top="716" left="199" width="185" height="15" font="4">: a truth assignment to A</text>
<text top="739" left="117" width="11" height="12" font="7">1:</text>
<text top="738" left="136" width="115" height="14" font="4">lowCost ← +∞</text>
<text top="759" left="117" width="11" height="12" font="7">2:</text>
<text top="757" left="136" width="204" height="15" font="4">for try = 1 to MaxTries do</text>
<text top="779" left="117" width="11" height="12" font="7">3:</text>
<text top="777" left="152" width="269" height="15" font="4">σ ← a random truth assignment to A</text>
<text top="800" left="117" width="11" height="12" font="7">4:</text>
<text top="798" left="152" width="212" height="15" font="4">for flip = 1 to MaxFlips do</text>
<text top="820" left="117" width="11" height="12" font="7">5:</text>
<text top="818" left="169" width="264" height="15" font="4">pick a random c ∈ C that is violated</text>
<text top="840" left="117" width="11" height="12" font="7">6:</text>
<text top="840" left="169" width="314" height="14" font="4">rand ← a random ﬂoat between 0.0 and 1.0</text>
<text top="861" left="117" width="11" height="12" font="7">7:</text>
<text top="859" left="169" width="138" height="15" font="4">if rand ≤ 0.5 then</text>
<text top="881" left="117" width="11" height="12" font="7">8:</text>
<text top="879" left="185" width="171" height="15" font="4">ﬂip a random atom in c</text>
<text top="901" left="117" width="11" height="12" font="7">9:</text>
<text top="899" left="169" width="30" height="15" font="4">else</text>
<text top="922" left="110" width="18" height="12" font="7">10:</text>
<text top="920" left="185" width="323" height="15" font="4">ﬂip an atom in c s.t. the cost decreases most</text>
<text top="942" left="110" width="18" height="12" font="7">11:</text>
<text top="940" left="169" width="177" height="15" font="4">if cost &lt; lowCost then</text>
<text top="962" left="110" width="18" height="12" font="7">12:</text>
<text top="962" left="185" width="139" height="14" font="4">lowCost ← cost, σ</text>
<text top="957" left="325" width="6" height="11" font="5">∗</text>
<text top="959" left="336" width="30" height="15" font="4">← σ</text>
<text top="1069" left="451" width="16" height="15" font="4">21</text>
</page>
<page number="22" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="17" size="14" family="Times" color="#0000ff"/>
<text top="112" left="108" width="31" height="16" font="1">A.5</text>
<text top="112" left="159" width="254" height="16" font="1">Marginal Inference of MLNs</text>
<text top="144" left="108" width="702" height="15" font="4">In marginal inference, we are given a set of atoms together with a truth assignment to them.</text>
<text top="164" left="108" width="702" height="15" font="4">The goal is to estimate the marginal probability of this partial assignment. Since this problem</text>
<text top="185" left="108" width="702" height="15" font="4">is generally intractable, we usually resort to sampling methods. The state-of-the-art marginal</text>
<text top="205" left="108" width="702" height="17" font="4">inference algorithm of MLNs is MC-SAT [40], which is implemented in both Alchemy and Tuffy.</text>
<text top="225" left="108" width="702" height="15" font="4">In MC-SAT, each sampling step consists of a call to a heuristic SAT sampler named SampleSAT [45].</text>
<text top="246" left="108" width="702" height="17" font="4">Essentially, SampleSAT is a combination of simulated annealing and WalkSAT. And so, Tuffy is</text>
<text top="266" left="108" width="420" height="15" font="4">able to perform marginal inference more eﬃciently as well.</text>
<text top="314" left="108" width="17" height="19" font="3">B</text>
<text top="314" left="149" width="222" height="19" font="3">Material for Systems</text>
<text top="354" left="108" width="30" height="16" font="1">B.1</text>
<text top="354" left="158" width="354" height="16" font="1">An Example SQL Query For Grounding</text>
<text top="385" left="108" width="173" height="15" font="4">Consider the formula F</text>
<text top="391" left="281" width="6" height="11" font="5">3</text>
<text top="385" left="295" width="515" height="15" font="4">in Fig. 1. Suppose that the actual schemata of cat and refers are</text>
<text top="407" left="108" width="702" height="14" font="4">cat(tid, paper, category, truth, state) and refers(tid, paper1, paper2, truth, state), respectively.</text>
<text top="426" left="108" width="702" height="15" font="4">Given the evidence – as indicated by the “truth” attributes – we can ground the clauses for this</text>
<text top="446" left="108" width="281" height="15" font="4">formula using the following SQL query.</text>
<text top="477" left="109" width="59" height="14" font="17">S E L E C T</text>
<text top="477" left="181" width="245" height="14" font="4">- t1 . tid , - t2 . tid , t3 . tid</text>
<text top="497" left="109" width="38" height="14" font="17">F R O M</text>
<text top="497" left="161" width="255" height="14" font="4">cat t1 , r e f e r s t2 , cat t3</text>
<text top="518" left="109" width="49" height="14" font="17">W H E R E</text>
<text top="518" left="171" width="101" height="14" font="4">( t1 . t r u t h =</text>
<text top="518" left="274" width="70" height="14" font="17">N U L L OR</text>
<text top="518" left="357" width="91" height="14" font="4">t1 . t r u t h )</text>
<text top="538" left="109" width="28" height="14" font="17">AND</text>
<text top="538" left="150" width="101" height="14" font="4">( t2 . t r u t h =</text>
<text top="538" left="254" width="70" height="14" font="17">N U L L OR</text>
<text top="538" left="336" width="91" height="14" font="4">t2 . t r u t h )</text>
<text top="558" left="109" width="28" height="14" font="17">AND</text>
<text top="558" left="150" width="101" height="14" font="4">( t3 . t r u t h =</text>
<text top="558" left="254" width="111" height="14" font="17">N U L L OR NOT</text>
<text top="558" left="377" width="91" height="14" font="4">t3 . t r u t h )</text>
<text top="579" left="109" width="28" height="14" font="17">AND</text>
<text top="579" left="150" width="183" height="14" font="4">t1 . p a p e r = t2 . p a p e r 1</text>
<text top="599" left="109" width="28" height="14" font="17">AND</text>
<text top="599" left="150" width="234" height="14" font="4">t1 . c a t e g o r y = t3 . c a t e g o r y</text>
<text top="619" left="109" width="28" height="14" font="17">AND</text>
<text top="619" left="150" width="183" height="14" font="4">t2 . p a p e r 2 = t3 . p a p e r</text>
<text top="647" left="133" width="677" height="15" font="4">Note that the tids of t1 and t2 are negated because the corresponding predicates are negated</text>
<text top="668" left="108" width="169" height="15" font="4">in the clausal form of F</text>
<text top="673" left="277" width="6" height="11" font="5">3</text>
<text top="668" left="284" width="5" height="15" font="4">.</text>
<text top="710" left="108" width="30" height="16" font="1">B.2</text>
<text top="710" left="158" width="360" height="16" font="1">A Compilation Algorithm for Grounding</text>
<text top="742" left="108" width="702" height="17" font="4">Algorithm 2 is a basic algorithm of expressing the grounding process of an MLN formula in SQL.</text>
<text top="763" left="108" width="702" height="15" font="4">To support existential quantiﬁers, we used PostgreSQL’s array aggregate feature. The ideas in §A.3</text>
<text top="783" left="108" width="370" height="15" font="4">can be easily implemented on top of this algorithm.</text>
<text top="826" left="108" width="30" height="16" font="1">B.3</text>
<text top="826" left="158" width="318" height="16" font="1">Implementing WalkSAT in RDBMS</text>
<text top="858" left="108" width="702" height="15" font="4">WalkSAT is a stochastic local search algorithm; its random access patterns pose considerable chal-</text>
<text top="878" left="108" width="702" height="17" font="4">lenges to the design of Tuffy. More speciﬁcally, the following operations are diﬃcult to implement</text>
<text top="898" left="108" width="702" height="15" font="4">eﬃciently with on-disk data: 1) uniformly sample an unsatisﬁed clause; 2) random access (read-</text>
<text top="919" left="108" width="702" height="15" font="4">/write) to per-atom or per-clause data structures; and 3) traverse clauses involving a given atom.</text>
<text top="939" left="108" width="702" height="15" font="4">Atoms are cached as in-memory arrays, while the per-clause data structures are read-only. Each</text>
<text top="959" left="108" width="651" height="15" font="4">step of WalkSAT involves a scan over the clauses and many random accesses to the atoms.</text>
<text top="980" left="133" width="677" height="15" font="4">Although our design process iterated over numerous combinations of various design choices, we</text>
<text top="1000" left="108" width="702" height="15" font="4">were still unable to reduce the gap as reported in §4.2. For example, compared to clause table</text>
<text top="1020" left="108" width="702" height="15" font="4">scans, one might suspect that indexing could improve search speed by reading less data at each</text>
<text top="1069" left="451" width="16" height="15" font="4">22</text>
</page>
<page number="23" position="absolute" top="0" left="0" height="1188" width="918">
<text top="112" left="108" width="283" height="15" font="4">Algorithm 2 MLN Grounding in SQL</text>
<text top="139" left="108" width="231" height="17" font="4">Input: an MLN formula φ = ∨</text>
<text top="137" left="339" width="7" height="11" font="5">k</text>
<text top="147" left="339" width="21" height="11" font="5">i=1</text>
<text top="139" left="360" width="5" height="15" font="4">l</text>
<text top="145" left="365" width="4" height="11" font="5">i</text>
<text top="139" left="375" width="89" height="15" font="4">where each l</text>
<text top="145" left="464" width="4" height="11" font="5">i</text>
<text top="139" left="475" width="308" height="15" font="4">is a literal supported by predicate table r(l</text>
<text top="145" left="783" width="4" height="11" font="5">i</text>
<text top="139" left="788" width="6" height="15" font="4">)</text>
<text top="160" left="108" width="296" height="15" font="4">Output: a SQL query Q that grounds φ</text>
<text top="182" left="117" width="11" height="12" font="7">1:</text>
<text top="180" left="136" width="227" height="15" font="4">FROM clause of Q includes ‘r(l</text>
<text top="186" left="363" width="4" height="11" font="5">i</text>
<text top="180" left="368" width="18" height="15" font="4">) t</text>
<text top="186" left="386" width="4" height="11" font="5">i</text>
<text top="180" left="391" width="124" height="15" font="4">’ for each literal l</text>
<text top="186" left="515" width="4" height="11" font="5">i</text>
<text top="202" left="117" width="11" height="12" font="7">2:</text>
<text top="200" left="136" width="231" height="15" font="4">SELECT clause of Q contains ‘t</text>
<text top="206" left="366" width="4" height="11" font="5">i</text>
<text top="200" left="372" width="151" height="15" font="4">.aid’ for each literal l</text>
<text top="206" left="523" width="4" height="11" font="5">i</text>
<text top="223" left="117" width="11" height="12" font="7">3:</text>
<text top="221" left="136" width="293" height="15" font="4">For each positive (resp. negative) literal l</text>
<text top="226" left="429" width="4" height="11" font="5">i</text>
<text top="221" left="434" width="228" height="15" font="4">, there is a WHERE predicate ‘t</text>
<text top="226" left="662" width="4" height="11" font="5">i</text>
<text top="221" left="667" width="143" height="15" font="4">.truth = true’ (resp.</text>
<text top="241" left="136" width="10" height="15" font="4">‘t</text>
<text top="247" left="146" width="4" height="11" font="5">i</text>
<text top="241" left="151" width="107" height="15" font="4">.truth = false’)</text>
<text top="263" left="117" width="11" height="12" font="7">4:</text>
<text top="261" left="136" width="674" height="15" font="4">For each variable x in φ, there is a WHERE predicate that equates the corresponding columns</text>
<text top="282" left="136" width="25" height="15" font="4">of t</text>
<text top="287" left="160" width="4" height="11" font="5">i</text>
<text top="282" left="165" width="59" height="15" font="4">’s with l</text>
<text top="287" left="224" width="4" height="11" font="5">i</text>
<text top="282" left="235" width="89" height="15" font="4">containing x</text>
<text top="304" left="117" width="11" height="12" font="7">5:</text>
<text top="302" left="136" width="229" height="15" font="4">For each constant argument of l</text>
<text top="308" left="365" width="4" height="11" font="5">i</text>
<text top="302" left="370" width="412" height="15" font="4">, there is an equal-constant WHERE predicate for table t</text>
<text top="308" left="782" width="4" height="11" font="5">i</text>
<text top="324" left="117" width="11" height="12" font="7">6:</text>
<text top="322" left="136" width="398" height="15" font="4">Form a conjunction with the above WHERE predicates</text>
<text top="379" left="108" width="702" height="15" font="4">step. However, we actually found that the cost of maintaining indices often outweighs the beneﬁt</text>
<text top="399" left="108" width="702" height="15" font="4">provided by indexing. Moreover, we found it very diﬃcult to get around RDBMS overhead such</text>
<text top="419" left="108" width="260" height="15" font="4">as PostgreSQL’s mandatory MVCC.</text>
<text top="462" left="108" width="30" height="16" font="1">B.4</text>
<text top="462" left="158" width="352" height="16" font="1">Illustrating Tuﬀy’s Hybrid Architecture</text>
<text top="494" left="108" width="702" height="17" font="4">Figure 10 illustrates the hybrid memory management approach of Tuffy. Alchemy is a represen-</text>
<text top="514" left="108" width="702" height="17" font="4">tative of prior art MLN systems, which uses RAM for both grounding and search; Tuffy-mm is</text>
<text top="535" left="108" width="702" height="17" font="4">a version of Tuffy we developed that uses an RDBMS for all memory management; and Tuffy</text>
<text top="555" left="108" width="310" height="15" font="4">is the hybrid approach as discussed in §3.2.</text>
<text top="657" left="476" width="33" height="10" font="8">RDBMS </text>
<text top="653" left="389" width="23" height="10" font="8">RAM </text>
<text top="720" left="389" width="23" height="10" font="8">RAM </text>
<text top="724" left="476" width="33" height="10" font="8">RDBMS </text>
<text top="720" left="573" width="23" height="10" font="8">RAM </text>
<text top="657" left="567" width="33" height="10" font="8">RDBMS </text>
<text top="651" left="297" width="72" height="16" font="4">Grounding </text>
<text top="718" left="310" width="47" height="16" font="4">Search </text>
<text top="595" left="373" width="61" height="16" font="11"><b>Alchemy </b></text>
<text top="595" left="459" width="68" height="16" font="11"><b>Tuffy-mm </b></text>
<text top="595" left="567" width="37" height="16" font="11"><b>Tuffy </b></text>
<text top="776" left="318" width="281" height="15" font="4">Figure 10: Comparison of architectures</text>
<text top="839" left="108" width="30" height="16" font="1">B.5</text>
<text top="839" left="158" width="321" height="16" font="1">MLNs Causing MRF Fragmentation</text>
<text top="874" left="108" width="702" height="14" font="4">MLN rules usually model the interaction of relationships and attributes of some underlying entities.</text>
<text top="892" left="108" width="702" height="15" font="4">As such, one can deﬁne entity-based transitive closures, which directly corresponds to components</text>
<text top="912" left="108" width="702" height="15" font="4">in the MRF. Since in real world data the interactions are usually sparse, one can expect to see</text>
<text top="932" left="108" width="702" height="15" font="4">multiple components in the MRF. A concrete example is the paper classiﬁcation running example,</text>
<text top="953" left="108" width="702" height="15" font="4">where the primary entities are papers, and the interactions are deﬁned by citations and common</text>
<text top="973" left="108" width="651" height="15" font="4">authors. Indeed, our RC dataset yields hundreds of components in the MRF (see Table 5).</text>
<text top="1069" left="451" width="16" height="15" font="4">23</text>
</page>
<page number="24" position="absolute" top="0" left="0" height="1188" width="918">
<text top="112" left="108" width="30" height="16" font="1">B.6</text>
<text top="112" left="158" width="111" height="16" font="1">Theorem 3.1</text>
<text top="144" left="108" width="702" height="15" font="4">of Theorem 3.1. We follow the notations of the theorem. Without loss of generality and for ease</text>
<text top="164" left="108" width="602" height="15" font="4">of notation, suppose H = {1, . . . , N }. Denote by Ω the state space of G. Let Q</text>
<text top="170" left="710" width="7" height="11" font="5">k</text>
<text top="163" left="725" width="85" height="15" font="4">⊆ Ω be the</text>
<text top="185" left="108" width="524" height="15" font="4">set of states of G where there are exactly k non-optimal components.</text>
<text top="185" left="648" width="162" height="15" font="4">For any state x ∈ Ω,</text>
<text top="205" left="108" width="147" height="15" font="4">deﬁne H(x) = E[H</text>
<text top="210" left="255" width="7" height="11" font="5">x</text>
<text top="205" left="263" width="19" height="15" font="4">(Q</text>
<text top="210" left="282" width="6" height="11" font="5">0</text>
<text top="205" left="289" width="521" height="15" font="4">)], i.e., the expected hitting time of an optimal state from x. Deﬁne</text>
<text top="225" left="108" width="8" height="15" font="4">f</text>
<text top="231" left="116" width="7" height="11" font="5">k</text>
<text top="225" left="129" width="45" height="15" font="4">= min</text>
<text top="231" left="173" width="26" height="11" font="5">x∈Q</text>
<text top="235" left="199" width="6" height="8" font="6">k</text>
<text top="225" left="209" width="155" height="15" font="4">H(x); in particular, f</text>
<text top="231" left="364" width="6" height="11" font="5">0</text>
<text top="225" left="376" width="97" height="15" font="4">= 0. Deﬁne g</text>
<text top="231" left="473" width="7" height="11" font="5">k</text>
<text top="225" left="486" width="26" height="15" font="4">= f</text>
<text top="231" left="511" width="23" height="11" font="5">k+1</text>
<text top="224" left="539" width="24" height="15" font="4">− f</text>
<text top="231" left="563" width="7" height="11" font="5">k</text>
<text top="225" left="571" width="239" height="15" font="4">. For any x, y ∈ Ω, let Pr(x → y)</text>
<text top="246" left="108" width="702" height="15" font="4">be the transition probability of WalkSAT, i.e., the probability that next state will be y given current</text>
<text top="266" left="108" width="702" height="15" font="4">state x. Note that Pr(x → y) &gt; 0 only if y ∈ N (x), where N (x) is the set of states that diﬀer from</text>
<text top="286" left="108" width="418" height="15" font="4">x by at most one bit. For any A ⊆ Ω, deﬁne Pr(x → A) =</text>
<text top="294" left="547" width="25" height="11" font="5">y∈A</text>
<text top="286" left="576" width="78" height="15" font="4">Pr(x → y).</text>
<text top="307" left="133" width="103" height="15" font="4">For any x ∈ Q</text>
<text top="312" left="236" width="7" height="11" font="5">k</text>
<text top="307" left="244" width="66" height="15" font="4">, we have</text>
<text top="345" left="294" width="37" height="15" font="4">H(x)</text>
<text top="345" left="346" width="13" height="15" font="4">=</text>
<text top="345" left="374" width="25" height="15" font="4">1 +</text>
<text top="368" left="402" width="24" height="11" font="5">y∈Ω</text>
<text top="345" left="429" width="110" height="15" font="4">Pr(x → y)H(y)</text>
<text top="392" left="346" width="13" height="15" font="4">=</text>
<text top="392" left="374" width="25" height="15" font="4">1 +</text>
<text top="416" left="402" width="90" height="11" font="5">t∈{−1,0,1} y∈Q</text>
<text top="419" left="492" width="19" height="8" font="6">k+t</text>
<text top="392" left="514" width="110" height="15" font="4">Pr(x → y)H(y)</text>
<text top="439" left="346" width="52" height="15" font="4">≥ 1 +</text>
<text top="464" left="402" width="90" height="11" font="5">t∈{−1,0,1} y∈Q</text>
<text top="467" left="492" width="19" height="8" font="6">k+t</text>
<text top="440" left="514" width="82" height="15" font="4">Pr(x → y)f</text>
<text top="446" left="596" width="21" height="11" font="5">k+t</text>
<text top="440" left="618" width="5" height="15" font="4">.</text>
<text top="495" left="108" width="45" height="15" font="4">Deﬁne</text>
<text top="515" left="300" width="11" height="15" font="4">P</text>
<text top="512" left="313" width="7" height="11" font="5">x</text>
<text top="522" left="311" width="10" height="11" font="5">+</text>
<text top="515" left="326" width="89" height="15" font="4">= Pr(x → Q</text>
<text top="521" left="415" width="23" height="11" font="5">k+1</text>
<text top="515" left="439" width="11" height="15" font="4">),</text>
<text top="515" left="469" width="11" height="15" font="4">P</text>
<text top="512" left="481" width="7" height="11" font="5">x</text>
<text top="522" left="479" width="10" height="11" font="5">−</text>
<text top="515" left="494" width="89" height="15" font="4">= Pr(x → Q</text>
<text top="521" left="583" width="23" height="11" font="5">k−1</text>
<text top="515" left="607" width="11" height="15" font="4">),</text>
<text top="545" left="108" width="109" height="15" font="4">then Pr(x → Q</text>
<text top="551" left="217" width="7" height="11" font="5">k</text>
<text top="545" left="225" width="67" height="15" font="4">) = 1 − P</text>
<text top="542" left="294" width="7" height="11" font="5">x</text>
<text top="552" left="291" width="10" height="11" font="5">+</text>
<text top="544" left="306" width="27" height="15" font="4">− P</text>
<text top="542" left="335" width="7" height="11" font="5">x</text>
<text top="552" left="333" width="10" height="11" font="5">−</text>
<text top="545" left="343" width="36" height="15" font="4">, and</text>
<text top="582" left="281" width="95" height="15" font="4">H(x) ≥ 1 + f</text>
<text top="588" left="376" width="7" height="11" font="5">k</text>
<text top="582" left="383" width="45" height="15" font="4">(1 − P</text>
<text top="578" left="431" width="7" height="11" font="5">x</text>
<text top="589" left="428" width="10" height="11" font="5">+</text>
<text top="581" left="443" width="27" height="15" font="4">− P</text>
<text top="578" left="472" width="7" height="11" font="5">x</text>
<text top="589" left="470" width="10" height="11" font="5">−</text>
<text top="582" left="480" width="34" height="15" font="4">) + f</text>
<text top="588" left="515" width="23" height="11" font="5">k−1</text>
<text top="582" left="539" width="11" height="15" font="4">P</text>
<text top="578" left="551" width="7" height="11" font="5">x</text>
<text top="589" left="549" width="10" height="11" font="5">−</text>
<text top="582" left="563" width="24" height="15" font="4">+ f</text>
<text top="588" left="588" width="23" height="11" font="5">k+1</text>
<text top="582" left="612" width="11" height="15" font="4">P</text>
<text top="578" left="624" width="7" height="11" font="5">x</text>
<text top="589" left="622" width="10" height="11" font="5">+</text>
<text top="582" left="633" width="5" height="15" font="4">.</text>
<text top="619" left="133" width="296" height="15" font="4">Since this inequality holds for any x ∈ Q</text>
<text top="625" left="429" width="7" height="11" font="5">k</text>
<text top="619" left="437" width="200" height="15" font="4">, we can ﬁx it to be some x</text>
<text top="615" left="637" width="6" height="11" font="5">∗</text>
<text top="618" left="649" width="29" height="15" font="4">∈ Q</text>
<text top="625" left="678" width="7" height="11" font="5">k</text>
<text top="619" left="692" width="61" height="15" font="4">s.t. H(x</text>
<text top="615" left="753" width="6" height="11" font="5">∗</text>
<text top="619" left="760" width="38" height="15" font="4">) = f</text>
<text top="625" left="798" width="7" height="11" font="5">k</text>
<text top="619" left="805" width="5" height="15" font="4">.</text>
<text top="639" left="108" width="51" height="15" font="4">Then g</text>
<text top="645" left="159" width="23" height="11" font="5">k−1</text>
<text top="639" left="182" width="11" height="15" font="4">P</text>
<text top="636" left="195" width="7" height="11" font="5">x</text>
<text top="634" left="202" width="6" height="8" font="6">∗</text>
<text top="646" left="193" width="10" height="11" font="5">−</text>
<text top="638" left="214" width="53" height="15" font="4">≥ 1 + g</text>
<text top="645" left="267" width="7" height="11" font="5">k</text>
<text top="639" left="275" width="11" height="15" font="4">P</text>
<text top="636" left="288" width="7" height="11" font="5">x</text>
<text top="634" left="295" width="6" height="8" font="6">∗</text>
<text top="646" left="286" width="10" height="11" font="5">+</text>
<text top="639" left="302" width="120" height="15" font="4">, which implies g</text>
<text top="645" left="422" width="23" height="11" font="5">k−1</text>
<text top="638" left="451" width="25" height="15" font="4">≥ g</text>
<text top="645" left="476" width="7" height="11" font="5">k</text>
<text top="639" left="484" width="11" height="15" font="4">P</text>
<text top="636" left="496" width="7" height="11" font="5">x</text>
<text top="634" left="504" width="6" height="8" font="6">∗</text>
<text top="646" left="494" width="10" height="11" font="5">+</text>
<text top="639" left="511" width="19" height="15" font="4">/P</text>
<text top="636" left="532" width="7" height="11" font="5">x</text>
<text top="634" left="539" width="6" height="8" font="6">∗</text>
<text top="646" left="529" width="10" height="11" font="5">−</text>
<text top="639" left="546" width="5" height="15" font="4">.</text>
<text top="660" left="133" width="329" height="15" font="4">Now without loss of generality assume that in x</text>
<text top="656" left="463" width="6" height="11" font="5">∗</text>
<text top="660" left="470" width="21" height="15" font="4">, G</text>
<text top="665" left="491" width="6" height="11" font="5">1</text>
<text top="660" left="498" width="49" height="15" font="4">, . . . , G</text>
<text top="665" left="548" width="7" height="11" font="5">k</text>
<text top="660" left="559" width="169" height="15" font="4">are non-optimal while G</text>
<text top="665" left="728" width="23" height="11" font="5">k+1</text>
<text top="660" left="752" width="49" height="15" font="4">, . . . , G</text>
<text top="665" left="801" width="10" height="11" font="5">N</text>
<text top="680" left="108" width="132" height="15" font="4">are optimal. Let x</text>
<text top="676" left="240" width="6" height="11" font="5">∗</text>
<text top="687" left="240" width="4" height="11" font="5">i</text>
<text top="680" left="253" width="156" height="15" font="4">be the projection of x</text>
<text top="676" left="409" width="6" height="11" font="5">∗</text>
<text top="680" left="422" width="36" height="15" font="4">on G</text>
<text top="685" left="457" width="4" height="11" font="5">i</text>
<text top="680" left="462" width="89" height="15" font="4">. Then since</text>
<text top="731" left="269" width="11" height="15" font="4">P</text>
<text top="728" left="282" width="7" height="11" font="5">x</text>
<text top="725" left="289" width="6" height="8" font="6">∗</text>
<text top="738" left="279" width="10" height="11" font="5">−</text>
<text top="731" left="300" width="13" height="15" font="4">=</text>
<text top="716" left="337" width="7" height="11" font="5">k</text>
<text top="728" left="337" width="6" height="11" font="5">1</text>
<text top="720" left="347" width="8" height="15" font="4">v</text>
<text top="726" left="355" width="4" height="11" font="5">i</text>
<text top="720" left="360" width="16" height="15" font="4">(x</text>
<text top="717" left="376" width="6" height="11" font="5">∗</text>
<text top="728" left="376" width="4" height="11" font="5">i</text>
<text top="720" left="383" width="17" height="15" font="4">)α</text>
<text top="726" left="400" width="4" height="11" font="5">i</text>
<text top="720" left="405" width="16" height="15" font="4">(x</text>
<text top="717" left="421" width="6" height="11" font="5">∗</text>
<text top="728" left="421" width="4" height="11" font="5">i</text>
<text top="720" left="428" width="6" height="15" font="4">)</text>
<text top="741" left="357" width="10" height="11" font="5">N</text>
<text top="753" left="357" width="6" height="11" font="5">1</text>
<text top="745" left="372" width="8" height="15" font="4">v</text>
<text top="751" left="380" width="4" height="11" font="5">i</text>
<text top="745" left="385" width="16" height="15" font="4">(x</text>
<text top="742" left="400" width="6" height="11" font="5">∗</text>
<text top="753" left="400" width="4" height="11" font="5">i</text>
<text top="745" left="408" width="6" height="15" font="4">)</text>
<text top="731" left="436" width="5" height="15" font="4">,</text>
<text top="731" left="460" width="11" height="15" font="4">P</text>
<text top="728" left="472" width="7" height="11" font="5">x</text>
<text top="725" left="479" width="6" height="8" font="6">∗</text>
<text top="738" left="470" width="10" height="11" font="5">+</text>
<text top="731" left="491" width="13" height="15" font="4">=</text>
<text top="714" left="528" width="10" height="11" font="5">N</text>
<text top="726" left="528" width="23" height="11" font="5">k+1</text>
<text top="718" left="554" width="8" height="15" font="4">v</text>
<text top="724" left="562" width="5" height="11" font="5">j</text>
<text top="718" left="569" width="16" height="15" font="4">(x</text>
<text top="715" left="584" width="6" height="11" font="5">∗</text>
<text top="726" left="584" width="5" height="11" font="5">j</text>
<text top="718" left="592" width="16" height="15" font="4">)β</text>
<text top="724" left="607" width="5" height="11" font="5">j</text>
<text top="718" left="614" width="16" height="15" font="4">(x</text>
<text top="715" left="629" width="6" height="11" font="5">∗</text>
<text top="726" left="629" width="5" height="11" font="5">j</text>
<text top="718" left="637" width="6" height="15" font="4">)</text>
<text top="741" left="557" width="10" height="11" font="5">N</text>
<text top="753" left="557" width="6" height="11" font="5">1</text>
<text top="745" left="572" width="8" height="15" font="4">v</text>
<text top="751" left="579" width="4" height="11" font="5">i</text>
<text top="745" left="585" width="16" height="15" font="4">(x</text>
<text top="742" left="600" width="6" height="11" font="5">∗</text>
<text top="753" left="600" width="4" height="11" font="5">i</text>
<text top="745" left="607" width="6" height="15" font="4">)</text>
<text top="731" left="645" width="5" height="15" font="4">,</text>
<text top="779" left="108" width="56" height="15" font="4">we have</text>
<text top="810" left="301" width="8" height="15" font="4">g</text>
<text top="816" left="309" width="23" height="11" font="5">k−1</text>
<text top="809" left="338" width="25" height="15" font="4">≥ g</text>
<text top="816" left="363" width="7" height="11" font="5">k</text>
<text top="792" left="389" width="10" height="11" font="5">N</text>
<text top="805" left="389" width="23" height="11" font="5">k+1</text>
<text top="797" left="416" width="8" height="15" font="4">v</text>
<text top="802" left="424" width="5" height="11" font="5">j</text>
<text top="797" left="431" width="16" height="15" font="4">(x</text>
<text top="793" left="446" width="6" height="11" font="5">∗</text>
<text top="804" left="446" width="5" height="11" font="5">j</text>
<text top="797" left="453" width="16" height="15" font="4">)β</text>
<text top="802" left="469" width="5" height="11" font="5">j</text>
<text top="797" left="476" width="16" height="15" font="4">(x</text>
<text top="793" left="491" width="6" height="11" font="5">∗</text>
<text top="804" left="491" width="5" height="11" font="5">j</text>
<text top="797" left="498" width="6" height="15" font="4">)</text>
<text top="819" left="399" width="7" height="11" font="5">k</text>
<text top="832" left="399" width="6" height="11" font="5">1</text>
<text top="824" left="409" width="8" height="15" font="4">v</text>
<text top="829" left="417" width="4" height="11" font="5">i</text>
<text top="824" left="422" width="16" height="15" font="4">(x</text>
<text top="821" left="438" width="6" height="11" font="5">∗</text>
<text top="832" left="438" width="4" height="11" font="5">i</text>
<text top="824" left="445" width="17" height="15" font="4">)α</text>
<text top="829" left="462" width="4" height="11" font="5">i</text>
<text top="824" left="467" width="16" height="15" font="4">(x</text>
<text top="821" left="482" width="6" height="11" font="5">∗</text>
<text top="832" left="482" width="4" height="11" font="5">i</text>
<text top="824" left="489" width="6" height="15" font="4">)</text>
<text top="809" left="511" width="25" height="15" font="4">≥ g</text>
<text top="816" left="536" width="7" height="11" font="5">k</text>
<text top="799" left="546" width="65" height="15" font="4">r(N − k)</text>
<text top="821" left="573" width="9" height="15" font="4">k</text>
<text top="810" left="612" width="5" height="15" font="4">,</text>
<text top="851" left="108" width="400" height="15" font="4">where the second inequality follows from deﬁnition of r.</text>
<text top="872" left="133" width="241" height="15" font="4">For all k ≤ rN/(r + 2), we have g</text>
<text top="877" left="374" width="23" height="11" font="5">k−1</text>
<text top="871" left="403" width="33" height="15" font="4">≥ 2g</text>
<text top="877" left="436" width="7" height="11" font="5">k</text>
<text top="872" left="444" width="62" height="15" font="4">. Since g</text>
<text top="877" left="506" width="7" height="11" font="5">k</text>
<text top="871" left="518" width="114" height="15" font="4">≥ 1 for any k, f</text>
<text top="877" left="632" width="6" height="11" font="5">1</text>
<text top="872" left="644" width="25" height="15" font="4">= g</text>
<text top="877" left="669" width="6" height="11" font="5">0</text>
<text top="871" left="681" width="25" height="15" font="4">≥ 2</text>
<text top="869" left="706" width="55" height="11" font="5">rN/(r+2)</text>
<text top="872" left="762" width="5" height="15" font="4">.</text>
<text top="906" left="133" width="424" height="15" font="4">According to this theorem, the gap on Example 1 is at least 2</text>
<text top="903" left="557" width="23" height="11" font="5">N/3</text>
<text top="906" left="581" width="229" height="15" font="4">; in fact, a more detailed analysis</text>
<text top="926" left="108" width="222" height="15" font="4">reveals that the gap is at least</text>
<text top="921" left="344" width="28" height="11" font="5">N −1</text>
<text top="932" left="353" width="9" height="8" font="6">N</text>
<text top="942" left="355" width="5" height="8" font="6">2</text>
<text top="925" left="385" width="46" height="15" font="4">≈ Θ(2</text>
<text top="923" left="430" width="10" height="11" font="5">N</text>
<text top="926" left="442" width="8" height="15" font="4">/</text>
<text top="911" left="451" width="14" height="15" font="4">√</text>
<text top="926" left="464" width="26" height="15" font="4">N ).</text>
<text top="923" left="490" width="6" height="11" font="5">9</text>
<text top="926" left="507" width="303" height="15" font="4">Figure 11 shows the experiment results of</text>
<text top="951" left="108" width="702" height="17" font="4">running Alchemy, Tuffy, and Tuffy-p (i.e., Tuffy without partitioning) on Example 1 with</text>
<text top="971" left="108" width="127" height="15" font="4">1000 components.</text>
<text top="1000" left="127" width="5" height="8" font="6">9</text>
<text top="1003" left="133" width="459" height="12" font="7">Instead of applying the bound r directly, we can use the actual values of α</text>
<text top="1007" left="592" width="4" height="8" font="6">i</text>
<text top="1003" left="597" width="17" height="12" font="7">, β</text>
<text top="1007" left="614" width="4" height="8" font="6">i</text>
<text top="1003" left="619" width="43" height="12" font="7">, and v</text>
<text top="1007" left="662" width="4" height="8" font="6">i</text>
<text top="1003" left="672" width="138" height="12" font="7">to solve the recurrence</text>
<text top="1019" left="108" width="26" height="12" font="7">on g</text>
<text top="1024" left="134" width="6" height="8" font="6">k</text>
<text top="1019" left="141" width="4" height="12" font="7">.</text>
<text top="1069" left="451" width="16" height="15" font="4">24</text>
</page>
<page number="25" position="absolute" top="0" left="0" height="1188" width="918">
	<fontspec id="18" size="18" family="Times" color="#000000"/>
<text top="232" left="340" width="22" height="15" font="2">500</text>
<text top="193" left="332" width="30" height="15" font="2">1000</text>
<text top="154" left="332" width="30" height="15" font="2">1500</text>
<text top="115" left="332" width="30" height="15" font="2">2000</text>
<text top="251" left="372" width="7" height="15" font="2">0</text>
<text top="251" left="423" width="15" height="15" font="2">20</text>
<text top="251" left="478" width="15" height="15" font="2">40</text>
<text top="251" left="533" width="15" height="15" font="2">60</text>
<text top="251" left="589" width="15" height="15" font="2">80</text>
<text top="182" left="324" width="0" height="21" font="18"><b>cos</b></text>
<text top="155" left="324" width="0" height="21" font="18"><b>t </b></text>
<text top="273" left="443" width="90" height="21" font="18"><b>time (sec) </b></text>
<text top="125" left="394" width="188" height="17" font="11"><b>Performance on Example 1 </b></text>
<text top="164" left="454" width="97" height="15" font="2">Tuffy-p (dotted) </text>
<text top="182" left="454" width="94" height="15" font="2">Alchemy (solid) </text>
<text top="214" left="454" width="34" height="15" font="2">Tuffy </text>
<text top="319" left="292" width="334" height="15" font="4">Figure 11: Eﬀect of partitioning on Example 1</text>
<text top="371" left="133" width="677" height="15" font="4">Note that the analysis of Theorem 3.1 actually applies to not only WalkSAT, but stochastic</text>
<text top="391" left="108" width="702" height="15" font="4">local search in general. Since stochastic local search algorithms are used in many statistical models,</text>
<text top="411" left="108" width="702" height="15" font="4">we believe that our observation here and corresponding techniques have much wider implications</text>
<text top="432" left="108" width="152" height="17" font="4">than MLN inference.</text>
<text top="474" left="108" width="30" height="16" font="1">B.7</text>
<text top="474" left="158" width="271" height="16" font="1">Hardness of MRF Partitioning</text>
<text top="506" left="108" width="702" height="15" font="4">A bisection of a graph G = (V, E) with an even number of vertices is a pair of disjoint subsets</text>
<text top="526" left="108" width="10" height="15" font="4">V</text>
<text top="532" left="118" width="6" height="11" font="5">1</text>
<text top="526" left="125" width="17" height="15" font="4">, V</text>
<text top="532" left="141" width="6" height="11" font="5">2</text>
<text top="526" left="153" width="593" height="15" font="4">⊂ V of equal size. The cost of a bisection is the number of edges adjacent to both V</text>
<text top="532" left="746" width="6" height="11" font="5">1</text>
<text top="526" left="758" width="41" height="15" font="4">and V</text>
<text top="532" left="798" width="6" height="11" font="5">2</text>
<text top="526" left="805" width="5" height="15" font="4">.</text>
<text top="547" left="108" width="702" height="15" font="4">The problem of Minimum Graph Bisection (MGB) is to ﬁnd a bisection with minimum cost. This</text>
<text top="567" left="108" width="702" height="15" font="4">problem admits no PTAS [15]. The hardness of MGB directly implies the hardness of partitioning</text>
<text top="587" left="108" width="702" height="15" font="4">MRFs. As such, one may wonder if it still holds w.r.t. the domain size for a given MLN program</text>
<text top="608" left="108" width="528" height="15" font="4">(hence of size O(1)). The following theorem shows that the answer is yes.</text>
<text top="641" left="108" width="702" height="15" font="4">Theorem B.1. MGB can be reduced to the problem of ﬁnding a minimum bisection of the MRF</text>
<text top="661" left="108" width="229" height="15" font="4">generated an MLN of size O(1).</text>
<text top="694" left="108" width="563" height="15" font="4">Proof. Consider the MLN that contains a single formula of the following form:</text>
<text top="730" left="388" width="143" height="15" font="4">p(x), r(x, y) → p(y),</text>
<text top="766" left="108" width="702" height="15" font="4">where p is query and r is evidence. For any graph G = (V, E), we can set the domain of the</text>
<text top="787" left="108" width="702" height="15" font="4">predicates to be V , and let r = E. The MRF generated by the above MLN (using techniques in</text>
<text top="806" left="108" width="702" height="15" font="4">§A.3) is identical to G. Hence, if we could bisect the MRF in time polynomial in |V |, MGB would</text>
<text top="827" left="108" width="59" height="15" font="4">be in P.</text>
<text top="870" left="108" width="30" height="16" font="1">B.8</text>
<text top="870" left="158" width="257" height="16" font="1">MRF Partitioning Algorithm</text>
<text top="902" left="108" width="702" height="15" font="4">We provide a very simple MRF partitioning algorithm (Algorithm 3) that is inspired by Kruskal’s</text>
<text top="922" left="108" width="702" height="15" font="4">minimum spanning tree algorithm. Its greediness on clause wights serving as a simple heuristic to</text>
<text top="943" left="108" width="171" height="15" font="4">minimizing the cut size.</text>
<text top="963" left="133" width="677" height="15" font="4">To explain the partitioning procedure, we provide the following deﬁnitions. Each clause c in the</text>
<text top="983" left="108" width="623" height="15" font="4">MRF G = (V, E) is assigned to an atom in c. A partition of the MRF is a subgraph G</text>
<text top="989" left="731" width="4" height="11" font="5">i</text>
<text top="983" left="741" width="33" height="15" font="4">= (V</text>
<text top="989" left="774" width="4" height="11" font="5">i</text>
<text top="983" left="779" width="19" height="15" font="4">, E</text>
<text top="989" left="799" width="4" height="11" font="5">i</text>
<text top="983" left="804" width="6" height="15" font="4">)</text>
<text top="1003" left="108" width="218" height="15" font="4">deﬁned by a subset of atoms V</text>
<text top="1009" left="326" width="4" height="11" font="5">i</text>
<text top="1003" left="335" width="52" height="15" font="4">⊆ V ; E</text>
<text top="1009" left="387" width="4" height="11" font="5">i</text>
<text top="1003" left="398" width="337" height="15" font="4">is the set of clauses assigned to some atom in V</text>
<text top="1009" left="734" width="4" height="11" font="5">i</text>
<text top="1003" left="739" width="71" height="15" font="4">. The size</text>
<text top="1024" left="108" width="32" height="15" font="4">of G</text>
<text top="1029" left="140" width="4" height="11" font="5">i</text>
<text top="1024" left="151" width="474" height="15" font="4">as referred to by Algorithm 3 can be any monotone function in G</text>
<text top="1029" left="624" width="4" height="11" font="5">i</text>
<text top="1024" left="629" width="181" height="15" font="4">; in practice, it is deﬁned</text>
<text top="1069" left="451" width="16" height="15" font="4">25</text>
</page>
<page number="26" position="absolute" top="0" left="0" height="1188" width="918">
<text top="113" left="108" width="352" height="15" font="4">to be the total number of literals and atoms in G</text>
<text top="119" left="460" width="4" height="11" font="5">i</text>
<text top="113" left="465" width="345" height="15" font="4">. Note that when the parameter β is set to +∞,</text>
<text top="133" left="108" width="329" height="15" font="4">the output is the connected components of G.</text>
<text top="170" left="108" width="386" height="15" font="4">Algorithm 3 A Simple MRF Partitioning Algorithm</text>
<text top="195" left="108" width="430" height="17" font="4">Input: an MRF G = (V, E) with clause weights w : E → R</text>
<text top="216" left="108" width="218" height="15" font="4">Input: partition size bound β</text>
<text top="236" left="108" width="560" height="15" font="4">Output: a partitioning of V s.t. the size of each partition is no larger than β</text>
<text top="258" left="117" width="11" height="12" font="7">1:</text>
<text top="256" left="136" width="319" height="15" font="4">initialize hypergraph H = (V, F ) with F = ∅</text>
<text top="279" left="117" width="11" height="12" font="7">2:</text>
<text top="277" left="136" width="292" height="15" font="4">for all e ∈ E in |w|-descending order do</text>
<text top="299" left="117" width="11" height="12" font="7">3:</text>
<text top="297" left="152" width="434" height="15" font="4">F ← F ∪ e if afterwards no component in H is larger than β</text>
<text top="319" left="117" width="11" height="12" font="7">4:</text>
<text top="317" left="136" width="402" height="15" font="4">return the collection of per-component atom sets in H</text>
<text top="362" left="133" width="677" height="15" font="4">Our implementation of Algorithm 3 only uses RAM to maintain a union-ﬁnd structure of the</text>
<text top="383" left="108" width="702" height="15" font="4">nodes, and performs all other operations in the RDBMS. For example, we use SQL queries to</text>
<text top="403" left="108" width="667" height="15" font="4">“assign” clauses to atoms, and to compute the partition of clauses from a partition of atoms.</text>
<text top="451" left="108" width="17" height="19" font="3">C</text>
<text top="451" left="150" width="269" height="19" font="3">Material for Experiments</text>
<text top="491" left="108" width="30" height="16" font="1">C.1</text>
<text top="491" left="158" width="270" height="16" font="1">Alternative Search Algorithms</text>
<text top="523" left="108" width="702" height="15" font="4">As shown in §4.3, RDBMS-based implementation of WalkSAT is several orders of magnitude slower</text>
<text top="543" left="108" width="702" height="15" font="4">than the in-memory counter part. This gap is consistent with the I/O performance of disk vs. main</text>
<text top="563" left="108" width="702" height="15" font="4">memory. One might imagine some clever caching schemes for WalkSAT, but even assuming that</text>
<text top="584" left="108" width="702" height="15" font="4">a ﬂip incurs only one random I/O operation (which is usually on the order of 10 ms), the ﬂipping</text>
<text top="604" left="108" width="702" height="15" font="4">rate of RDBMS-based search is still no more than 100 ﬂips/sec. Thus, it is highly unlikely that</text>
<text top="624" left="108" width="592" height="15" font="4">disk-based search implementations could catch up to their in-memory counterpart.</text>
<text top="645" left="133" width="677" height="15" font="4">We explored alternative search algorithms by designing a MaxSAT algorithm called SweepSAT</text>
<text top="665" left="108" width="702" height="15" font="4">that is more I/O friendly than WalkSAT. Although experiments show that SweepSAT gives faster</text>
<text top="685" left="108" width="702" height="15" font="4">search speed than WalkSAT when both are implemented in an RDBMS, we eventually decided that</text>
<text top="706" left="108" width="702" height="15" font="4">search algorithmics is orthogonal to our investigation of how the hybrid architecture and the idea</text>
<text top="726" left="108" width="331" height="17" font="4">of partitioning can beneﬁt the Tuffy system.</text>
<text top="769" left="108" width="30" height="16" font="1">C.2</text>
<text top="769" left="158" width="292" height="16" font="1">Lesion Study of Tuﬀy Grounding</text>
<text top="801" left="108" width="702" height="17" font="4">To understand which part of the RDBMS contributes the most to Tuffy’s fast grounding speed,</text>
<text top="821" left="108" width="702" height="15" font="4">we conduct a lesion study by comparing the grounding time in three settings: 1) full optimizer,</text>
<text top="841" left="108" width="702" height="15" font="4">where the RDBMS is free to optimize SQL queries in all ways; 2) ﬁxed join order, where we force</text>
<text top="862" left="108" width="702" height="17" font="4">the RDBMS to use the same join order as Alchemy does; 3) ﬁxed join algorithm, where we</text>
<text top="882" left="108" width="702" height="15" font="4">force the RDBMS to use nested loop join only. The results are shown in Table 6. Clearly, being</text>
<text top="902" left="108" width="567" height="17" font="4">able to use various join algorithms is the key to Tuffy’s fast grounding speed.</text>
<text top="945" left="108" width="30" height="16" font="1">C.3</text>
<text top="945" left="158" width="263" height="16" font="1">Data Loading and Parallelism</text>
<text top="977" left="108" width="702" height="15" font="4">To validate the importance of batch data loading and parallelism (§3.3), we run three versions of</text>
<text top="1000" left="108" width="702" height="14" font="4">Tuffy on the IE and RC datasets: 1) Tuﬀy, which has batch loading but no parallelism; 2) Tuﬀy-</text>
<text top="1018" left="108" width="709" height="15" font="4">batch, which loads components one by one and does not use parallelism; and 3) Tuﬀy+parallelism,</text>
<text top="1069" left="451" width="16" height="15" font="4">26</text>
</page>
<page number="27" position="absolute" top="0" left="0" height="1188" width="918">
<text top="111" left="434" width="22" height="13" font="2">LP</text>
<text top="111" left="479" width="18" height="13" font="2">IE</text>
<text top="111" left="544" width="25" height="13" font="2">RC</text>
<text top="111" left="616" width="24" height="13" font="2">ER</text>
<text top="129" left="299" width="92" height="13" font="2">Full optimizer</text>
<text top="129" left="449" width="7" height="13" font="2">6</text>
<text top="129" left="482" width="15" height="13" font="2">13</text>
<text top="129" left="554" width="15" height="13" font="2">40</text>
<text top="129" left="618" width="22" height="13" font="2">106</text>
<text top="148" left="292" width="105" height="13" font="2">Fixed join order</text>
<text top="148" left="449" width="7" height="13" font="2">7</text>
<text top="148" left="482" width="15" height="13" font="2">13</text>
<text top="148" left="554" width="15" height="13" font="2">43</text>
<text top="148" left="618" width="22" height="13" font="2">111</text>
<text top="166" left="277" width="134" height="13" font="2">Fixed join algorithm</text>
<text top="166" left="434" width="22" height="13" font="2">112</text>
<text top="166" left="475" width="22" height="13" font="2">306</text>
<text top="166" left="516" width="53" height="13" font="2">&gt;36,000</text>
<text top="166" left="587" width="53" height="13" font="2">&gt;16,000</text>
<text top="202" left="330" width="257" height="15" font="4">Table 6: Grounding time in seconds</text>
<text top="240" left="500" width="18" height="13" font="2">IE</text>
<text top="240" left="537" width="25" height="13" font="2">RC</text>
<text top="259" left="377" width="76" height="13" font="2">Tuﬀy-batch</text>
<text top="259" left="496" width="22" height="13" font="2">448</text>
<text top="259" left="539" width="22" height="13" font="2">133</text>
<text top="277" left="398" width="34" height="13" font="2">Tuﬀy</text>
<text top="277" left="496" width="22" height="13" font="2">117</text>
<text top="277" left="546" width="15" height="13" font="2">77</text>
<text top="296" left="357" width="117" height="13" font="2">Tuﬀy+parallelism</text>
<text top="296" left="503" width="15" height="13" font="2">28</text>
<text top="296" left="546" width="15" height="13" font="2">42</text>
<text top="331" left="280" width="358" height="15" font="4">Table 7: Comparison of execution time in seconds</text>
<text top="384" left="108" width="702" height="15" font="4">which has both batch loading and parallelism. We use the same WalkSAT parameters on each com-</text>
<text top="404" left="108" width="122" height="15" font="4">ponent (up to 10</text>
<text top="401" left="230" width="6" height="11" font="5">6</text>
<text top="404" left="243" width="142" height="15" font="4">ﬂips per component</text>
<text top="401" left="385" width="13" height="11" font="5">10</text>
<text top="404" left="398" width="412" height="15" font="4">) and run all three settings on the same machine with an</text>
<text top="425" left="108" width="558" height="15" font="4">8-core Xeon CPU. Table 7 shows the end-to-end running time of each setting.</text>
<text top="445" left="133" width="677" height="15" font="4">Clearly, loading the components one by one incurs signiﬁcant I/O cost on both datasets. The</text>
<text top="465" left="108" width="702" height="15" font="4">grounding + partitioning time of IE and RC are 11 seconds and 35 seconds, respectively. Hence,</text>
<text top="485" left="108" width="503" height="15" font="4">Tuﬀy+parallelism achieved roughly 6-time speed up on both datasets.</text>
<text top="533" left="108" width="19" height="19" font="3">D</text>
<text top="533" left="151" width="256" height="19" font="3">Extended Related Work</text>
<text top="574" left="108" width="702" height="17" font="4">The idea of using the stochastic local search algorithm WalkSAT to ﬁnd the most likely world is due</text>
<text top="594" left="108" width="702" height="17" font="4">to Kautz et al. [14]. Singla and Domingos [43] proposed lazy grounding and applies it to WalkSAT,</text>
<text top="614" left="108" width="702" height="17" font="4">resulting in an algorithm called LazySAT that is implemented in Alchemy. The idea of ignoring</text>
<text top="635" left="108" width="702" height="15" font="4">ground clauses that are satisﬁed by evidence is highlighted as an eﬀective way of speeding up the</text>
<text top="658" left="108" width="702" height="14" font="4">MLN grounding process in Shavlik and Natarajan [42], which formulates the grounding process</text>
<text top="675" left="108" width="702" height="15" font="4">as nested loops and provides heuristics to approximate the optimal looping order. Mihalkova and</text>
<text top="696" left="108" width="702" height="15" font="4">Mooney [36] also employ a bottom-up approach, but they address structure learning of MLNs</text>
<text top="716" left="108" width="702" height="15" font="4">whereas we focus on inference. As an orthogonal approach to scaling MLN inference, Mihalkova</text>
<text top="736" left="108" width="702" height="15" font="4">and Richardson [37] study how to avoid redundant computation by clustering similar query literals.</text>
<text top="756" left="108" width="702" height="17" font="4">It is an interesting problem to incorporate their techniques into Tuffy. While Tuffy employs</text>
<text top="777" left="108" width="702" height="15" font="4">the simple WalkSAT algorithm, there are more advanced techniques for MAP inference [32, 35]; we</text>
<text top="797" left="108" width="702" height="17" font="4">plan to integrate them into upcoming versions of Tuffy. For hypergraph partitioning, there are</text>
<text top="817" left="108" width="702" height="15" font="4">established solutions such as hMETIS [13]. However, their existing implementations are limited by</text>
<text top="838" left="108" width="702" height="15" font="4">memory size, and it is challenging to implement the same algorithms eﬃciently for on-disk data –</text>
<text top="858" left="108" width="306" height="15" font="4">which motivated us to design Algorithm 3.</text>
<text top="878" left="133" width="677" height="15" font="4">The technique of cutset conditioning [17] from the SAT and probabilistic inference literature is</text>
<text top="899" left="108" width="702" height="15" font="4">closely related to our partitioning technique [31, 38]. Cutset conditioning recursively conditions on</text>
<text top="919" left="108" width="702" height="15" font="4">cutsets of graphical models, and at each step exhaustively enumerates all conﬁgurations of the cut,</text>
<text top="939" left="108" width="702" height="15" font="4">which is impractical in our scenario: even for small datasets, the cut size can easily be thousands,</text>
<text top="960" left="108" width="702" height="15" font="4">making exhaustive enumeration infeasible. Instead, we use a Gauss-Seidel strategy, which proves</text>
<text top="980" left="108" width="702" height="15" font="4">to be eﬃcient and eﬀective in practice. Additionally, our conceptual goals are diﬀerent: our goal is</text>
<text top="1009" left="121" width="11" height="8" font="6">10</text>
<text top="1012" left="133" width="442" height="12" font="7">Early stopping could occur for components that have zero-cost solutions.</text>
<text top="1069" left="451" width="16" height="15" font="4">27</text>
</page>
<page number="28" position="absolute" top="0" left="0" height="1188" width="918">
<text top="113" left="108" width="702" height="15" font="4">to ﬁnd an analytic formula that quantiﬁes the eﬀect of partitioning and then, we use this formula</text>
<text top="133" left="108" width="702" height="15" font="4">to optimize the IO and scheduling behavior of a wide class of local search algorithms; in contrast,</text>
<text top="154" left="108" width="413" height="15" font="4">prior work focuses on designing new inference algorithms.</text>
<text top="174" left="133" width="677" height="17" font="4">Finally, we note that there are statistical-logical frameworks similar to MLNs, such as Proba-</text>
<text top="194" left="108" width="702" height="15" font="4">bilistic Relational Models [34] and Relational Markov Models [44]. Since inference on those models</text>
<text top="215" left="108" width="702" height="17" font="4">also requires grounding and search, we believe that the lessons we learned with MLNs will carry</text>
<text top="235" left="108" width="129" height="15" font="4">over to them, too.</text>
<text top="281" left="108" width="113" height="19" font="3">References</text>
<text top="318" left="108" width="669" height="13" font="2">[31] D. Allen and A. Darwiche. New advances in inference by recursive conditioning. In UAI03, 2003.</text>
<text top="345" left="108" width="702" height="13" font="2">[32] J. Duchi, D. Tarlow, G. Elidan, and D. Koller. Using combinatorial optimization within max-product</text>
<text top="363" left="139" width="207" height="13" font="2">belief propagation. NIPS, 2007.</text>
<text top="390" left="108" width="702" height="13" font="2">[33] C. Forgy. Rete: A fast algorithm for the many pattern/many object pattern match problem. Artiﬁcial</text>
<text top="408" left="139" width="116" height="13" font="2">intelligence, 1982.</text>
<text top="435" left="108" width="702" height="13" font="2">[34] N. Friedman, L. Getoor, D. Koller, and A. Pfeﬀer. Learning probabilistic relational models. In IJCAI,</text>
<text top="453" left="139" width="34" height="13" font="2">1999.</text>
<text top="480" left="108" width="702" height="13" font="2">[35] R. Gupta, A. Diwan, and S. Sarawagi. Eﬃcient inference with cardinality-based clique potentials. In</text>
<text top="497" left="139" width="82" height="13" font="2">ICML, 2007.</text>
<text top="524" left="108" width="700" height="13" font="2">[36] L. Mihalkova and R. Mooney. Bottom-up learning of Markov logic network structure. In ICML, 2007.</text>
<text top="551" left="108" width="702" height="13" font="2">[37] L. Mihalkova and M. Richardson. Speeding up inference in statistical relational learning by clustering</text>
<text top="569" left="139" width="380" height="13" font="2">similar query literals. Inductive Logic Programming, 2010.</text>
<text top="596" left="108" width="702" height="13" font="2">[38] T. Park and A. Van Gelder. Partitioning methods for satisﬁability testing on large formulas. Automated</text>
<text top="614" left="139" width="109" height="13" font="2">Deduction, 1996.</text>
<text top="641" left="108" width="638" height="13" font="2">[39] J. Pearl. Probabilistic reasoning in intelligent systems: networks of plausible inference. 1988.</text>
<text top="668" left="108" width="702" height="13" font="2">[40] H. Poon and P. Domingos. Sound and eﬃcient inference with probabilistic and deterministic dependen-</text>
<text top="686" left="139" width="135" height="13" font="2">cies. In AAAI, 2006.</text>
<text top="713" left="108" width="702" height="13" font="2">[41] H. Poon, P. Domingos, and M. Sumner. A general method for reducing the complexity of relational</text>
<text top="731" left="139" width="332" height="13" font="2">inference and its application to MCMC. AAAI-08.</text>
<text top="758" left="108" width="702" height="13" font="2">[42] J. Shavlik and S. Natarajan. Speeding up inference in Markov logic networks by preprocessing to reduce</text>
<text top="775" left="139" width="371" height="13" font="2">the size of the resulting grounded network. In IJCAI-09.</text>
<text top="802" left="108" width="630" height="13" font="2">[43] P. Singla and P. Domingos. Memory-eﬃcient inference in relational domains. In AAAI ’06.</text>
<text top="829" left="108" width="702" height="13" font="2">[44] B. Taskar, P. Abbeel, and D. Koller. Discriminative probabilistic models for relational data. In UAI,</text>
<text top="847" left="139" width="34" height="13" font="2">2002.</text>
<text top="874" left="108" width="702" height="13" font="2">[45] W. Wei, J. Erenrich, and B. Selman. Towards eﬃcient sampling: Exploiting random walk strategies.</text>
<text top="892" left="139" width="101" height="13" font="2">In AAAI, 2004.</text>
<text top="919" left="108" width="702" height="13" font="2">[46] M. Wellman, J. Breese, and R. Goldman. From knowledge bases to decision models. The Knowledge</text>
<text top="937" left="139" width="171" height="13" font="2">Engineering Review, 1992.</text>
<text top="1069" left="451" width="16" height="15" font="4">28</text>
</page>
</pdf2xml>
