=======================================PAGE========================================
=======================================COL========================================
0	<text font="0" height="23" left="368" textpieces="0" top="205" width="182">using an RDBMS</text>
 
0	<text font="1" height="16" left="341" textpieces="0" top="283" width="253">University of Wisconsin-Madison</text>
 
0	<text font="1" height="17" left="310" textpieces="0" top="303" width="317">{leonn,chrisre,anhai,shavlik}@cs.wisc.edu</text>
 
0	<text font="1" height="16" left="391" textpieces="0" top="339" width="136">December 7, 2010</text>
 
0	<text font="2" height="13" left="426" textpieces="0" top="402" width="66">Abstract</text>
 
0	<text font="2" height="16" left="171" textpieces="0" top="429" width="598">Markov Logic Networks (MLNs) have emerged as a powerful framework that combines sta-</text>
 
0	<text font="2" height="13" left="149" textpieces="0" top="447" width="620">tistical and logical reasoning; they have been applied to many data intensive problems including</text>
 
0	<text font="2" height="16" left="149" textpieces="0" top="465" width="620">information extraction, entity resolution, and text mining. Current implementations of MLNs</text>
 
0	<text font="2" height="13" left="149" textpieces="0" top="483" width="620">do not scale to real-world data sets, which is preventing their wide-spread adoption. We present</text>
 
0	<text font="2" height="13" left="149" textpieces="0" top="503" width="620">Tuffy that achieves scalability via three novel contributions: (1) a bottom-up approach to</text>
 
0	<text font="2" height="13" left="149" textpieces="0" top="519" width="620">grounding that allows us to leverage the full power of the relational optimizer, (2) a novel hy-</text>
 
0	<text font="2" height="13" left="149" textpieces="0" top="572" width="620">of stochastic local search. We leverage (3) to build novel partitioning, loading, and parallel</text>
 
0	<text font="2" height="13" left="149" textpieces="0" top="590" width="620">algorithms. We show that our approach outperforms state-of-the-art implementations in both</text>
 
0	<text font="2" height="13" left="149" textpieces="0" top="608" width="366">quality and speed on several publicly available datasets.</text>
 
0	<text font="3" height="19" left="108" textpieces="1" top="655" width="169">1  Introduction</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="695" width="702">Over the past few years, Markov Logic Networks (MLNs) have emerged as a powerful and popular</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="716" width="702">framework that combines logical and probabilistic reasoning. MLNs have been successfully applied</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="736" width="702">to a wide variety of data management problems, including information extraction, entity resolution,</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="756" width="702">and text mining. In contrast to probability models like factor graphs [24] that require complex</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="899" width="702">structured data (e.g., entities, relationships) from Web data, then use this structured data to answer</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="939" width="702">kinds of extractions into one coherent picture. To accomplish this goal, it is critical that MLNs</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="960" width="615">scale to large data sets, and we have been put in charge of investigating this problem.</text>
 
0	<text font="4" height="17" left="133" textpieces="0" top="980" width="677">Unfortunately, none of the current MLN implementations scale beyond relatively small data</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="1000" width="702">sets (and even on many of these data sets, existing implementations routinely take hours to run).</text>
 
0	<text font="4" height="15" left="455" textpieces="0" top="1069" width="8">1</text>
 
=======================================PAGE========================================
=======================================COL========================================
0	<text font="4" height="17" left="108" textpieces="0" top="154" width="702">paper, we describe our system, Tuffy, that leverages an RDBMS to address the above scalability</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="174" width="63">problem.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="215" width="702">ence, since typically a model is learned once, and then an application may perform inference many</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="235" width="702">times using the same model; hence inference is an on-line process, which must be fast. Conceptu-</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="255" width="702">ally, inference in MLNs has two phases: a grounding phase, which constructs a large, weighted SAT</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="276" width="702">formula, and a search phase, which searches for a low cost (weight) assignment (called a solution)</text>
 
0	<text font="4" height="17" left="108" textpieces="1" top="296" width="702">to the SAT formula from grounding (using WalkSAT [14], a local search procedure).1 Grounding</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="337" width="702">the state-of-the-art MLN inference engine, Alchemy [7], spends over 96% of its execution time in</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="357" width="702">grounding. The state-of-the-art strategy for the grounding phase (and the one used by Alchemy)</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="377" width="702">is a top-down procedure (similar to the proof strategy in Prolog). In contrast, we propose a bottom-</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="398" width="702">up grounding strategy. Intuitively, bottom-up grounding allows Tuffy to fully exploit the RDBMS</text>
 
0	<text font="4" height="15" left="133" textpieces="0" top="479" width="677">But not all phases are well-optimized by the RDBMS: during the search phase, we found that</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="499" width="702">the RDBMS implementation performed poorly. The underlying reason is a fundamental problem</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="520" width="702">for pushing local search procedures into an RDBMS: search procedures often perform inherently</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="540" width="702">sequential, random data accesses. Consequently, any RDBMS-based solution must execute a large</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="560" width="702">number of disk accesses, each of which has a substantial overhead (due to the RDBMS) versus direct</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="581" width="702">main-memory access. Not surprisingly, given the same amount of time, an in-memory solution can</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="621" width="702">an RDBMS. Thus, to achieve competitive performance, we are forced to develop a novel hybrid</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="642" width="702">architecture that supports local search procedures in main memory whenever possible. This is our</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="662" width="214">second technical contribution.</text>
 
0	<text font="4" height="17" left="133" textpieces="0" top="682" width="677">Our third contribution is a simple partitioning technique that allows Tuffy to introduce paral-</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="702" width="702">lelism and use less memory than state-of-the-art approaches. Surprisingly, this same technique often</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="723" width="702">allows Tuffy to speed up the search phase exponentially. The underlying idea is simple: in many</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="743" width="702">cases, a local search problem can be divided into multiple independent subproblems. For example,</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="763" width="702">the formula that is output by the grounding phase may consist of multiple connected components.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="804" width="702">dently results in exponentially faster search than running the larger global problem (Thm. 3.1). An</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="824" width="702">application of our theorem shows that on an information extraction testbed, a system that is not</text>
 
0	<text font="4" height="17" left="108" textpieces="1" top="845" width="702">aware of the partitioning phenomenon (such as Alchemy) must take at least 2200more steps than</text>
 
0	<text font="4" height="14" left="108" textpieces="0" top="888" width="702">Tuffy within one minute has higher quality than those found by non-partitioning systems (such</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="906" width="303">as Alchemy) even after running for days.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="946" width="702">problem suggests that in some cases, further decomposing the search space may improve the overall</text>
 
0	<text font="6" height="8" left="127" textpieces="0" top="975" width="682">1We discuss maximum a posteriori inference (highest probability world) which is critical for many integration</text>
 
0	<text font="7" height="12" left="108" textpieces="0" top="1011" width="259">we apply our results to marginal inference.</text>
 
0	<text font="4" height="15" left="455" textpieces="0" top="1069" width="8">2</text>
 
=======================================PAGE========================================
=======================================COL========================================
0	<text font="4" height="15" left="108" textpieces="0" top="133" width="702">the formula from grounding (and so the search space) to minimize the number of formula that are</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="154" width="702">split between partitions, and (2) augmenting the search algorithm to be aware of partitioning.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="194" width="702">partitioning algorithm. For the second problem, we apply a technique from non-linear optimization</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="215" width="702">to leverage the insights gained from our characterization of the phenomenon described above. The</text>
 
0	<text font="4" height="14" left="108" textpieces="0" top="258" width="702">Tuffy (using 15MB of RAM) produces much better result quality in minutes than Alchemy</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="276" width="702">(using 2.8GB of RAM) even after days of running. In fact, Tuffy is able to answer queries on a</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="296" width="702">version of the RC dataset that is over 2 orders of magnitude larger. (We estimate that Alchemy</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="316" width="315">would need 280GB+ of RAM to process it.)</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="360" width="702">Related Work  MLNs are an integral part of state-of-the-art approaches in a variety of applica-</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="380" width="702">tions: natural language processing [22], ontology matching [30], information extraction [18], entity</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="400" width="702">resolution [26], data mining [27], etc. And so, there is an application push to support MLNs. In</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="441" width="631">apply fundamental data management principles to improve scalability and performance.</text>
 
0	<text font="4" height="15" left="133" textpieces="0" top="461" width="680">Pushing statistical reasoning models inside a database system has been a goal of many projects [5,</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="481" width="702">11, 12, 20, 29]. Most closely related is the BayesStore project, in which the database essentially</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="502" width="702">stores Bayes Nets [17] and allows these networks to be retrieved for inference by an external pro-</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="522" width="702">gram. In contrast, Tuffy uses an RDBMS to optimize the inference procedure. The Monte-Carlo</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="563" width="702">approach can be viewed as pushing classical search inside the database engine. One way to view</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="603" width="702">in contrast, we take an existing, widely used class of algorithms (local search), and our focus is to</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="624" width="332">leverage the RDBMS to improve performance.</text>
 
0	<text font="4" height="15" left="133" textpieces="0" top="644" width="677">There has also been an extensive amount of work on probabilistic databases [1, 2, 4, 19] that</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="664" width="702">deal with simpler probabilistic models. Finding the most likely world is trivial in these models;</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="685" width="702">in contrast, it is highly non-trivial in MLNs (in fact, it is NP-hard [6]). MLNs also provide an</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="705" width="702">appealing answer for one of the most pressing questions in the area of probabilistic databases:</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="746" width="702">core technical challenge Tuffy addresses, which is handling AI-style search inside a database.</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="809" width="702">Contributions, Validation, and Outline  To summarize, we make the following contributions:</text>
 
0	<text font="4" height="15" left="149" textpieces="0" top="863" width="661">bottom-up grounding that allows us to leverage the RDBMS optimizer; this idea improves</text>
 
0	<text font="4" height="15" left="149" textpieces="0" top="884" width="516">the performance of the grounding phase by several orders of magnitude.</text>
 
0	<text font="4" height="15" left="149" textpieces="0" top="928" width="661">inference. By itself, this architecture is orders of magnitude more scalable and, given the</text>
 
0	<text font="4" height="15" left="149" textpieces="0" top="948" width="614">same amount of time, performs orders of magnitude more search steps than prior art.</text>
 
0	<text font="4" height="15" left="149" textpieces="0" top="1013" width="661">gorithms. Additionally, we show that for any MLN with an MRF that contains multiple</text>
 
0	<text font="4" height="15" left="455" textpieces="0" top="1069" width="8">3</text>
 
=======================================PAGE========================================
=======================================COL========================================
0	<text font="2" height="12" left="126" textpieces="0" top="129" width="147">paper(PaperID, URL)</text>
 
0	<text font="2" height="12" left="127" textpieces="0" top="147" width="145">wrote(Author, Paper)</text>
 
0	<text font="2" height="12" left="127" textpieces="0" top="165" width="145">refers(Paper, Paper)</text>
 
0	<text font="2" height="12" left="128" textpieces="0" top="183" width="142">cat(Paper, Category)</text>
 
0	<text font="2" height="13" left="295" textpieces="1" top="110" width="85">weight   rule</text>
 
0	<text font="2" height="13" left="312" textpieces="3" top="128" width="423">5      cat(p, c1), cat(p, c2) =&gt; c1 = c2                       (F1)</text>
 
0	<text font="2" height="13" left="312" textpieces="2" top="146" width="422">1      wrote(x, p1), wrote(x, p2), cat(p1, c) =&gt; cat(p2, c)   (F2)</text>
 
0	<text font="2" height="13" left="312" textpieces="2" top="164" width="422">2      cat(p1, c), refers(p1, p2) =&gt; cat(p2, c)               (F3)</text>
 
0	<text font="2" height="13" left="175" textpieces="2" top="218" width="673">Schema                                  A Markov Logic Program                               Evidence</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="253" width="702">Figure 1: A Sample Markov Logic Program: The goal is to classify papers by category. As evidence</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="274" width="702">we are given author and citation information of all papers, as well as the labels of a subset of the</text>
 
0	<text font="4" height="15" left="149" textpieces="0" top="364" width="661">components, partitioning exponentially improves search speed, and we quantify this theoret-</text>
 
0	<text font="4" height="15" left="149" textpieces="0" top="384" width="41">ically.</text>
 
0	<text font="4" height="15" left="149" textpieces="0" top="428" width="661">of the partitioning phenomenon. These techniques result in our highest quality, most space-</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="479" width="702">We present an extensive experimental study on a diverse set of MLN testbeds to demonstrate that</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="499" width="702">our system Tuffy is able to get better result quality more quickly and work over larger datasets</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="519" width="263">than the state-of-the-art approaches.</text>
 
0	<text font="3" height="19" left="108" textpieces="1" top="567" width="176">2  Preliminaries</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="607" width="702">We illustrate a Markov Logic Network program using the example of classifying papers by topic</text>
 
0	<text font="1" height="16" left="108" textpieces="1" top="669" width="233">2.1  The Syntax of MLNs</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="701" width="702">Figure 1 shows an example input MLN program for Tuffy that is used to classify paper references</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="722" width="702">by topic area, such as databases, systems, AI, etc. In this example, a user gives Tuffy a set of</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="742" width="702">relations that capture information about the papers in her dataset: she has extracted authors and</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="762" width="702">citations and stored in them in the relations wrote(Author,Paper) and refers(Paper,Paper). She</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="783" width="702">may also provide evidence, which is data that she knows to be true (or false). Here, the evidence</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="803" width="702">shows that Joe wrote papers P1 and P2 and P1 cited another paper P3. In the relation cat, she</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="823" width="702">provides Tuffy with a subset of papers and the categories into which they fall. The cat relation is</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="844" width="702">incomplete: some papers are not labeled. We can think of each possible labeling of these papers as</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="905" width="44">world.</text>
 
0	<text font="4" height="15" left="133" textpieces="0" top="922" width="677">To tell the system which possible world it should produce, the user provides (in addition to the</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="940" width="702">above data) a set of rules that incorporate their knowledge of the problem. A simple example rule</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="958" width="38">is F1:</text>
 
0	<text font="2" height="12" left="331" textpieces="1" top="978" width="255">cat(p, c1), cat(p, c2) =&gt; c1 = c2  (F1)</text>
 
0	<text font="4" height="15" left="115" textpieces="1" top="1003" width="695">Intuitively, F1 says that a paper should be in one category. In MLNs, this rule may be hard,</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="1024" width="702">meaning that it behaves like a standard key constraint: in any possible world, each paper must</text>
 
0	<text font="4" height="15" left="455" textpieces="0" top="1069" width="8">4</text>
 
=======================================PAGE========================================
=======================================COL========================================
0	<text font="4" height="15" left="108" textpieces="0" top="113" width="702">be in at most one category. This rule may also be soft, meaning that it may be violated in some</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="133" width="702">possible worlds. For example, in some worlds a paper may be in two categories. Soft rules also have</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="154" width="701">weights that intuitively tell us how likely the rule is to hold in a possible world. In this example, F1</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="194" width="702">in a single category compared to being in 2 categories.2 MLNs can also involve data in non-trivial</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="258" width="702">Query Model  Given the data and the rules, a user may write arbitrary queries in terms of the</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="299" width="702">example, the category of each unlabeled paper is unknown, and so to answer a query the system</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="319" width="441">infers the most likely labels for each paper from the evidence.</text>
 
0	<text font="1" height="16" left="108" textpieces="1" top="362" width="219">2.2  Semantics of MLNs</text>
 
0	<text font="5" height="11" left="644" textpieces="0" top="470" width="7">d</text>
 
0	<text font="4" height="15" left="656" textpieces="0" top="463" width="154">called a ground clause</text>
 
0	<text font="5" height="11" left="163" textpieces="0" top="488" width="7">d</text>
 
0	<text font="4" height="15" left="176" textpieces="3" top="481" width="634">denotes the result of substituting each variable xi of F with di. For example, for F3the</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="518" width="16">is:</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="586" width="701">ground predicate or atom for short. In the worst case there are D3 ground clauses for F3. For each</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="606" width="701">formula Fi (for i = 1 . . . N ), we perform the above process. Each ground clause g of a formula Fi</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="626" width="702">is assigned the same weight, wi. So, a ground clause of F1 has weight 5, while any ground clause</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="687" width="702">(instance) I we say a ground clause g is violated if w(g) &gt; 0 and g is false in I or if w(g) &lt; 0 and</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="708" width="702">g is true in I. We denote the set of ground clauses violated in a world I as V (I). The cost of the</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="728" width="70">world I is</text>
 
0	<text font="4" height="15" left="380" textpieces="0" top="748" width="67">cost(I) =</text>
 
0	<text font="4" height="15" left="496" textpieces="1" top="747" width="314">|w(g)|                                   (1)</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="908" width="702">most likely world. On the other hand the most likely world may have positive cost. There are two</text>
 
0	<text font="6" height="8" left="127" textpieces="0" top="957" width="682">2In MLNs, it is not possible to give a direct probabilistic interpretation of weights [21]. In practice, the weights</text>
 
0	<text font="7" height="12" left="108" textpieces="0" top="977" width="702">associated to formula are learned,which compensates for their non-intuitive nature. In this work, we do not discuss</text>
 
0	<text font="7" height="12" left="108" textpieces="0" top="993" width="158">the mechanics of learning.</text>
 
0	<text font="6" height="8" left="127" textpieces="0" top="1007" width="682">3Clausal form is a disjunction of positive or negative literals. For example, the rule is R(a) =&gt; R(b) is not in</text>
 
0	<text font="4" height="15" left="455" textpieces="0" top="1069" width="8">5</text>
 
=======================================PAGE========================================
=======================================COL========================================
0	<text font="4" height="17" left="108" textpieces="0" top="113" width="702">and marginal inference, where we want to compute marginal probabilities. Tuffy is capable of</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="133" width="702">both types of inference, but we present only MAP inference in the body of this paper. We refer</text>
 
0	<text font="1" height="16" left="108" textpieces="1" top="196" width="127">2.3  Inference</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="228" width="702">We now describe the state of the art of inference for MLNs (as in Alchemy, the reference MLN</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="249" width="122">implementation).</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="292" width="702">Grounding  Conceptually, to obtain the ground clauses of an MLN formula F , the most straight-</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="312" width="702">forward way is to enumerate all possible assignments to the free variables in F . There have been</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="333" width="702">several heuristics in the literature that improve the grounding process by pruning groundings that</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="394" width="702">node and each clause is a hyperedge. This graph structure is often called a Markov Random Field</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="457" width="702">Search  Finding a most likely world of an MLN is a generalization of the (NP-hard) MaxSAT</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="477" width="702">problem. In this paper we concentrate on one of the most popular heuristic search algorithms,</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="498" width="702">WalkSAT [14], which is used by Alchemy. WalkSAT works by repeatedly selecting a random</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="559" width="702">the goal of any system that executes such a search procedure is: execute more search steps in the</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="579" width="702">same amount of time. To keep the comparison with Alchemy fair, we only discuss WalkSAT in</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="643" width="702">Problem Description  The primary challenge that we address in this paper is scaling both</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="663" width="702">phases of MAP inference algorithms, grounding and search, using an RDBMS. Second, our goal</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="744" width="702">performing inference (search) on large MLNs, and (3) designing partitioning and partition-aware</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="765" width="506">search algorithms that preserve (or enhance) search quality and speed.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="853" width="702">In this section, we describe our technical contributions: a bottom-up grounding approach to fully</text>
 
0	<text font="1" height="16" left="108" textpieces="1" top="956" width="398">3.1  Grounding with a Bottom-up Approach</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="988" width="702">We describe how Tuffy performs grounding. In contrast to top-down approaches (similar to</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="1009" width="702">Prolog) that employ nested loops, Tuffy takes a bottom-up approach (similar to Datalog) and</text>
 
0	<text font="4" height="15" left="455" textpieces="0" top="1069" width="8">6</text>
 
=======================================PAGE========================================
=======================================COL========================================
0	<text font="4" height="15" left="108" textpieces="0" top="113" width="702">expresses grounding as a sequence of SQL queries. Each SQL query is optimized by the RDBMS,</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="133" width="702">which allows Tuffy to complete the grounding process orders of magnitude more quickly than</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="154" width="123">prior approaches.</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="215" width="702">P , and truth is a three-valued attribute that indicates if apis true or false (in the evidence), or not</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="255" width="284">using standard bulk-loading techniques.</text>
 
0	<text font="4" height="17" left="133" textpieces="0" top="276" width="677">In Tuffy, we produce an output table C(cid, lits, weight) where each row corresponds to a</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="296" width="702">single ground clause. Here, cid is the id of a ground clause, lits is an array that stores the atom</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="316" width="702">id of each literal in this clause (and whether or not it is negated), and weight is the weight of</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="377" width="702">query Q for F that joins together the relations corresponding to the predicates in F to produce</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="398" width="702">the atom ids of the ground clauses (and whether or not they are negated). The join conditions in</text>
 
0	<text font="1" height="16" left="108" textpieces="1" top="481" width="367">3.2  A Hybrid Architecture for Inference</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="513" width="702">Our initial prototype of Tuffy ran both grounding and search in the RDBMS. While the grounding</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="533" width="702">phase described in the previous section had good performance and scalability, we found that search</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="635" width="702">number of random accesses to the data representing ground clauses and atoms. Moreover, the data</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="655" width="702">that is accessed in one iteration depends on the data that is accessed in the previous iteration. And</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="696" width="702">per data access. Thus, we implement a hybrid architecture where the RDBMS performs grounding</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="716" width="702">and Tuffy is able to read the result of grounding from the RDBMS into memory and perform</text>
 
0	<text font="4" height="14" left="108" textpieces="0" top="800" width="161">Tuffy in more detail.</text>
 
0	<text font="4" height="15" left="133" textpieces="0" top="818" width="677">While it is clear that this hybrid approach is at least as scalable as a direct memory imple-</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="838" width="702">mentation, such as Alchemy; in fact, there are cases where Tuffy can run in-memory search</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="858" width="702">while Alchemy would crash. The reason is that the space requirement of a purely in-memory</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="879" width="702">implementation is determined by the peak memory footprint throughout grounding and search,</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="899" width="702">whereas Tuffy needs main memory only for search. For example, on a dataset called Relational</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="940" width="304">On RC, Tuffy uses only 19 MB of RAM.</text>
 
0	<text font="4" height="15" left="455" textpieces="0" top="1069" width="8">7</text>
 
=======================================PAGE========================================
=======================================COL========================================
0	<text font="1" height="16" left="108" textpieces="1" top="112" width="374">3.3  Partitioning to Improve Performance</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="185" width="702">By splitting the problem into smaller pieces, we can reduce the memory footprint and introduce</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="205" width="702">parallelism, which conceptually breaks the sequential nature of the search. These are expected</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="246" width="281">speed, a point that we return to below.</text>
 
0	<text font="4" height="17" left="133" textpieces="0" top="266" width="677">First, observe that the logical forms of MLNs often result in an MRF with multiple disjoint</text>
 
0	<text font="4" height="15" left="361" textpieces="0" top="360" width="76">costG(I) =</text>
 
0	<text font="4" height="15" left="483" textpieces="1" top="360" width="73">costGi(Ii).</text>
 
0	<text font="4" height="15" left="133" textpieces="0" top="472" width="677">Component detection is done after the grounding phase and before the search phase, as follows.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="596" width="702">on each component sequentially one by one may incur many I/O operations, as there may be many</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="616" width="702">partitions. For example, the MRF of the Information Extraction (IE) dataset contains thousands</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="636" width="702">of 2-cliques and 3-cliques. One solution is to group the components into batches. The goal is to</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="656" width="702">minimize the total number of batches (and thereby the I/O cost of loading), and the constraint is</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="677" width="702">that each batch cannot exceed the memory budget. This is essentially the bin packing problem,</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="697" width="418">and we implement the First Fit Decreasing algorithm [28].</text>
 
0	<text font="4" height="17" left="133" textpieces="0" top="717" width="677">Once the partitions are in memory, we can take advantage of parallelism. In Tuffy, we execute</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="738" width="702">threads using a round-robin policy. It is future work to consider more advanced thread scheduling</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="758" width="537">policies, such as the Gittins Index in the multi-armed bandit literature [10].</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="801" width="702">Quality  Although processing each component individually produces solutions that are no worse</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="821" width="702">than processing the whole graph at once, we give an example to illustrate that independently</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="841" width="558">processing each component may result in exponentially faster speed of search.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="874" width="702">Example 1 Consider an MRF consisting of N identical connected components each containing</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="895" width="333">two atoms {Xi, Yi} and three weighted clauses</text>
 
0	<text font="4" height="15" left="108" textpieces="2" top="979" width="702">from a random state, the expected hitting time4 of the optimal state, i.e. (X1, Y1) = (1, 1), is no</text>
 
0	<text font="6" height="8" left="127" textpieces="0" top="1007" width="682">4The hitting time is a standard notion from Markov Chains [9], it is a random variable that represents the number</text>
 
0	<text font="4" height="15" left="455" textpieces="0" top="1069" width="8">8</text>
 
=======================================PAGE========================================
=======================================COL========================================
0	<text font="2" height="15" left="415" textpieces="1" top="126" width="91">G1         G2 </text>
 
0	<text font="7" height="13" left="456" textpieces="0" top="119" width="10">e </text>
 
0	<text font="7" height="13" left="437" textpieces="1" top="131" width="48">a      b </text>
 
0	<text font="4" height="15" left="404" textpieces="0" top="180" width="110">Figure 2: Ex. 2</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="232" width="702">more than 4. Therefore, if we run WalkSAT on each component separately, the expected runtime</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="252" width="702">of reaching the optimum is no more than 4N . Now consider the case where we run WalkSAT on</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="293" width="702">one by one. As the number of optimal components increases, however, it becomes more and more</text>
 
0	<text font="4" height="15" left="133" textpieces="0" top="392" width="677">To generalize this example, we need some notations. Let G be an MRF with components</text>
 
0	<text font="4" height="15" left="108" textpieces="3" top="413" width="702">G1, . . . , GN. For i = 1, . . . , N , let Oi be the set of optimal states of Gi, and Si the set of non-</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="453" width="701">probability of WalkSAT running on Gi, i.e., the probability that one step of WalkSAT would take</text>
 
0	<text font="4" height="15" left="108" textpieces="3" top="474" width="702">Gi from x to y. Let x be a state of Gi, denote by vi(x) the number of violated clauses in Gi at</text>
 
0	<text font="4" height="15" left="330" textpieces="0" top="609" width="53">r(H) =</text>
 
0	<text font="5" height="11" left="552" textpieces="0" top="603" width="26">i(x)</text>
 
0	<text font="4" height="15" left="584" textpieces="0" top="609" width="5">.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="654" width="702">Theorem 3.1. Let H be any non-empty subset of {1, . . . , N } s.t. r = r(H) &gt; 0, then Whole-</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="675" width="702">MRF WalkSAT on G takes at least 2|H|r/(2+r) more steps than component-wise WalkSAT on the</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="695" width="125">components of G.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="769" width="702">information extraction (IE) benchmark dataset, there is some H with |H| = 1196 and r(H) = 0.5.</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="810" width="702">lower cost solutions in minutes than non-partition aware approaches such as Alchemy produce</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="830" width="112">even after days.</text>
 
0	<text font="1" height="16" left="108" textpieces="1" top="873" width="288">3.4  Further Partitioning MRFs</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="905" width="702">Although our algorithms are more scalable than prior approaches, if the largest component does</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="946" width="702">slower. Intuitively, if the graph is only weakly connected, then we should still be able to get the</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="966" width="576">exponential speed up of partitioning. To gain intuition, we consider an example.</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="1000" width="701">Example 2 Consider an MRF consisting of two equally sized subgraphs G1and G2, plus an edge</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="1020" width="702">e = (a, b) between them (Figure 2). Suppose that the expected hitting time of WalkSAT on Giis Hi.</text>
 
0	<text font="4" height="15" left="455" textpieces="0" top="1069" width="8">9</text>
 
=======================================PAGE========================================
=======================================COL========================================
0	<text font="4" height="15" left="108" textpieces="2" top="113" width="702">Since H1 and H2 are essentially independent, the hitting time of WalkSAT on G could be roughly</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="133" width="701">H1H2. On the other hand, consider the following scheme: enumerate all possible truth assignments</text>
 
0	<text font="4" height="15" left="108" textpieces="2" top="174" width="702">assignment, run WalkSAT on G1 and G2 independently. Clearly, the overall hitting time is no</text>
 
0	<text font="4" height="15" left="108" textpieces="4" top="194" width="702">more than 2(H1+ H2), which is a huge improvement over H1H2 since Hi is usually a high-order</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="215" width="348">polynomial or even exponential in the size of Gi.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="289" width="152">each of them in turn.</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="332" width="702">MRF Partitioning  Intuitively, to maximally utilize the memory budget, we want to partition</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="353" width="702">the MRF into roughly equal sizes; to minimize information loss, we want to minimize total weight</text>
 
0	<text font="5" height="11" left="794" textpieces="0" top="399" width="15">2|.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="542" width="702">to approximate (unless P = NP, there is no PTAS). In fact, the problem we are facing (multi-</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="562" width="702">way hypergraph partitioning) is more challenging than graph bisection, and has been extensively</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="583" width="702">studied [13, 25]. And so, we design a simple, greedy partitioning algorithm: it assigns each clause</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="603" width="702">to a bin in descending order by clause weight, subject to the constraint that no component in the</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="687" width="702">central challenge is that a clause in the cut may depend on atoms in two distinct partitions. Hence,</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="707" width="702">there are dependencies between the partitions. We exploit the idea in Example 2 to design the</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="748" width="702">nonlinear optimization [3, pg. 219]. Denote by X1, . . . , Xk the states (i.e., truth assignments to the</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="768" width="346">atoms) of the partitions. First initialize Xi= x0</text>
 
0	<text font="5" height="11" left="448" textpieces="0" top="776" width="4">i</text>
 
0	<text font="4" height="15" left="461" textpieces="0" top="768" width="349">for i = 1 . . . k. For t = 1 . . . T , for i = 1 . . . k, run</text>
 
0	<text font="5" height="11" left="215" textpieces="0" top="796" width="4">i</text>
 
0	<text font="4" height="15" left="243" textpieces="0" top="788" width="134">conditioned on {xt</text>
 
0	<text font="5" height="11" left="372" textpieces="0" top="796" width="5">j</text>
 
0	<text font="5" height="11" left="496" textpieces="0" top="796" width="5">j</text>
 
0	<text font="5" height="11" left="687" textpieces="0" top="796" width="4">i</text>
 
0	<text font="4" height="15" left="693" textpieces="0" top="788" width="117">. Finally, return</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="810" width="25">{xT</text>
 
0	<text font="5" height="11" left="126" textpieces="0" top="819" width="4">i</text>
 
0	<text font="3" height="19" left="108" textpieces="1" top="859" width="169">4  Experiments</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="940" width="34">goal.</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="983" width="702">Experimental Setup  We select Alchemy, the currently most widely used MLN system, as our</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="1003" width="702">comparison point. Alchemy and Tuffy are implemented in C++ and Java, respectively. The</text>
 
0	<text font="4" height="15" left="451" textpieces="0" top="1069" width="16">10</text>
 
=======================================PAGE========================================
=======================================COL========================================
0	<text font="4" height="15" left="108" textpieces="0" top="113" width="702">on an Intel Core2 at 2.4GHz with 4 GB of RAM running Red Hat Enterprise Linux 5. For fair</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="133" width="594">comparison, in all experiments Tuffy runs a single thread unless otherwise noted.</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="177" width="702">Datasets  We run Alchemy and Tuffy on four datasets; three of them (including their MLNs)</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="197" width="702">are taken directly from the Alchemy website [7]: Link Prediction (LP), given an administrative</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="217" width="702">database of a CS department, the goal is to predict student-adviser relationships; Information</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="238" width="702">Extraction (IE), given a set of Citeseer citations, the goal is to extract from them structured records</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="278" width="702">citation records based on word similarity. These tasks have been extensively used in prior work.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="319" width="548">contains all the rules in Figure 1. Table 1 contains statistics about the data.</text>
 
1	<text font="2" height="13" left="436" textpieces="3" top="354" width="189">LP      IE     RC    ER</text>
 
3	<text font="2" height="13" left="293" textpieces="4" top="373" width="332">#relations             22       18        4     10</text>
 
3	<text font="2" height="13" left="293" textpieces="4" top="391" width="332">#rules                 94      1K       15   3.8K</text>
 
3	<text font="2" height="13" left="293" textpieces="4" top="409" width="331">#entities             302    2.6K     51K    510</text>
 
3	<text font="2" height="13" left="293" textpieces="4" top="426" width="331">#evidence tuples     731   0.25M   0.43M    676</text>
 
3	<text font="2" height="13" left="293" textpieces="4" top="444" width="332">#query atoms      4.6K   0.34M     10K   16K</text>
 
3	<text font="2" height="13" left="293" textpieces="4" top="462" width="331">#components           1     5341      489       1</text>
 
4	<text font="4" height="15" left="365" textpieces="0" top="498" width="189">Table 1: Dataset statistics</text>
 
0	<text font="1" height="16" left="108" textpieces="1" top="562" width="253">4.1  High-level Performance</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="594" width="702">We empirically demonstrate that Tuffy with all the techniques we have described has faster</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="614" width="702">grounding, higher search speed, lower memory usage, and in some cases produces much better</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="634" width="702">solutions than a competitor main memory approach, Alchemy. Recall that the name of the game</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="655" width="702">is to produce low-cost solutions quickly. With this in mind, we run Tuffy and Alchemy on each</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="675" width="702">dataset for 7500 seconds, and track the cost of the best solution found up to any moment; on</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="695" width="702">datasets that have multiple components, namely IE and RC, we apply the partitioning strategy</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="797" width="702">begins only when grounding is completed. We analyze the experiment results in more details in</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="817" width="157">the following sections.</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="892" width="702">We validate that the RDBMS-based grounding approach in Tuffy allows us to complete the</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="932" width="702">run Tuffy and Alchemy on the four datasets, and show their grounding time in Table 2. We can</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="953" width="702">see that Tuffy outperforms Alchemy by orders of magnitude at run time in the grounding phase</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="993" width="702">study, and found that sort join and hash join algorithms (along with predicate pushdown) are the</text>
 
0	<text font="4" height="15" left="451" textpieces="0" top="1069" width="16">11</text>
 
=======================================PAGE========================================
=======================================COL========================================
0	<text font="9" height="13" left="471" textpieces="0" top="182" width="44">1.0E+03</text>
 
0	<text font="9" height="13" left="471" textpieces="0" top="150" width="44">2.0E+03</text>
 
0	<text font="9" height="13" left="471" textpieces="0" top="117" width="44">3.0E+03</text>
 
0	<text font="9" height="13" left="524" textpieces="2" top="200" width="134">0         20         40</text>
 
0	<text font="10" height="15" left="465" textpieces="0" top="157" width="0">cost </text>
 
0	<text font="11" height="17" left="607" textpieces="0" top="117" width="16">IE </text>
 
0	<text font="4" height="17" left="619" textpieces="0" top="132" width="62">Alchemy </text>
 
0	<text font="4" height="17" left="555" textpieces="0" top="172" width="38">Tuffy </text>
 
0	<text font="9" height="13" left="241" textpieces="0" top="183" width="44">0.0E+00</text>
 
0	<text font="9" height="13" left="241" textpieces="0" top="161" width="44">1.0E+04</text>
 
0	<text font="9" height="13" left="241" textpieces="0" top="139" width="44">2.0E+04</text>
 
0	<text font="9" height="13" left="241" textpieces="0" top="117" width="44">3.0E+04</text>
 
0	<text font="9" height="13" left="294" textpieces="2" top="200" width="159">0           50          100</text>
 
0	<text font="10" height="15" left="235" textpieces="0" top="158" width="0">cost </text>
 
0	<text font="11" height="17" left="342" textpieces="0" top="120" width="20">LP </text>
 
0	<text font="4" height="17" left="380" textpieces="1" top="142" width="-21">Alchemy                  Tuffy </text>
 
0	<text font="9" height="13" left="470" textpieces="0" top="287" width="44">0.0E+00</text>
 
0	<text font="9" height="13" left="470" textpieces="0" top="254" width="44">1.0E+05</text>
 
0	<text font="9" height="13" left="470" textpieces="0" top="222" width="44">2.0E+05</text>
 
0	<text font="9" height="13" left="523" textpieces="1" top="304" width="170">0   2000 4000 6000 8000</text>
 
0	<text font="10" height="15" left="464" textpieces="0" top="262" width="0">cost </text>
 
0	<text font="11" height="17" left="602" textpieces="0" top="220" width="21">ER </text>
 
0	<text font="7" height="13" left="535" textpieces="0" top="242" width="163">Alchemy grounding took 7 hr. </text>
 
0	<text font="4" height="17" left="585" textpieces="0" top="258" width="38">Tuffy </text>
 
0	<text font="9" height="13" left="241" textpieces="0" top="287" width="44">0.0E+00</text>
 
0	<text font="9" height="13" left="241" textpieces="0" top="265" width="44">2.0E+03</text>
 
0	<text font="9" height="13" left="241" textpieces="0" top="244" width="44">4.0E+03</text>
 
0	<text font="9" height="13" left="241" textpieces="0" top="222" width="44">6.0E+03</text>
 
0	<text font="9" height="13" left="294" textpieces="3" top="304" width="142">0    2000  4000  6000</text>
 
0	<text font="10" height="15" left="235" textpieces="0" top="262" width="0">cost </text>
 
0	<text font="11" height="17" left="341" textpieces="0" top="224" width="22">RC </text>
 
0	<text font="4" height="17" left="385" textpieces="0" top="242" width="62">Alchemy </text>
 
0	<text font="4" height="17" left="330" textpieces="0" top="254" width="38">Tuffy </text>
 
0	<text font="4" height="17" left="183" textpieces="0" top="347" width="552">Figure 3: Time-cost plots of Alchemy vs. Tuffy; the x axes are time (sec)</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="400" width="702">obviates the need for Alchemy to reimplement all of the optimization techniques in an RDBMS</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="420" width="94">from scratch.</text>
 
1	<text font="4" height="15" left="416" textpieces="3" top="453" width="181">LP  IE    RC     ER</text>
 
3	<text font="4" height="14" left="320" textpieces="4" top="476" width="277">Alchemy    48   13  3,913  23,891</text>
 
3	<text font="4" height="14" left="332" textpieces="4" top="497" width="266">Tuffy       6   13     40     106</text>
 
4	<text font="4" height="15" left="350" textpieces="0" top="532" width="218">Table 2: Grounding time (sec)</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="631" width="702">We validate two technical claims: (1) the hybrid memory management strategy of Tuffy (even</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="651" width="702">without our partitioning optimizations) has comparable search rates to existing main memory</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="671" width="702">implementations (and much faster than RDBMS-based implementation) and (2) Tuffy maintains</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="692" width="702">a much smaller memory footprint (again without partitioning). Thus, we compare three approaches:</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="732" width="702">version of Tuffy (also without partitioning) that implements RDBMS-based WalkSAT (detailed</text>
 
0	<text font="4" height="15" left="133" textpieces="0" top="773" width="677">Figure 4 illustrates the time-cost plots on LP and RC of all three approaches. We see from</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="793" width="702">RC that Tuffy-p is able to ground much more quickly than Alchemy (40s compared to 3913s).</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="874" width="702">rate, which is the number of steps performed by WalkSAT per second. As shown in Table 3, the</text>
 
0	<text font="4" height="17" left="133" textpieces="0" top="935" width="677">To validate our second claim, that Tuffy-p has a smaller memory footprint, we see in Table 4,</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="956" width="702">that on all datasets, the memory footprint of Tuffy is no more than 5% of Alchemy. Drilling</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="996" width="702">than the size of grounding results. For example, on the RC dataset, Alchemy allocated 2.8 GB</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="1017" width="702">of RAM only to produce 4.8 MB of ground clauses. While Alchemy has to hold everything in</text>
 
0	<text font="4" height="15" left="451" textpieces="0" top="1069" width="16">12</text>
 
=======================================PAGE========================================
=======================================COL========================================
0	<text font="7" height="13" left="240" textpieces="0" top="204" width="43">0.0E+00</text>
 
0	<text font="7" height="13" left="240" textpieces="0" top="168" width="43">1.0E+04</text>
 
0	<text font="7" height="13" left="240" textpieces="0" top="132" width="43">2.0E+04</text>
 
0	<text font="7" height="13" left="292" textpieces="2" top="221" width="135">0       1000     2000</text>
 
0	<text font="10" height="15" left="233" textpieces="0" top="167" width="0">cost </text>
 
0	<text font="10" height="15" left="339" textpieces="0" top="240" width="64">time (sec) </text>
 
0	<text font="11" height="17" left="367" textpieces="0" top="116" width="20">LP </text>
 
0	<text font="2" height="15" left="345" textpieces="0" top="155" width="97">Alchemy (solid) </text>
 
0	<text font="2" height="15" left="330" textpieces="0" top="139" width="88">Tuffy-p (dash) </text>
 
0	<text font="2" height="15" left="380" textpieces="0" top="174" width="63">Tuffy-mm </text>
 
0	<text font="7" height="13" left="473" textpieces="0" top="204" width="43">0.0E+00</text>
 
0	<text font="7" height="13" left="473" textpieces="0" top="163" width="43">2.0E+05</text>
 
0	<text font="7" height="13" left="473" textpieces="0" top="122" width="43">4.0E+05</text>
 
0	<text font="7" height="13" left="525" textpieces="2" top="221" width="169">0          4000        8000</text>
 
0	<text font="10" height="15" left="466" textpieces="0" top="167" width="0">cost </text>
 
0	<text font="10" height="15" left="574" textpieces="0" top="240" width="64">time (sec) </text>
 
0	<text font="11" height="17" left="600" textpieces="0" top="120" width="22">RC </text>
 
0	<text font="2" height="15" left="634" textpieces="0" top="159" width="56">Alchemy </text>
 
0	<text font="2" height="15" left="550" textpieces="0" top="189" width="47">Tuffy-p </text>
 
0	<text font="2" height="15" left="540" textpieces="0" top="139" width="63">Tuffy-mm </text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="277" width="702">Figure 4: Time-cost plots of Alchemy vs. Tuffy-p (i.e., Tuffy without partitioning) vs. Tuffy-</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="297" width="325">mm (i.e., Tuffy with RDBMS-based search)</text>
 
1	<text font="4" height="15" left="421" textpieces="3" top="336" width="196">LP      IE     RC   ER</text>
 
3	<text font="4" height="14" left="301" textpieces="4" top="360" width="322">Alchemy   0.20M     1M    1.9K  0.9K</text>
 
3	<text font="4" height="14" left="295" textpieces="4" top="381" width="327">Tuffy-mm      0.9      13      0.9   0.03</text>
 
3	<text font="4" height="14" left="305" textpieces="4" top="402" width="318">Tuffy-p    0.11M  0.39M  0.17M  7.9K</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="488" width="702">memory, Tuffy only needs to load the grounding result from the RDBMS at the end of grounding.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="549" width="701">exhausts all 4GB of RAM and crashes soon after launching5, whereas Tuffy runs normally with</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="570" width="244">peak RAM usage of roughly 2GB.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="685" width="702">In this section, we validate that, when there are multiple components in the data, partitioning not</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="746" width="535">enabled) against Tuffy-p: a version of Tuffy with partitioning disabled.</text>
 
0	<text font="4" height="17" left="133" textpieces="0" top="766" width="677">We run the search phase on each of the four datasets using three approaches: Alchemy,</text>
 
0	<text font="4" height="14" left="108" textpieces="0" top="790" width="702">Tuffy-p, and Tuffy (with partitioning). Tuffy-p and Alchemy run WalkSAT on the whole</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="807" width="702">MRF for 107 steps. Tuffy runs WalkSAT on each component in the MRF independently, each</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="827" width="219">component Gi receiving 107|G</text>
 
0	<text font="5" height="11" left="329" textpieces="0" top="833" width="163">i|/|G| steps, where |Gi</text>
 
0	<text font="4" height="15" left="494" textpieces="0" top="826" width="316">| and |G| are the numbers of atoms in this</text>
 
0	<text font="6" height="8" left="127" textpieces="0" top="857" width="494">5We verify on a separate machine that Alchemy requires at least 23GB of RAM.</text>
 
1	<text font="4" height="15" left="422" textpieces="3" top="908" width="246">LP        IE      RC       ER</text>
 
3	<text font="4" height="15" left="267" textpieces="4" top="929" width="402">clause table      5.2 MB   0.6 MB  4.8 MB  164 MB</text>
 
3	<text font="4" height="14" left="250" textpieces="4" top="952" width="418">Alchemy RAM   411 MB  206 MB  2.8 GB   3.5 GB</text>
 
3	<text font="4" height="14" left="254" textpieces="4" top="973" width="415">Tuffy-p RAM      9 MB     8 MB   19 MB  184 MB</text>
 
0	<text font="4" height="15" left="451" textpieces="0" top="1069" width="16">13</text>
 
=======================================PAGE========================================
=======================================COL========================================
0	<text font="4" height="15" left="108" textpieces="0" top="113" width="576">component and the MRF, respectively. This is weighted round-robin scheduling.</text>
 
1	<text font="4" height="15" left="426" textpieces="3" top="149" width="208">LP    IE    RC      ER</text>
 
2	<text font="4" height="15" left="289" textpieces="4" top="170" width="346">#components       1   5341     489        1</text>
 
3	<text font="4" height="14" left="283" textpieces="4" top="194" width="352">Tuffy-p RAM   9MB  8MB  19MB  184MB</text>
 
3	<text font="4" height="14" left="291" textpieces="4" top="215" width="344">Tuffy RAM    9MB  8MB  15MB  184MB</text>
 
3	<text font="4" height="14" left="289" textpieces="4" top="236" width="346">Tuffy-p cost    2534  1933    1943    18717</text>
 
3	<text font="4" height="14" left="296" textpieces="4" top="257" width="339">Tuffy cost     2534  1635    1281    18717</text>
 
4	<text font="4" height="17" left="169" textpieces="0" top="291" width="579">Table 5: Performance of Tuffy vs. Tuffy-p (i.e., Tuffy without partitioning)</text>
 
0	<text font="7" height="13" left="241" textpieces="0" top="440" width="27">1000</text>
 
0	<text font="7" height="13" left="241" textpieces="0" top="418" width="27">1400</text>
 
0	<text font="7" height="13" left="241" textpieces="0" top="395" width="27">1800</text>
 
0	<text font="7" height="13" left="241" textpieces="0" top="373" width="27">2200</text>
 
0	<text font="7" height="13" left="241" textpieces="0" top="350" width="27">2600</text>
 
0	<text font="7" height="13" left="277" textpieces="4" top="458" width="192">0      20     40     60     80</text>
 
0	<text font="10" height="15" left="235" textpieces="0" top="403" width="0">cost </text>
 
0	<text font="10" height="15" left="340" textpieces="0" top="477" width="64">time (sec) </text>
 
0	<text font="12" height="20" left="381" textpieces="0" top="350" width="20">IE </text>
 
0	<text font="7" height="13" left="385" textpieces="0" top="430" width="31">Tuffy </text>
 
0	<text font="7" height="13" left="286" textpieces="0" top="360" width="89">Tuffy-p (dotted) </text>
 
0	<text font="7" height="13" left="286" textpieces="0" top="376" width="86">Alchemy (solid) </text>
 
0	<text font="7" height="13" left="490" textpieces="0" top="440" width="7">0</text>
 
0	<text font="7" height="13" left="470" textpieces="0" top="410" width="27">1000</text>
 
0	<text font="7" height="13" left="470" textpieces="0" top="380" width="27">2000</text>
 
0	<text font="7" height="13" left="470" textpieces="0" top="350" width="27">3000</text>
 
0	<text font="7" height="13" left="506" textpieces="3" top="458" width="183">0       100      200      300</text>
 
0	<text font="10" height="15" left="464" textpieces="0" top="403" width="0">cost </text>
 
0	<text font="10" height="15" left="564" textpieces="0" top="477" width="64">time (sec) </text>
 
0	<text font="12" height="20" left="566" textpieces="0" top="350" width="26">RC </text>
 
0	<text font="7" height="13" left="605" textpieces="0" top="390" width="31">Tuffy </text>
 
0	<text font="7" height="13" left="615" textpieces="0" top="358" width="42">Tuffy-p </text>
 
0	<text font="5" height="12" left="522" textpieces="0" top="429" width="167">Alchemy grounding took over 1 hr. </text>
 
0	<text font="4" height="17" left="158" textpieces="0" top="518" width="601">Figure 5: Time-cost plots of Tuffy vs Tuffy-p (i.e., Tuffy without partitioning)</text>
 
0	<text font="4" height="15" left="133" textpieces="0" top="559" width="677">As shown in Table 5, when there are multiple components in the MRF, partitioning allows</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="620" width="702">p. We then extend the run time of all systems. As shown in Figure 5, there continues to be a</text>
 
0	<text font="4" height="17" left="108" textpieces="1" top="721" width="702">our batch loading technique, Tuffy takes 448s to perform 106 search steps per component on RC,</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="742" width="702">while 117s to perform the same operation with batch loading. With the addition of 8 threads (on</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="762" width="702">8 cores), we further reduce the runtime to 28s. Additional loading and parallelism experiments</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="803" width="200">improving processing speed.</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="938" width="702">dataset, we give Tuffy three memory budgets, with the largest one corresponding to the case</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="959" width="702">when no components are split; note that according to the partitioning algorithm, the memory</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="979" width="702">budget is inversely correlated to partitioning granularity. Figure 6 shows the experiment results.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="999" width="702">On RC, we see another improvement of the result quality (cf. Figure 5). Similar to Example 2, we</text>
 
0	<text font="4" height="15" left="451" textpieces="0" top="1069" width="16">14</text>
 
=======================================PAGE========================================
=======================================COL========================================
0	<text font="2" height="15" left="181" textpieces="0" top="232" width="30">0E+0</text>
 
0	<text font="2" height="15" left="181" textpieces="0" top="191" width="30">1E+3</text>
 
0	<text font="2" height="15" left="181" textpieces="0" top="149" width="29">2E+3</text>
 
0	<text font="2" height="15" left="181" textpieces="0" top="108" width="29">3E+3</text>
 
0	<text font="2" height="15" left="220" textpieces="3" top="251" width="132">0    100  200  300</text>
 
0	<text font="11" height="17" left="174" textpieces="0" top="178" width="0">cost </text>
 
0	<text font="11" height="17" left="248" textpieces="0" top="272" width="72">time (sec) </text>
 
0	<text font="11" height="17" left="277" textpieces="0" top="109" width="22">RC </text>
 
0	<text font="4" height="17" left="311" textpieces="0" top="126" width="40">15MB</text>
 
0	<text font="4" height="17" left="311" textpieces="0" top="146" width="40">13MB</text>
 
0	<text font="4" height="17" left="311" textpieces="0" top="166" width="40">12MB</text>
 
0	<text font="2" height="15" left="375" textpieces="0" top="232" width="41">2.4E+3</text>
 
0	<text font="2" height="15" left="375" textpieces="0" top="191" width="41">2.6E+3</text>
 
0	<text font="2" height="15" left="375" textpieces="0" top="149" width="41">2.8E+3</text>
 
0	<text font="2" height="15" left="375" textpieces="0" top="108" width="41">3.0E+3</text>
 
0	<text font="2" height="15" left="425" textpieces="2" top="251" width="124">0    50  100 150</text>
 
0	<text font="11" height="17" left="367" textpieces="0" top="178" width="0">cost </text>
 
0	<text font="11" height="17" left="449" textpieces="0" top="272" width="72">time (sec) </text>
 
0	<text font="13" height="19" left="467" textpieces="0" top="111" width="22">LP </text>
 
0	<text font="4" height="17" left="506" textpieces="0" top="137" width="32">9MB</text>
 
0	<text font="4" height="17" left="506" textpieces="0" top="156" width="32">5MB</text>
 
0	<text font="4" height="17" left="506" textpieces="0" top="176" width="44">3.5MB</text>
 
0	<text font="2" height="15" left="575" textpieces="0" top="232" width="30">0E+0</text>
 
0	<text font="2" height="15" left="575" textpieces="0" top="201" width="29">2E+4</text>
 
0	<text font="2" height="15" left="575" textpieces="0" top="170" width="29">4E+4</text>
 
0	<text font="2" height="15" left="575" textpieces="0" top="139" width="30">6E+4</text>
 
0	<text font="2" height="15" left="575" textpieces="0" top="108" width="29">8E+4</text>
 
0	<text font="2" height="15" left="614" textpieces="1" top="251" width="132">0   500 1000 1500</text>
 
0	<text font="11" height="17" left="567" textpieces="0" top="178" width="0">cost </text>
 
0	<text font="11" height="17" left="640" textpieces="0" top="272" width="72">time (sec) </text>
 
0	<text font="13" height="19" left="666" textpieces="0" top="111" width="24">ER </text>
 
0	<text font="4" height="17" left="701" textpieces="0" top="134" width="48">200MB</text>
 
0	<text font="4" height="17" left="701" textpieces="0" top="155" width="48">100MB</text>
 
0	<text font="4" height="17" left="701" textpieces="0" top="176" width="40">50MB</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="341" width="702">In contrast, while MRF partitioning lowers RAM usage considerably on ER, it also leads to slower</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="551" width="702">This is true even when a component is split into a relatively small number of pieces. To explain</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="591" width="374">is more dramatic than as predicted by Theorem 3.1.</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="629" width="702">Example 1 Consider an MRF G with two identical components G1, G2, and let p be the stationary</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="650" width="701">probability of the optima on each Gi. Then, after entering a communication class containing some</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="670" width="702">optimum, component-wise WalkSAT would need an expected total of 2/p steps to reach the optima;</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="731" width="456">neighbors, Theorem 3.1 only predicts a gap of no more than 22.</text>
 
0	<text font="4" height="15" left="133" textpieces="0" top="769" width="677">The implication of this observation is that, even when the largest component in the MRF is</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="790" width="702">smaller than the RAM, we may still want to partition the components to even smaller pieces. This</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="810" width="702">raises an interesting question: How do we decide the optimal partitioning granularity? Furthermore,</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="830" width="702">given two partitioning schemes, how do we decide which one is better, i.e., produces better search</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="871" width="235">and cut size on inference quality.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="912" width="702">positive (resp. negative) literal of a positive-weighted ground clause, or in a negative (resp. positive)</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="932" width="702">literal of a negative-weighted ground clause. If an atom is both iTrue and iFalse, it is called critical.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="973" width="702">optima and thereby diminishing p, which in turn widens the gap in the above example. Hence,</text>
 
0	<text font="6" height="8" left="127" textpieces="0" top="1022" width="659">6That is assuming that the number of violated clauses in optimal states in both components are comparable.</text>
 
0	<text font="4" height="15" left="451" textpieces="0" top="1069" width="16">15</text>
 
=======================================PAGE========================================
=======================================COL========================================
0	<text font="4" height="15" left="108" textpieces="0" top="154" width="628">size, which would slow down the convergence rate of the Gauss-Seidel inference scheme.</text>
 
0	<text font="14" height="6" left="265" textpieces="0" top="397" width="4">0</text>
 
0	<text font="14" height="6" left="295" textpieces="0" top="388" width="9">0.2</text>
 
0	<text font="14" height="6" left="324" textpieces="0" top="379" width="9">0.4</text>
 
0	<text font="14" height="6" left="355" textpieces="0" top="371" width="9">0.6</text>
 
0	<text font="14" height="6" left="385" textpieces="0" top="363" width="9">0.8</text>
 
0	<text font="14" height="6" left="414" textpieces="0" top="354" width="4">1</text>
 
0	<text font="14" height="6" left="251" textpieces="0" top="396" width="4">0</text>
 
0	<text font="14" height="6" left="223" textpieces="0" top="384" width="9">0.1</text>
 
0	<text font="14" height="6" left="200" textpieces="0" top="373" width="9">0.2</text>
 
0	<text font="14" height="6" left="177" textpieces="0" top="362" width="9">0.3</text>
 
0	<text font="14" height="6" left="155" textpieces="0" top="351" width="9">0.4</text>
 
0	<text font="14" height="6" left="132" textpieces="0" top="339" width="9">0.5</text>
 
0	<text font="14" height="6" left="138" textpieces="0" top="332" width="4">0</text>
 
0	<text font="14" height="6" left="131" textpieces="0" top="307" width="11">500</text>
 
0	<text font="14" height="6" left="128" textpieces="0" top="283" width="14">1000</text>
 
0	<text font="14" height="6" left="128" textpieces="0" top="259" width="14">1500</text>
 
0	<text font="14" height="6" left="128" textpieces="0" top="235" width="14">2000</text>
 
0	<text font="14" height="6" left="409" textpieces="0" top="196" width="2"> </text>
 
0	<text font="14" height="6" left="326" textpieces="0" top="409" width="61">in the largest partition</text>
 
0	<text font="14" height="6" left="178" textpieces="0" top="405" width="26">in the cut</text>
 
0	<text font="14" height="6" left="146" textpieces="0" top="391" width="2"> </text>
 
0	<text font="14" height="6" left="123" textpieces="0" top="301" width="0">Lowest cost</text>
 
0	<text font="14" height="6" left="434" textpieces="0" top="382" width="11">400</text>
 
0	<text font="14" height="6" left="434" textpieces="0" top="357" width="11">600</text>
 
0	<text font="14" height="6" left="434" textpieces="0" top="333" width="11">800</text>
 
0	<text font="14" height="6" left="434" textpieces="0" top="309" width="14">1000</text>
 
0	<text font="14" height="6" left="434" textpieces="0" top="284" width="14">1200</text>
 
0	<text font="14" height="6" left="434" textpieces="0" top="260" width="14">1400</text>
 
0	<text font="14" height="6" left="434" textpieces="0" top="235" width="14">1600</text>
 
0	<text font="14" height="6" left="434" textpieces="0" top="210" width="14">1800</text>
 
0	<text font="7" height="12" left="237" textpieces="0" top="428" width="103">(a) Overall trend</text>
 
0	<text font="14" height="6" left="812" textpieces="0" top="347" width="4">0</text>
 
0	<text font="14" height="6" left="787" textpieces="0" top="358" width="9">0.2</text>
 
0	<text font="14" height="6" left="762" textpieces="0" top="370" width="9">0.4</text>
 
0	<text font="14" height="6" left="737" textpieces="0" top="381" width="9">0.6</text>
 
0	<text font="14" height="6" left="712" textpieces="0" top="393" width="9">0.8</text>
 
0	<text font="14" height="6" left="688" textpieces="0" top="404" width="4">1</text>
 
0	<text font="14" height="6" left="501" textpieces="0" top="363" width="4">0</text>
 
0	<text font="14" height="6" left="530" textpieces="0" top="372" width="9">0.1</text>
 
0	<text font="14" height="6" left="565" textpieces="0" top="380" width="9">0.2</text>
 
0	<text font="14" height="6" left="599" textpieces="0" top="388" width="9">0.3</text>
 
0	<text font="14" height="6" left="633" textpieces="0" top="397" width="9">0.4</text>
 
0	<text font="14" height="6" left="667" textpieces="0" top="405" width="9">0.5</text>
 
0	<text font="14" height="6" left="501" textpieces="0" top="356" width="4">0</text>
 
0	<text font="14" height="6" left="494" textpieces="0" top="331" width="11">500</text>
 
0	<text font="14" height="6" left="490" textpieces="0" top="307" width="14">1000</text>
 
0	<text font="14" height="6" left="490" textpieces="0" top="283" width="14">1500</text>
 
0	<text font="14" height="6" left="490" textpieces="0" top="259" width="14">2000</text>
 
0	<text font="14" height="6" left="806" textpieces="0" top="204" width="2"> </text>
 
0	<text font="14" height="6" left="734" textpieces="0" top="399" width="61">in the largest partition</text>
 
0	<text font="14" height="6" left="567" textpieces="0" top="404" width="26">in the cut</text>
 
0	<text font="14" height="6" left="509" textpieces="0" top="400" width="2"> </text>
 
0	<text font="14" height="6" left="486" textpieces="0" top="324" width="0">Lowest cost</text>
 
0	<text font="14" height="6" left="228" textpieces="0" top="735" width="9">0.1</text>
 
0	<text font="14" height="6" left="249" textpieces="0" top="732" width="9">0.2</text>
 
0	<text font="14" height="6" left="269" textpieces="0" top="728" width="9">0.3</text>
 
0	<text font="14" height="6" left="289" textpieces="0" top="725" width="9">0.4</text>
 
0	<text font="14" height="6" left="310" textpieces="0" top="722" width="9">0.5</text>
 
0	<text font="14" height="6" left="330" textpieces="0" top="718" width="9">0.6</text>
 
0	<text font="14" height="6" left="351" textpieces="0" top="714" width="9">0.7</text>
 
0	<text font="14" height="6" left="371" textpieces="0" top="711" width="9">0.8</text>
 
0	<text font="14" height="6" left="392" textpieces="0" top="707" width="9">0.9</text>
 
0	<text font="14" height="6" left="412" textpieces="0" top="704" width="4">1</text>
 
0	<text font="14" height="6" left="214" textpieces="0" top="732" width="4">0</text>
 
0	<text font="14" height="6" left="189" textpieces="0" top="714" width="9">0.2</text>
 
0	<text font="14" height="6" left="170" textpieces="0" top="695" width="9">0.4</text>
 
0	<text font="14" height="6" left="150" textpieces="0" top="676" width="9">0.6</text>
 
0	<text font="14" height="6" left="131" textpieces="0" top="658" width="9">0.8</text>
 
0	<text font="14" height="6" left="127" textpieces="0" top="649" width="14">2480</text>
 
0	<text font="14" height="6" left="127" textpieces="0" top="634" width="14">2500</text>
 
0	<text font="14" height="6" left="127" textpieces="0" top="619" width="14">2520</text>
 
0	<text font="14" height="6" left="127" textpieces="0" top="604" width="14">2540</text>
 
0	<text font="14" height="6" left="127" textpieces="0" top="589" width="14">2560</text>
 
0	<text font="14" height="6" left="127" textpieces="0" top="574" width="14">2580</text>
 
0	<text font="14" height="6" left="127" textpieces="0" top="560" width="14">2600</text>
 
0	<text font="14" height="6" left="407" textpieces="0" top="533" width="2"> </text>
 
0	<text font="14" height="6" left="298" textpieces="0" top="748" width="61">in the largest partition</text>
 
0	<text font="14" height="6" left="151" textpieces="0" top="738" width="26">in the cut</text>
 
0	<text font="14" height="6" left="145" textpieces="0" top="728" width="2"> </text>
 
0	<text font="14" height="6" left="122" textpieces="0" top="624" width="0">Lowest cost</text>
 
0	<text font="14" height="6" left="432" textpieces="0" top="705" width="26">2534.587</text>
 
0	<text font="14" height="6" left="432" textpieces="0" top="684" width="26">2534.588</text>
 
0	<text font="14" height="6" left="432" textpieces="0" top="661" width="26">2534.589</text>
 
0	<text font="14" height="6" left="432" textpieces="0" top="639" width="23">2534.59</text>
 
0	<text font="14" height="6" left="432" textpieces="0" top="617" width="26">2534.591</text>
 
0	<text font="14" height="6" left="432" textpieces="0" top="594" width="26">2534.592</text>
 
0	<text font="14" height="6" left="432" textpieces="0" top="573" width="26">2534.593</text>
 
0	<text font="14" height="6" left="432" textpieces="0" top="550" width="26">2534.594</text>
 
0	<text font="7" height="12" left="237" textpieces="0" top="766" width="103">(a) Overall trend</text>
 
0	<text font="14" height="6" left="636" textpieces="2" top="728" width="75">0              0.2            0.4</text>
 
0	<text font="14" height="6" left="737" textpieces="1" top="725" width="44">0.6             0.8</text>
 
0	<text font="14" height="6" left="809" textpieces="0" top="722" width="4">1</text>
 
0	<text font="14" height="6" left="636" textpieces="1" top="728" width="-24">0                  0.2</text>
 
0	<text font="14" height="6" left="573" textpieces="0" top="724" width="9">0.4</text>
 
0	<text font="14" height="6" left="542" textpieces="1" top="721" width="-22">0.6                    0.8</text>
 
0	<text font="14" height="6" left="496" textpieces="0" top="708" width="14">2480</text>
 
0	<text font="14" height="6" left="496" textpieces="0" top="680" width="14">2500</text>
 
0	<text font="14" height="6" left="496" textpieces="0" top="651" width="14">2520</text>
 
0	<text font="14" height="6" left="496" textpieces="0" top="622" width="14">2540</text>
 
0	<text font="14" height="6" left="496" textpieces="0" top="594" width="14">2560</text>
 
0	<text font="14" height="6" left="496" textpieces="0" top="566" width="14">2580</text>
 
0	<text font="14" height="6" left="496" textpieces="0" top="537" width="14">2600</text>
 
0	<text font="14" height="6" left="810" textpieces="0" top="531" width="2"> </text>
 
0	<text font="14" height="6" left="685" textpieces="0" top="747" width="61">in the largest partition</text>
 
0	<text font="14" height="6" left="564" textpieces="0" top="746" width="26">in the cut</text>
 
0	<text font="14" height="6" left="515" textpieces="0" top="720" width="2"> </text>
 
0	<text font="14" height="6" left="491" textpieces="0" top="638" width="0">Lowest cost</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="860" width="702">On each of the three usable datasets (i.e., RC, LP, and RC), we select the largest component in</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="880" width="702">the MRF, and partition it with various granularities: 2-way, 4-way, 8-way, and 16-way. For each</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="901" width="702">granularity, we generate several hundred random partitioning schemes, and measure two quantities</text>
 
0	<text font="6" height="8" left="127" textpieces="0" top="990" width="528">7Note that naive exhaustive search has a run time exponential in the number of atoms.</text>
 
0	<text font="4" height="15" left="451" textpieces="0" top="1069" width="16">16</text>
 
=======================================PAGE========================================
=======================================COL========================================
0	<text font="14" height="6" left="253" textpieces="0" top="334" width="4">0</text>
 
0	<text font="14" height="6" left="287" textpieces="0" top="326" width="9">0.2</text>
 
0	<text font="14" height="6" left="322" textpieces="0" top="319" width="9">0.4</text>
 
0	<text font="14" height="6" left="356" textpieces="0" top="313" width="9">0.6</text>
 
0	<text font="14" height="6" left="391" textpieces="0" top="306" width="9">0.8</text>
 
0	<text font="14" height="6" left="426" textpieces="0" top="299" width="4">1</text>
 
0	<text font="14" height="6" left="237" textpieces="0" top="332" width="4">0</text>
 
0	<text font="14" height="6" left="211" textpieces="0" top="320" width="9">0.2</text>
 
0	<text font="14" height="6" left="190" textpieces="0" top="309" width="9">0.4</text>
 
0	<text font="14" height="6" left="169" textpieces="0" top="297" width="9">0.6</text>
 
0	<text font="14" height="6" left="148" textpieces="0" top="286" width="9">0.8</text>
 
0	<text font="14" height="6" left="133" textpieces="0" top="275" width="4">1</text>
 
0	<text font="14" height="6" left="134" textpieces="0" top="266" width="4">1</text>
 
0	<text font="14" height="6" left="128" textpieces="0" top="247" width="9">1.5</text>
 
0	<text font="14" height="6" left="134" textpieces="0" top="228" width="4">2</text>
 
0	<text font="14" height="6" left="128" textpieces="0" top="209" width="9">2.5</text>
 
0	<text font="14" height="6" left="134" textpieces="0" top="190" width="4">3</text>
 
0	<text font="14" height="6" left="128" textpieces="0" top="171" width="9">3.5</text>
 
0	<text font="14" height="6" left="134" textpieces="0" top="152" width="4">4</text>
 
0	<text font="14" height="6" left="143" textpieces="0" top="137" width="15">x 104</text>
 
0	<text font="14" height="6" left="420" textpieces="0" top="121" width="2"> </text>
 
0	<text font="14" height="6" left="321" textpieces="0" top="349" width="64">in the largest partition</text>
 
0	<text font="14" height="6" left="165" textpieces="0" top="343" width="27">in the cut</text>
 
0	<text font="14" height="6" left="142" textpieces="0" top="327" width="2"> </text>
 
0	<text font="14" height="6" left="123" textpieces="0" top="228" width="0">Lowest cost</text>
 
0	<text font="14" height="6" left="446" textpieces="0" top="309" width="9">1.6</text>
 
0	<text font="14" height="6" left="446" textpieces="0" top="291" width="9">1.8</text>
 
0	<text font="14" height="6" left="446" textpieces="0" top="272" width="4">2</text>
 
0	<text font="14" height="6" left="446" textpieces="0" top="253" width="9">2.2</text>
 
0	<text font="14" height="6" left="446" textpieces="0" top="235" width="9">2.4</text>
 
0	<text font="14" height="6" left="446" textpieces="0" top="216" width="9">2.6</text>
 
0	<text font="14" height="6" left="446" textpieces="0" top="197" width="9">2.8</text>
 
0	<text font="14" height="6" left="446" textpieces="0" top="179" width="4">3</text>
 
0	<text font="14" height="6" left="446" textpieces="0" top="160" width="9">3.2</text>
 
0	<text font="14" height="6" left="446" textpieces="0" top="141" width="9">3.4</text>
 
0	<text font="14" height="6" left="446" textpieces="0" top="123" width="9">3.6</text>
 
0	<text font="14" height="6" left="444" textpieces="0" top="115" width="15">x 104</text>
 
0	<text font="7" height="12" left="237" textpieces="0" top="368" width="103">(a) Overall trend</text>
 
0	<text font="14" height="6" left="816" textpieces="0" top="302" width="4">0</text>
 
0	<text font="14" height="6" left="785" textpieces="0" top="312" width="9">0.2</text>
 
0	<text font="14" height="6" left="755" textpieces="0" top="321" width="9">0.4</text>
 
0	<text font="14" height="6" left="724" textpieces="0" top="330" width="9">0.6</text>
 
0	<text font="14" height="6" left="694" textpieces="0" top="339" width="9">0.8</text>
 
0	<text font="14" height="6" left="663" textpieces="0" top="348" width="4">1</text>
 
0	<text font="14" height="6" left="494" textpieces="0" top="302" width="4">0</text>
 
0	<text font="14" height="6" left="520" textpieces="0" top="312" width="9">0.2</text>
 
0	<text font="14" height="6" left="551" textpieces="0" top="321" width="9">0.4</text>
 
0	<text font="14" height="6" left="581" textpieces="0" top="330" width="9">0.6</text>
 
0	<text font="14" height="6" left="612" textpieces="0" top="339" width="9">0.8</text>
 
0	<text font="14" height="6" left="648" textpieces="0" top="348" width="4">1</text>
 
0	<text font="14" height="6" left="494" textpieces="0" top="295" width="4">1</text>
 
0	<text font="14" height="6" left="489" textpieces="0" top="277" width="9">1.5</text>
 
0	<text font="14" height="6" left="494" textpieces="0" top="258" width="4">2</text>
 
0	<text font="14" height="6" left="489" textpieces="0" top="239" width="9">2.5</text>
 
0	<text font="14" height="6" left="494" textpieces="0" top="221" width="4">3</text>
 
0	<text font="14" height="6" left="489" textpieces="0" top="202" width="9">3.5</text>
 
0	<text font="14" height="6" left="494" textpieces="0" top="184" width="4">4</text>
 
0	<text font="14" height="6" left="504" textpieces="0" top="168" width="15">x 104</text>
 
0	<text font="14" height="6" left="810" textpieces="0" top="141" width="2"> </text>
 
0	<text font="14" height="6" left="729" textpieces="0" top="346" width="63">in the largest partition</text>
 
0	<text font="14" height="6" left="554" textpieces="1" top="345" width="-49">in the cut                                        </text>
 
0	<text font="14" height="6" left="484" textpieces="0" top="257" width="0">Lowest cost</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="474" width="702">we run the Gauss-Seidel inference scheme with two rounds, and 105WalkSAT steps in each round.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="495" width="702">Finally, we measure the lowest total cost from each partitioning scheme. We plot the results in</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="515" width="139">Figures 7, 8, and 9.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="617" width="702">almost half of the clauses, they still yield the best result quality. Note that RC has a relatively</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="657" width="635">should partition aggressively to both improve search quality and increase parallelization.</text>
 
0	<text font="4" height="15" left="133" textpieces="0" top="678" width="677">On the LP dataset, we see that, as partition sizes decrease, the cut size increases more rapidly</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="698" width="702">(compared to RC), but the result quality remains largely the same (almost always between 2500 and</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="718" width="702">2560). For datasets like this, one should partition aggressively to take advantage of parallelization.</text>
 
0	<text font="4" height="15" left="133" textpieces="0" top="739" width="677">On the ER dataset, as partition sizes decrease, the cut size increases even more rapidly (com-</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="861" width="702">partitioning scheme P , we use the following simple formula to estimate how well P will perform in</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="881" width="168">terms of search quality:</text>
 
0	<text font="4" height="15" left="451" textpieces="0" top="1069" width="16">17</text>
 
=======================================PAGE========================================
=======================================COL========================================
0	<text font="4" height="15" left="108" textpieces="0" top="174" width="579">investigate how to design partitioning algorithms that make use of this heuristic.</text>
 
0	<text font="3" height="19" left="108" textpieces="1" top="222" width="343">6  Conclusion and Future Work</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="262" width="702">Motivated by a large set of data-rich applications, we study how to push MLN inference inside an</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="303" width="702">and that these operations are a substantial bottleneck in state-of-the-art MLN implementations</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="323" width="702">such as Alchemy. By using an RDBMS, Tuffy not only achieves scalability, but also speeds up the</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="343" width="702">grounding phase by orders of magnitude. We then develop a hybrid solution with RDBMS-based</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="384" width="702">we study a partitioning approach that allows for in-memory search even when the dataset does</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="425" width="702">experimentally; it allows us to produce higher quality results in a shorter amount of time and to</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="445" width="702">run on much larger datasets than were impossible with prior approaches. As future work, we plan</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="486" width="260">and partitioning) to other problems.</text>
 
0	<text font="3" height="19" left="108" textpieces="1" top="534" width="227">7  Acknowledgement</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="574" width="702">We gratefully acknowledge the support of Defense Advanced Research Projects Agency (DARPA)</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="594" width="702">Machine Reading Program under Air Force Research Laboratory (AFRL) prime contract no.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="655" width="142">the US government.</text>
 
0	<text font="3" height="19" left="108" textpieces="0" top="701" width="113">References</text>
 
0	<text font="2" height="13" left="115" textpieces="0" top="738" width="695">[1] L. Antova, T. Jansen, C. Koch, and D. Olteanu. Fast and simple relational processing of uncertain</text>
 
0	<text font="2" height="13" left="139" textpieces="0" top="756" width="140">data. In ICDE, 2008.</text>
 
0	<text font="2" height="13" left="115" textpieces="0" top="783" width="695">[2] O. Benjelloun, A. Sarma, A. Halevy, M. Theobald, and J. Widom. Databases with uncertainty and</text>
 
0	<text font="2" height="13" left="139" textpieces="0" top="801" width="159">lineage. VLDB J., 2008.</text>
 
0	<text font="2" height="13" left="115" textpieces="0" top="828" width="695">[3] D. P. Bertsekas and J. N. Tsitsiklis. Parallel and distributed computation: Numerical methods. Prentice-</text>
 
0	<text font="2" height="13" left="139" textpieces="0" top="846" width="70">Hall, 1989.</text>
 
0	<text font="2" height="13" left="115" textpieces="0" top="899" width="695">[5] A. Deshpande and S. Madden. MauveDB: Supporting model-based user views in database systems. In</text>
 
0	<text font="2" height="13" left="139" textpieces="0" top="917" width="105">SIGMOD, 2006.</text>
 
0	<text font="2" height="14" left="115" textpieces="0" top="971" width="415">[7] P. Domingos et al. http://alchemy.cs.washington.edu/.</text>
 
0	<text font="2" height="13" left="115" textpieces="0" top="998" width="613">[8] R. Fagin, J. Y. Halpern, and N. Megiddo. A logic for reasoning about probabilities. 1990.</text>
 
0	<text font="2" height="13" left="115" textpieces="0" top="1025" width="565">[9] W. Feller. An introduction to probability theory and its applications. Vol. I. 1950.</text>
 
0	<text font="4" height="15" left="451" textpieces="0" top="1069" width="16">18</text>
 
=======================================PAGE========================================
=======================================COL========================================
0	<text font="2" height="13" left="108" textpieces="0" top="114" width="634">[10] S. Guha and K. Munagala. Multi-armed bandits with metric switching costs. ICALP, 2009.</text>
 
0	<text font="2" height="13" left="108" textpieces="0" top="141" width="702">[11] R. Jampani, F. Xu, M. Wu, L. L. Perez, C. M. Jermaine, and P. J. Haas. MCDB: a monte carlo</text>
 
0	<text font="2" height="13" left="139" textpieces="0" top="159" width="381">approach to managing uncertain data. In SIGMOD, 2008.</text>
 
0	<text font="2" height="13" left="139" textpieces="0" top="204" width="140">data. In ICDE, 2008.</text>
 
0	<text font="2" height="13" left="108" textpieces="0" top="231" width="702">[13] G. Karypis, R. Aggarwal, V. Kumar, and S. Shekhar. Multilevel hypergraph partitioning: Applications</text>
 
0	<text font="2" height="13" left="139" textpieces="0" top="249" width="407">in VLSI domain. VLSI Systems, IEEE Transactions on, 2002.</text>
 
0	<text font="2" height="13" left="108" textpieces="0" top="275" width="702">[14] H. Kautz, B. Selman, and Y. Jiang. A general stochastic approach to solving problems with hard and</text>
 
0	<text font="2" height="13" left="108" textpieces="0" top="320" width="702">[15] S. Khot. Ruling out PTAS for graph min-bisection, densest subgraph and bipartite clique. In FOCS,</text>
 
0	<text font="2" height="13" left="139" textpieces="0" top="338" width="34">2004.</text>
 
0	<text font="2" height="13" left="108" textpieces="0" top="365" width="702">[16] A. McCallum, K. Nigam, J. Rennie, and K. Seymore. Automating the construction of internet portals</text>
 
0	<text font="2" height="13" left="139" textpieces="0" top="383" width="395">with machine learning. Information Retrieval Journal, 2000.</text>
 
0	<text font="2" height="13" left="108" textpieces="0" top="410" width="638">[17] J. Pearl. Probabilistic reasoning in intelligent systems: networks of plausible inference. 1988.</text>
 
0	<text font="2" height="13" left="139" textpieces="0" top="509" width="105">SIGMOD, 2008.</text>
 
0	<text font="2" height="13" left="108" textpieces="0" top="535" width="573">[21] M. Richardson and P. Domingos. Markov logic networks. Machine Learning, 2006.</text>
 
0	<text font="2" height="13" left="108" textpieces="0" top="589" width="702">[23] P. Sen and A. Deshpande. Representing and querying correlated tuples in probabilistic databases. In</text>
 
0	<text font="2" height="13" left="139" textpieces="0" top="607" width="81">ICDE, 2007.</text>
 
0	<text font="2" height="13" left="108" textpieces="0" top="634" width="702">[24] P. Sen, A. Deshpande, and L. Getoor. PrDB: managing and exploiting rich correlations in probabilistic</text>
 
0	<text font="2" height="13" left="139" textpieces="0" top="652" width="177">databases. VLDB J., 2009.</text>
 
0	<text font="2" height="13" left="108" textpieces="0" top="733" width="702">[27] P. Singla, H. Kautz, J. Luo, and A. Gallagher. Discovery of social relationships in consumer photo</text>
 
0	<text font="2" height="13" left="139" textpieces="0" top="751" width="389">collections using Markov Logic. In CVPR Workshops 2008.</text>
 
0	<text font="2" height="13" left="108" textpieces="0" top="778" width="442">[28] V. Vazirani. Approximation algorithms. Springer Verlag, 2001.</text>
 
0	<text font="2" height="13" left="108" textpieces="0" top="804" width="702">[29] D. Z. Wang, E. Michelakis, M. N. Garofalakis, and J. M. Hellerstein. BayesStore: managing large,</text>
 
0	<text font="2" height="13" left="139" textpieces="0" top="822" width="516">uncertain data repositories with probabilistic graphical models. PVLDB, 2008.</text>
 
0	<text font="4" height="15" left="451" textpieces="0" top="1069" width="16">19</text>
 
=======================================PAGE========================================
=======================================COL========================================
0	<text font="3" height="19" left="108" textpieces="1" top="110" width="318">A  Material for Preliminaries</text>
 
0	<text font="1" height="16" left="108" textpieces="1" top="149" width="366">A.1  More Details on the MLN Program</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="179" width="701">Rules in MLNs are expressive and may involve data in non-trivial ways. For example, consider F2:</text>
 
0	<text font="2" height="12" left="271" textpieces="1" top="214" width="375">wrote(x, p1), wrote(x, p2), cat(p1, c) =&gt; cat(p2, c)  (F2)</text>
 
0	<text font="4" height="15" left="113" textpieces="0" top="247" width="697">Intuitively, this rule says that all the papers written by a particular person are likely to be in the</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="308" width="702">so no possible world may violate this rule. The weight of a formula may also be negative, which</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="369" width="121">of these features.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="450" width="702">remove nonsensical ground clauses, e.g., both attributes of refers are paper references, and so it</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="470" width="504">is unnecessary to ground this predicate with another type, say person.</text>
 
0	<text font="1" height="16" left="108" textpieces="1" top="513" width="250">A.2  Markov Random Field</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="545" width="702">A Boolean Markov Random Field (or Boolean Markov network is a model of the joint distribution</text>
 
0	<text font="4" height="15" left="467" textpieces="0" top="659" width="8">1</text>
 
0	<text font="4" height="15" left="464" textpieces="0" top="681" width="11">Z</text>
 
0	<text font="4" height="15" left="133" textpieces="0" top="746" width="258">Fix a set of constants C = {c1, . . . , c</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="766" width="702">follows: for each possible grounding of each predicate (i.e., atom), create a node (and so a Boolean</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="787" width="702">random variable). For example, there will be a node refers(p1, p2) for each pair of papers p1, p2.</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="807" width="702">For each formula Fiwe ground it in all possible ways, then we create a hyperedge e that contains the</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="827" width="702">nodes corresponding to all terms in the formula. For example, the key constraint creates hyperedges</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="848" width="702">for each paper and all of its potential categories. We refer to this graph as the ground network.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="868" width="598">Once we have the ground network, our task reduces to inference in Markov models.</text>
 
0	<text font="4" height="15" left="133" textpieces="0" top="888" width="677">Explicitly representing such ground networks is prohibitively expensive and unnecessary. In</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="908" width="702">practice, we only include non-evidence nodes and groundings that are relevant to answering the</text>
 
0	<text font="1" height="16" left="108" textpieces="1" top="972" width="378">A.3  Optimizing MLN Grounding Process</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="1003" width="702">Conceptually, we might ground an MLN formula by enumerating all possible assignments to its</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="1024" width="701">free variables. However, this is both impractical and unnecessary. For example, if we ground F2</text>
 
0	<text font="4" height="15" left="451" textpieces="0" top="1069" width="16">20</text>
 
=======================================PAGE========================================
=======================================COL========================================
0	<text font="4" height="15" left="108" textpieces="1" top="113" width="702">exhaustively this way, the result would contain |D|4 ground clauses. Fortunately, in practice a</text>
 
0	<text font="5" height="11" left="711" textpieces="0" top="161" width="7">d</text>
 
0	<text font="4" height="15" left="725" textpieces="1" top="154" width="85">of F2 where</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="215" width="174">during the search phase.</text>
 
0	<text font="5" height="11" left="387" textpieces="1" top="344" width="423">d is not active. Alchemy keeps only active ground clauses</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="377" width="702">incremental grounding is more expensive than batch grounding, Alchemy uses the following one-</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="398" width="702">step look-ahead strategy: assume all atoms are inactive and compute active clauses; activate the</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="438" width="702">be repeatedly applied until convergence, resulting in an active closure. Tuffy implements this</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="459" width="128">closure algorithm.</text>
 
0	<text font="4" height="15" left="133" textpieces="0" top="479" width="677">In addition, we use a pruning strategy that ensures grounding to focus on only predicates and</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="499" width="702">rules that are relevant to the query. Similar ideas can be found in KBMC [46] inference and the</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="520" width="386">use of Rete algorithm [33] in production rule systems.</text>
 
0	<text font="1" height="16" left="108" textpieces="1" top="562" width="274">A.4  The WalkSAT Algorithm</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="594" width="503">For completeness, we list the pseudocode of WalkSAT in Algorithm 1.</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="631" width="299">Algorithm 1 The WalkSAT Algorithm</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="655" width="193">Input: A: an set of atoms</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="676" width="324">Input: C: an set of weighted ground clauses</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="696" width="204">Input: MaxFlips, MaxTries</text>
 
0	<text font="7" height="12" left="117" textpieces="1" top="759" width="223">2: for try = 1 to MaxTries do</text>
 
0	<text font="7" height="12" left="117" textpieces="1" top="800" width="247">4:    for flip = 1 to MaxFlips do</text>
 
0	<text font="7" height="12" left="117" textpieces="1" top="901" width="82">9:       else</text>
 
0	<text font="7" height="12" left="110" textpieces="1" top="942" width="236">11:       if cost &lt; lowCost then</text>
 
0	<text font="4" height="15" left="451" textpieces="0" top="1069" width="16">21</text>
 
=======================================PAGE========================================
=======================================COL========================================
0	<text font="1" height="16" left="108" textpieces="1" top="112" width="305">A.5  Marginal Inference of MLNs</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="144" width="702">In marginal inference, we are given a set of atoms together with a truth assignment to them.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="164" width="702">The goal is to estimate the marginal probability of this partial assignment. Since this problem</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="185" width="702">is generally intractable, we usually resort to sampling methods. The state-of-the-art marginal</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="205" width="702">inference algorithm of MLNs is MC-SAT [40], which is implemented in both Alchemy and Tuffy.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="225" width="702">In MC-SAT, each sampling step consists of a call to a heuristic SAT sampler named SampleSAT [45].</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="246" width="702">Essentially, SampleSAT is a combination of simulated annealing and WalkSAT. And so, Tuffy is</text>
 
0	<text font="3" height="19" left="108" textpieces="1" top="314" width="263">B  Material for Systems</text>
 
0	<text font="1" height="16" left="108" textpieces="1" top="354" width="404">B.1  An Example SQL Query For Grounding</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="385" width="702">Consider the formula F3 in Fig. 1. Suppose that the actual schemata of cat and refers are</text>
 
0	<text font="4" height="14" left="108" textpieces="0" top="407" width="702">cat(tid, paper, category, truth, state) and refers(tid, paper1, paper2, truth, state), respectively.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="446" width="281">formula using the following SQL query.</text>
 
0	<text font="17" height="14" left="109" textpieces="1" top="477" width="317">S E L E C T - t1 . tid , - t2 . tid , t3 . tid</text>
 
0	<text font="17" height="14" left="109" textpieces="1" top="497" width="307">F R O M  cat t1 , r e f e r s t2 , cat t3</text>
 
0	<text font="17" height="14" left="109" textpieces="3" top="518" width="339">W H E R E ( t1 . t r u t h =N U L L OR t1 . t r u t h )</text>
 
0	<text font="17" height="14" left="109" textpieces="3" top="538" width="318">AND ( t2 . t r u t h =N U L L OR t2 . t r u t h )</text>
 
0	<text font="17" height="14" left="109" textpieces="3" top="558" width="359">AND ( t3 . t r u t h =N U L L OR NOT t3 . t r u t h )</text>
 
0	<text font="17" height="14" left="109" textpieces="1" top="579" width="224">AND t1 . p a p e r = t2 . p a p e r 1</text>
 
0	<text font="17" height="14" left="109" textpieces="1" top="599" width="275">AND t1 . c a t e g o r y = t3 . c a t e g o r y</text>
 
0	<text font="17" height="14" left="109" textpieces="1" top="619" width="224">AND t2 . p a p e r 2 = t3 . p a p e r</text>
 
0	<text font="4" height="15" left="133" textpieces="0" top="647" width="677">Note that the tids of t1 and t2 are negated because the corresponding predicates are negated</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="668" width="180">in the clausal form of F3.</text>
 
0	<text font="1" height="16" left="108" textpieces="1" top="710" width="410">B.2  A Compilation Algorithm for Grounding</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="742" width="702">Algorithm 2 is a basic algorithm of expressing the grounding process of an MLN formula in SQL.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="783" width="370">can be easily implemented on top of this algorithm.</text>
 
0	<text font="1" height="16" left="108" textpieces="1" top="826" width="368">B.3  Implementing WalkSAT in RDBMS</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="858" width="702">WalkSAT is a stochastic local search algorithm; its random access patterns pose considerable chal-</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="919" width="702">/write) to per-atom or per-clause data structures; and 3) traverse clauses involving a given atom.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="939" width="702">Atoms are cached as in-memory arrays, while the per-clause data structures are read-only. Each</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="959" width="651">step of WalkSAT involves a scan over the clauses and many random accesses to the atoms.</text>
 
0	<text font="4" height="15" left="133" textpieces="0" top="980" width="677">Although our design process iterated over numerous combinations of various design choices, we</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="1020" width="702">scans, one might suspect that indexing could improve search speed by reading less data at each</text>
 
0	<text font="4" height="15" left="451" textpieces="0" top="1069" width="16">22</text>
 
=======================================PAGE========================================
=======================================COL========================================
0	<text font="4" height="15" left="108" textpieces="0" top="112" width="283">Algorithm 2 MLN Grounding in SQL</text>
 
0	<text font="5" height="11" left="339" textpieces="0" top="147" width="30">i=1li</text>
 
0	<text font="4" height="15" left="375" textpieces="1" top="139" width="418">where each li is a literal supported by predicate table r(li)</text>
 
0	<text font="7" height="12" left="117" textpieces="1" top="304" width="668">5: For each constant argument of li, there is an equal-constant WHERE predicate for table ti</text>
 
0	<text font="7" height="12" left="117" textpieces="1" top="324" width="417">6: Form a conjunction with the above WHERE predicates</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="494" width="702">Figure 10 illustrates the hybrid memory management approach of Tuffy. Alchemy is a represen-</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="514" width="702">tative of prior art MLN systems, which uses RAM for both grounding and search; Tuffy-mm is</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="535" width="702">a version of Tuffy we developed that uses an RDBMS for all memory management; and Tuffy</text>
 
0	<text font="8" height="10" left="476" textpieces="1" top="657" width="-64">RDBMS                               RAM </text>
 
0	<text font="8" height="10" left="389" textpieces="2" top="720" width="207">RAM                 RDBMS                 RAM </text>
 
0	<text font="8" height="10" left="567" textpieces="1" top="657" width="-198">RDBMS                                                                            Grounding </text>
 
0	<text font="4" height="16" left="310" textpieces="0" top="718" width="47">Search </text>
 
0	<text font="11" height="16" left="373" textpieces="2" top="595" width="231">Alchemy    Tuffy-mm      Tuffy </text>
 
0	<text font="4" height="15" left="318" textpieces="0" top="776" width="281">Figure 10: Comparison of architectures</text>
 
0	<text font="1" height="16" left="108" textpieces="1" top="839" width="371">B.5  MLNs Causing MRF Fragmentation</text>
 
0	<text font="4" height="14" left="108" textpieces="0" top="874" width="702">MLN rules usually model the interaction of relationships and attributes of some underlying entities.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="912" width="702">in the MRF. Since in real world data the interactions are usually sparse, one can expect to see</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="973" width="651">authors. Indeed, our RC dataset yields hundreds of components in the MRF (see Table 5).</text>
 
0	<text font="4" height="15" left="451" textpieces="0" top="1069" width="16">23</text>
 
=======================================PAGE========================================
=======================================COL========================================
0	<text font="1" height="16" left="108" textpieces="1" top="112" width="161">B.6  Theorem 3.1</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="144" width="702">of Theorem 3.1. We follow the notations of the theorem. Without loss of generality and for ease</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="246" width="702">be the transition probability of WalkSAT, i.e., the probability that next state will be y given current</text>
 
0	<text font="4" height="15" left="294" textpieces="2" top="345" width="105">H(x)  =  1 +</text>
 
0	<text font="4" height="15" left="346" textpieces="1" top="392" width="53">=  1 +</text>
 
0	<text font="4" height="15" left="300" textpieces="1" top="515" width="20">Px</text>
 
0	<text font="5" height="11" left="311" textpieces="0" top="522" width="10">+</text>
 
0	<text font="5" height="11" left="291" textpieces="0" top="552" width="10">+</text>
 
0	<text font="5" height="11" left="428" textpieces="0" top="589" width="10">+</text>
 
0	<text font="4" height="15" left="539" textpieces="0" top="582" width="18">Px</text>
 
0	<text font="4" height="15" left="563" textpieces="1" top="582" width="67">+ fk+1Px</text>
 
0	<text font="5" height="11" left="622" textpieces="0" top="589" width="15">+.</text>
 
0	<text font="5" height="11" left="286" textpieces="0" top="646" width="10">+</text>
 
0	<text font="5" height="11" left="494" textpieces="0" top="646" width="10">+</text>
 
0	<text font="4" height="15" left="546" textpieces="0" top="639" width="5">.</text>
 
0	<text font="5" height="11" left="548" textpieces="1" top="665" width="262">kare non-optimal while Gk+1, . . . , GN</text>
 
0	<text font="5" height="11" left="240" textpieces="0" top="687" width="4">i</text>
 
0	<text font="4" height="15" left="300" textpieces="0" top="731" width="13">=</text>
 
0	<text font="5" height="11" left="337" textpieces="0" top="716" width="7">k</text>
 
0	<text font="5" height="11" left="337" textpieces="0" top="728" width="6">1</text>
 
0	<text font="5" height="11" left="376" textpieces="0" top="728" width="4">i</text>
 
0	<text font="5" height="11" left="421" textpieces="0" top="728" width="4">i</text>
 
0	<text font="4" height="15" left="428" textpieces="0" top="720" width="6">)</text>
 
0	<text font="5" height="11" left="357" textpieces="0" top="741" width="10">N</text>
 
0	<text font="5" height="11" left="357" textpieces="0" top="753" width="6">1</text>
 
0	<text font="5" height="11" left="400" textpieces="0" top="753" width="4">i</text>
 
0	<text font="4" height="15" left="408" textpieces="0" top="745" width="6">)</text>
 
0	<text font="5" height="11" left="470" textpieces="0" top="738" width="10">+</text>
 
0	<text font="4" height="15" left="491" textpieces="0" top="731" width="13">=</text>
 
0	<text font="5" height="11" left="528" textpieces="0" top="714" width="10">N</text>
 
0	<text font="5" height="11" left="528" textpieces="0" top="726" width="23">k+1</text>
 
0	<text font="5" height="11" left="584" textpieces="0" top="726" width="5">j</text>
 
0	<text font="5" height="11" left="629" textpieces="0" top="726" width="5">j</text>
 
0	<text font="4" height="15" left="637" textpieces="0" top="718" width="6">)</text>
 
0	<text font="5" height="11" left="557" textpieces="0" top="741" width="10">N</text>
 
0	<text font="5" height="11" left="557" textpieces="0" top="753" width="6">1</text>
 
0	<text font="5" height="11" left="600" textpieces="0" top="753" width="4">i</text>
 
0	<text font="4" height="15" left="607" textpieces="0" top="745" width="6">)</text>
 
0	<text font="4" height="15" left="645" textpieces="0" top="731" width="5">,</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="779" width="56">we have</text>
 
0	<text font="5" height="11" left="389" textpieces="0" top="792" width="10">N</text>
 
0	<text font="5" height="11" left="389" textpieces="0" top="805" width="23">k+1</text>
 
0	<text font="5" height="11" left="446" textpieces="0" top="804" width="5">j</text>
 
0	<text font="5" height="11" left="491" textpieces="0" top="804" width="5">j</text>
 
0	<text font="4" height="15" left="498" textpieces="0" top="797" width="6">)</text>
 
0	<text font="5" height="11" left="399" textpieces="0" top="819" width="7">k</text>
 
0	<text font="5" height="11" left="399" textpieces="0" top="832" width="6">1</text>
 
0	<text font="5" height="11" left="438" textpieces="0" top="832" width="4">i</text>
 
0	<text font="5" height="11" left="482" textpieces="0" top="832" width="4">i</text>
 
0	<text font="4" height="15" left="489" textpieces="0" top="824" width="6">)</text>
 
0	<text font="4" height="15" left="573" textpieces="0" top="821" width="9">k</text>
 
0	<text font="4" height="15" left="612" textpieces="0" top="810" width="5">,</text>
 
0	<text font="4" height="15" left="133" textpieces="0" top="906" width="676">According to this theorem, the gap on Example 1 is at least 2N/3; in fact, a more detailed analysis</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="926" width="222">reveals that the gap is at least</text>
 
0	<text font="6" height="8" left="353" textpieces="0" top="932" width="9">N</text>
 
0	<text font="6" height="8" left="355" textpieces="0" top="942" width="5">2</text>
 
0	<text font="4" height="15" left="464" textpieces="1" top="926" width="346">N ).9 Figure 11 shows the experiment results of</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="951" width="702">running Alchemy, Tuffy, and Tuffy-p (i.e., Tuffy without partitioning) on Example 1 with</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="971" width="127">1000 components.</text>
 
0	<text font="7" height="12" left="108" textpieces="0" top="1019" width="36">on gk.</text>
 
0	<text font="4" height="15" left="451" textpieces="0" top="1069" width="16">24</text>
 
=======================================PAGE========================================
=======================================COL========================================
0	<text font="2" height="15" left="340" textpieces="0" top="232" width="22">500</text>
 
0	<text font="2" height="15" left="332" textpieces="0" top="193" width="30">1000</text>
 
0	<text font="2" height="15" left="332" textpieces="0" top="154" width="30">1500</text>
 
0	<text font="2" height="15" left="332" textpieces="0" top="115" width="30">2000</text>
 
0	<text font="2" height="15" left="372" textpieces="4" top="251" width="232">0       20      40      60      80</text>
 
0	<text font="18" height="21" left="324" textpieces="0" top="182" width="0">cost </text>
 
0	<text font="18" height="21" left="443" textpieces="0" top="273" width="90">time (sec) </text>
 
0	<text font="11" height="17" left="394" textpieces="0" top="125" width="188">Performance on Example 1 </text>
 
0	<text font="2" height="15" left="454" textpieces="0" top="164" width="97">Tuffy-p (dotted) </text>
 
0	<text font="2" height="15" left="454" textpieces="0" top="182" width="94">Alchemy (solid) </text>
 
0	<text font="2" height="15" left="454" textpieces="0" top="214" width="34">Tuffy </text>
 
0	<text font="4" height="15" left="133" textpieces="0" top="371" width="677">Note that the analysis of Theorem 3.1 actually applies to not only WalkSAT, but stochastic</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="391" width="702">local search in general. Since stochastic local search algorithms are used in many statistical models,</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="411" width="702">we believe that our observation here and corresponding techniques have much wider implications</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="432" width="152">than MLN inference.</text>
 
0	<text font="1" height="16" left="108" textpieces="1" top="474" width="321">B.7  Hardness of MRF Partitioning</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="506" width="702">A bisection of a graph G = (V, E) with an even number of vertices is a pair of disjoint subsets</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="567" width="702">problem admits no PTAS [15]. The hardness of MGB directly implies the hardness of partitioning</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="587" width="702">MRFs. As such, one may wonder if it still holds w.r.t. the domain size for a given MLN program</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="608" width="528">(hence of size O(1)). The following theorem shows that the answer is yes.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="661" width="229">generated an MLN of size O(1).</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="694" width="563">Proof. Consider the MLN that contains a single formula of the following form:</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="766" width="702">where p is query and r is evidence. For any graph G = (V, E), we can set the domain of the</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="787" width="702">predicates to be V , and let r = E. The MRF generated by the above MLN (using techniques in</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="827" width="59">be in P.</text>
 
0	<text font="1" height="16" left="108" textpieces="1" top="870" width="307">B.8  MRF Partitioning Algorithm</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="922" width="702">minimum spanning tree algorithm. Its greediness on clause wights serving as a simple heuristic to</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="943" width="171">minimizing the cut size.</text>
 
0	<text font="4" height="15" left="108" textpieces="1" top="983" width="689">MRF G = (V, E) is assigned to an atom in c. A partition of the MRF is a subgraph Gi= (Vi, E</text>
 
0	<text font="5" height="11" left="799" textpieces="0" top="989" width="10">i)</text>
 
0	<text font="4" height="15" left="451" textpieces="0" top="1069" width="16">25</text>
 
=======================================PAGE========================================
=======================================COL========================================
0	<text font="4" height="15" left="108" textpieces="0" top="133" width="329">the output is the connected components of G.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="170" width="386">Algorithm 3 A Simple MRF Partitioning Algorithm</text>
 
0	<text font="7" height="12" left="117" textpieces="1" top="319" width="421">4: return the collection of per-component atom sets in H</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="383" width="702">nodes, and performs all other operations in the RDBMS. For example, we use SQL queries to</text>
 
0	<text font="3" height="19" left="108" textpieces="1" top="451" width="311">C  Material for Experiments</text>
 
0	<text font="1" height="16" left="108" textpieces="1" top="491" width="320">C.1  Alternative Search Algorithms</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="543" width="702">than the in-memory counter part. This gap is consistent with the I/O performance of disk vs. main</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="563" width="702">memory. One might imagine some clever caching schemes for WalkSAT, but even assuming that</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="624" width="592">disk-based search implementations could catch up to their in-memory counterpart.</text>
 
0	<text font="4" height="15" left="133" textpieces="0" top="645" width="677">We explored alternative search algorithms by designing a MaxSAT algorithm called SweepSAT</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="665" width="702">that is more I/O friendly than WalkSAT. Although experiments show that SweepSAT gives faster</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="685" width="702">search speed than WalkSAT when both are implemented in an RDBMS, we eventually decided that</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="706" width="702">search algorithmics is orthogonal to our investigation of how the hybrid architecture and the idea</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="821" width="702">we conduct a lesion study by comparing the grounding time in three settings: 1) full optimizer,</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="882" width="702">force the RDBMS to use nested loop join only. The results are shown in Table 6. Clearly, being</text>
 
0	<text font="1" height="16" left="108" textpieces="1" top="945" width="313">C.3  Data Loading and Parallelism</text>
 
0	<text font="4" height="15" left="451" textpieces="0" top="1069" width="16">26</text>
 
=======================================PAGE========================================
=======================================COL========================================
1	<text font="2" height="13" left="434" textpieces="3" top="111" width="206">LP   IE       RC       ER</text>
 
3	<text font="2" height="13" left="299" textpieces="4" top="129" width="341">Full optimizer         6    13         40        106</text>
 
3	<text font="2" height="13" left="292" textpieces="4" top="148" width="348">Fixed join order        7    13         43        111</text>
 
3	<text font="2" height="13" left="277" textpieces="4" top="166" width="363">Fixed join algorithm   112   306   &gt;36,000   &gt;16,000</text>
 
4	<text font="4" height="15" left="330" textpieces="0" top="202" width="257">Table 6: Grounding time in seconds</text>
 
1	<text font="2" height="13" left="500" textpieces="1" top="240" width="62">IE   RC</text>
 
4	<text font="4" height="15" left="280" textpieces="0" top="331" width="358">Table 7: Comparison of execution time in seconds</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="384" width="702">which has both batch loading and parallelism. We use the same WalkSAT parameters on each com-</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="425" width="558">8-core Xeon CPU. Table 7 shows the end-to-end running time of each setting.</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="465" width="702">grounding + partitioning time of IE and RC are 11 seconds and 35 seconds, respectively. Hence,</text>
 
0	<text font="3" height="19" left="108" textpieces="1" top="533" width="299">D  Extended Related Work</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="594" width="702">to Kautz et al. [14]. Singla and Domingos [43] proposed lazy grounding and applies it to WalkSAT,</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="614" width="702">resulting in an algorithm called LazySAT that is implemented in Alchemy. The idea of ignoring</text>
 
0	<text font="4" height="14" left="108" textpieces="0" top="658" width="702">MLN grounding process in Shavlik and Natarajan [42], which formulates the grounding process</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="675" width="702">as nested loops and provides heuristics to approximate the optimal looping order. Mihalkova and</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="696" width="702">Mooney [36] also employ a bottom-up approach, but they address structure learning of MLNs</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="716" width="702">whereas we focus on inference. As an orthogonal approach to scaling MLN inference, Mihalkova</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="736" width="702">and Richardson [37] study how to avoid redundant computation by clustering similar query literals.</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="756" width="702">It is an interesting problem to incorporate their techniques into Tuffy. While Tuffy employs</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="777" width="702">the simple WalkSAT algorithm, there are more advanced techniques for MAP inference [32, 35]; we</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="797" width="702">plan to integrate them into upcoming versions of Tuffy. For hypergraph partitioning, there are</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="817" width="702">established solutions such as hMETIS [13]. However, their existing implementations are limited by</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="858" width="306">which motivated us to design Algorithm 3.</text>
 
0	<text font="4" height="15" left="133" textpieces="0" top="878" width="677">The technique of cutset conditioning [17] from the SAT and probabilistic inference literature is</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="899" width="702">closely related to our partitioning technique [31, 38]. Cutset conditioning recursively conditions on</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="939" width="702">which is impractical in our scenario: even for small datasets, the cut size can easily be thousands,</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="960" width="702">making exhaustive enumeration infeasible. Instead, we use a Gauss-Seidel strategy, which proves</text>
 
0	<text font="6" height="8" left="121" textpieces="0" top="1009" width="453">10Early stopping could occur for components that have zero-cost solutions.</text>
 
0	<text font="4" height="15" left="451" textpieces="0" top="1069" width="16">27</text>
 
=======================================PAGE========================================
=======================================COL========================================
0	<text font="4" height="15" left="108" textpieces="0" top="133" width="702">to optimize the IO and scheduling behavior of a wide class of local search algorithms; in contrast,</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="154" width="413">prior work focuses on designing new inference algorithms.</text>
 
0	<text font="4" height="17" left="133" textpieces="0" top="174" width="677">Finally, we note that there are statistical-logical frameworks similar to MLNs, such as Proba-</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="194" width="702">bilistic Relational Models [34] and Relational Markov Models [44]. Since inference on those models</text>
 
0	<text font="4" height="17" left="108" textpieces="0" top="215" width="702">also requires grounding and search, we believe that the lessons we learned with MLNs will carry</text>
 
0	<text font="4" height="15" left="108" textpieces="0" top="235" width="129">over to them, too.</text>
 
0	<text font="3" height="19" left="108" textpieces="0" top="281" width="113">References</text>
 
0	<text font="2" height="13" left="108" textpieces="0" top="318" width="669">[31] D. Allen and A. Darwiche. New advances in inference by recursive conditioning. In UAI03, 2003.</text>
 
0	<text font="2" height="13" left="108" textpieces="0" top="345" width="702">[32] J. Duchi, D. Tarlow, G. Elidan, and D. Koller. Using combinatorial optimization within max-product</text>
 
0	<text font="2" height="13" left="139" textpieces="0" top="363" width="207">belief propagation. NIPS, 2007.</text>
 
0	<text font="2" height="13" left="139" textpieces="0" top="408" width="116">intelligence, 1982.</text>
 
0	<text font="2" height="13" left="139" textpieces="0" top="453" width="34">1999.</text>
 
0	<text font="2" height="13" left="139" textpieces="0" top="497" width="82">ICML, 2007.</text>
 
0	<text font="2" height="13" left="108" textpieces="0" top="524" width="700">[36] L. Mihalkova and R. Mooney. Bottom-up learning of Markov logic network structure. In ICML, 2007.</text>
 
0	<text font="2" height="13" left="108" textpieces="0" top="551" width="702">[37] L. Mihalkova and M. Richardson. Speeding up inference in statistical relational learning by clustering</text>
 
0	<text font="2" height="13" left="139" textpieces="0" top="569" width="380">similar query literals. Inductive Logic Programming, 2010.</text>
 
0	<text font="2" height="13" left="139" textpieces="0" top="614" width="109">Deduction, 1996.</text>
 
0	<text font="2" height="13" left="108" textpieces="0" top="641" width="638">[39] J. Pearl. Probabilistic reasoning in intelligent systems: networks of plausible inference. 1988.</text>
 
0	<text font="2" height="13" left="139" textpieces="0" top="686" width="135">cies. In AAAI, 2006.</text>
 
0	<text font="2" height="13" left="108" textpieces="0" top="713" width="702">[41] H. Poon, P. Domingos, and M. Sumner. A general method for reducing the complexity of relational</text>
 
0	<text font="2" height="13" left="139" textpieces="0" top="731" width="332">inference and its application to MCMC. AAAI-08.</text>
 
0	<text font="2" height="13" left="108" textpieces="0" top="758" width="702">[42] J. Shavlik and S. Natarajan. Speeding up inference in Markov logic networks by preprocessing to reduce</text>
 
0	<text font="2" height="13" left="139" textpieces="0" top="775" width="371">the size of the resulting grounded network. In IJCAI-09.</text>
 
0	<text font="2" height="13" left="108" textpieces="0" top="829" width="702">[44] B. Taskar, P. Abbeel, and D. Koller. Discriminative probabilistic models for relational data. In UAI,</text>
 
0	<text font="2" height="13" left="139" textpieces="0" top="847" width="34">2002.</text>
 
0	<text font="2" height="13" left="139" textpieces="0" top="892" width="101">In AAAI, 2004.</text>
 
0	<text font="2" height="13" left="108" textpieces="0" top="919" width="702">[46] M. Wellman, J. Breese, and R. Goldman. From knowledge bases to decision models. The Knowledge</text>
 
0	<text font="2" height="13" left="139" textpieces="0" top="937" width="171">Engineering Review, 1992.</text>
 
0	<text font="4" height="15" left="451" textpieces="0" top="1069" width="16">28</text>
 
